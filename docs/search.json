[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "POL232 R Handbook (W2025)",
    "section": "",
    "text": "Preface\nThis book is used for statistical software lab sessions in POL232 Introductory Quantitative Reasoning II at the Department of Political Science at the University of Toronto in Winter 2025.\nQuantitative social science research requires the use of statistical software. In POL232, you will learn an elementary use of statistical software called R. In particular, you will use RStudio, a popular and accessible graphical user interface (GUI) to R.\nR is an open source software, and many packages developed by contributors around the world are available for free. To make your learning of R accessible, this book will cover only a limited set of packages and their functionalities specifically used in POL232. Even if you have no experience of programming before, don’t worry, as you will learn what you need in order to complete this class step by step, and we will focus only on a manageable set of functionalities of R. By the end of the semester, you are expected to be able to conduct an elementary quantitative data analysis and write a research paper based on it.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "1  Setting Up R & RStudio",
    "section": "",
    "text": "1.1 In-Class Lab Session at SS561\nIn our computer lab (SS561), both RStudio and R are preinstalled on all lab computers. During the class time, you can simply login to a lab computer using your utorid and open RStudio.\nMake sure you open only RStudio. When you use RStudio, you don’t need to open R because opening RStudio quietly starts R behind its GUI.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "setup.html#in-class-lab-session-at-ss561",
    "href": "setup.html#in-class-lab-session-at-ss561",
    "title": "Setting Up R & RStudio",
    "section": "",
    "text": "UNDER CONSTRUCTION"
  },
  {
    "objectID": "setup.html#download-and-install-r-rstudio",
    "href": "setup.html#download-and-install-r-rstudio",
    "title": "1  Setting Up R & RStudio",
    "section": "1.3 Download and Install R & RStudio",
    "text": "1.3 Download and Install R & RStudio\nUNDER CONSTRUCTION",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "setup.html#use-rstudio-from-jupyterhub",
    "href": "setup.html#use-rstudio-from-jupyterhub",
    "title": "1  Setting Up R & RStudio",
    "section": "1.2 Use RStudio from JupyterHub",
    "text": "1.2 Use RStudio from JupyterHub\nUNDER CONSTRUCTION",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "setup.html#r-packages",
    "href": "setup.html#r-packages",
    "title": "1  Setting Up R & RStudio",
    "section": "1.4 R Packages",
    "text": "1.4 R Packages\nUNDER CONSTRUCTION",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "basic.html",
    "href": "basic.html",
    "title": "2  Basic Use of RStudio",
    "section": "",
    "text": "2.1 Very Basics",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Use of RStudio</span>"
    ]
  },
  {
    "objectID": "basic.html#very-basics",
    "href": "basic.html#very-basics",
    "title": "2  Basic Use of RStudio",
    "section": "",
    "text": "2.1.1 Open RStudio Desktop\nYou may open R and use it directly through its own GUI, but many people find using R through RStudio more intuitive and easier than using R directly. When you use RStudio, you don’t need to open R. Just open RStudio only, as it also quietly starts R behind its GUI. Let’s open RStudio. Then, you will see the following GUI.\n\n\n\n\n\n\n\n\n\nIn R, we have our work done by executing a command. We enter a command after the &gt; prompt in the R Console, and then, the command will be executed by R.\n\n\n\n\n\n\n\n\n\nIn RStudio, we can also choose a menu from its GUI, and RStudio translates our input into a command and execute it in the R Console. Let’s see an example by reading the datasets we will use in this class.\n\n\n2.1.2 Datasets Used in POL232\nI prepared the datasets you will use in this class in the RData format, which is available on the class Quercus site. Go to the class Quercus site and download the following file to your computer (remember where you downloaded it).\n\n    POL232.RData\n\nLet’s open POL232.RData in RStudio.\n\n\n\n\n\n2.1.3 Load Datasets to RStudio: load()\nWe use a menu from GUI of RStudio to load POL232.RData to RStudio. First, choose an open folder icon on the Environment tab on the upper right pane of RStudio.\n\n\n\n\n\n\n\n\n\nThen, locate POL232.RData on your computer and choose it to open. In the following figure, I have located POL232.RData in the TEMP folder on my Desktop. Note, however, that the location where you have downloaded POL232.RData is different from mine. \n\n\n\n\n\n\n\n\n\nThen, the content of POL232.RData appears in the upper right pane of RStudio. As you can see, POL232.RData includes five datasets named anes2020, ces2019, ipe2020, ipe2015, and usstates2010. The datasets are stored in the format called data frame in R. So I will call these datasets data frames onward. To learn more about these data frames, see the codebooks available on the class Quercus site.\n\n\n\n\n\n\n\n\n\nAs you can see on the left pane of RStudio (see the red arrow), when we chose POL232.RData to open, RStudio translated this action into an R command and executed in the R Console. The commands used in R consist of R functions. An R function mostly takes the form of function.name(...), and we input arguments in the ... within the parentheses.\nIn the above example, to open POL232.RData, RStudio executed the load() function which takes the name and location (a file path) of the file as its argument (recall that an argument refers to what we specify in the parentheses of R functions). As you can see in the above figure, RStudio used the following code to open POL232.RData.\n\n  load(\"~/Desktop/TEMP/POL232.RData\")\n\n\n\n2.1.4 Browse Data Frame: View()\nLet’s browse a data frame by entering a command in the R console directly. You may use the View() function for this purpose. Include the name of the data frame you want to browse as argument; i.e., include it inside ().\n\n  View(ces2019)\n\nThen, the data frame specified will be open at the upper left pane as shown below.\n\n\n\n\n\n\n\n\n\nAn alternative to typing in View(ces2019) in the R console is to click ces2019 in the Environment tab at the upper right pane.  Then, RStudio will execute View(ces2019) for you to open the data frame in the upper left pane.\nYou may browse the data frame in this way. As you can see, the data frame is structured such that each row corresponds to each observation (in this case, each respondent of the survey) and each column corresponds to each variable. See ces2019_codebook.pdf for the description of the variables included in ces2019.\nI’d suggest you browse other data frames such as anes2020 and ipe2010. Try both typing in the View() function directly in the R console and clicking the name of a data frame on the Environment tab on the upper right pane.\n\n\n2.1.5 Getting Help for Functions: help() or ?\nIf you need help for a function, you may use the help() function with the name of your function of interest in the parentheses or ? operator followed by the name of the function. Try help(View) and ? View. Both of them will open the help window for View() on the lower right pane of RStudio.\n\n  help(View)\n  ? View\n\n\n\n\n\n\n\n\n\n\nWhenever you have a question about the usage of a specific function, you may use the help() function or the ? operator. If the explanation in the help menu is unclear to you, you may post your question on the Discussions Board of the class Quercus site.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Use of RStudio</span>"
    ]
  },
  {
    "objectID": "basic.html#r-script",
    "href": "basic.html#r-script",
    "title": "2  Basic Use of RStudio",
    "section": "2.2 R Script",
    "text": "2.2 R Script\nWhen you conduct an analysis in R, you should write a series of functions in an R script file and save it.\nLet’s look at a simple example. Go to the class Quercus site and download the following file.\n\n    POL232_R_Lab1_Example1.R\n\nPOL232_R_Lab1_Example1.R is an R script. The file extension .R is used for R scripts. Open this R script file in RStudio by choosing “File” \\(\\rightarrow\\) “Open File…” from the menu bar or clicking the open folder icon () at the upper left corner. (Make sure you do NOT click the open folder icon () at the Environment tab on the upper right pane, because you cannot open an R script from there. Note that if you hover your cursor over the open folder icon at the upper left corner, the following message, “Open an existing file,” should appear as shown below. If you hover your cursor over the icon at the Environment tab on the upper right, the description to appear is “Load Workspace.”)\n\nThen, this R script appears in the top left window of RStudio.\n\n\n\n\n\n\n\n\n\nPOL232_R_Lab1_Example1.R contains functions to draw a scatterplot using the usstates2010 data frame. Don’t worry about these functions for now. You will learn how to draw a similar scatterplot later in the semester.\n\n2.2.1 Execute Functions from an R Script\nIf you write a series of functions in an R script like this one, you can easily repeat your analysis. From an R script file, you can execute the functions.\nIn POL232_R_Lab1_Example1.R, go to a line or highlight a line (or a set of lines), and then press Ctrl + Enter in Windows or Command + Return in Mac. Then, the functions chosen will be implemented in the R Console. Alternatively, you may click the “Run” icon ().\n\n\n\n\n\n\n\n\n\nIf you execute all the functions in POL232_R_Lab1_Example1.R, RStudio will draw the following scatterplot on the lower right pane.\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Write Comments After #\nPOL232_R_Lab1_Example1.R produced a scatterplot with a linear regression line for the relationship between the proportion of two-party vote share for a democratic gubernatorial candidate and the percent of Democratic identifiers, individuals who identify themselves as Democrats, across US states.\nBelow is a copy of this R script. As I suggested above, don’t worry about what these functions in the R script are doing. I am showing the content of the R script below only to explain how you can write comments in your R script file.\n\n# Estimate a simple linear regression model for the relationship\n# between the proportion of two-party vote share for a democratic gubernatorial\n# candidate (ranney3_gub_prop) and the percent of Democratic identifiers\n# (democrat), individuals who identify themselves as Democrats, across\n# US states, and assign its result to the object named \"us.\"\nus &lt;- lm(formula = ranney3_gub_prop*100 ~ democrat, data=usstates2010)\n\n# Draw a scatterplot using presidential election years.\nplot(usstates2010$democrat, usstates2010$ranney3_gub_prop*100,\n     type=\"n\",\n     ylim=c(0,100), xlim=c(15, 75),\n     main=\"US Gubernatorial Elections\",\n     ylab=\"Vote Share (%) of Dem Candidate\",\n     xlab=\"Democratic Identifiers (%)\",\n     cex.main=1.0, cex.lab=1.0, cex.axis=1.0)\ntext(x=usstates2010$democrat, y=usstates2010$ranney3_gub_prop*100,\n    usstates2010$st, col=\"blue\", cex=0.75)\n\n# Add a linear regression line.\nabline(a=us$coefficients[1],b=us$coefficients[2],\n    col=\"red\", lwd=3)\n\nIn the above R script, you may notice that some descriptions are given after #. In an R script file, everything after # will not be executed by R. When R implements these functions, it ignores everything after #. Therefore, we can write comments after #.\nI suggest you sufficiently annotate your R script using # so that you can understand what you did when you come back to work on your R project after a while.\n\n\n2.2.3 Always Write an R Script\nI suggest you always create an R script file, write functions and comments in this R script, and save this script when you conduct analysis in R, because this may be the most transparent and effective way to save and reproduce your analysis.\nTherefore, in every R lab session, I will ask you to write an R script file and submit it to Quercus by the end of the lab session to earn a participation mark, so that you can develop the habit of writing R scripts.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Use of RStudio</span>"
    ]
  },
  {
    "objectID": "basic.html#practic-writing-an-r-script",
    "href": "basic.html#practic-writing-an-r-script",
    "title": "2  Basic Use of RStudio",
    "section": "2.3 Practic Writing an R Script",
    "text": "2.3 Practic Writing an R Script\n\nLet’s write a very simple R script to try some very basic (mathematical) operations in R.\n\n2.3.1 How to Start a New R Script\nYou may start a new file by choosing “File” \\(\\rightarrow\\) “New File” \\(\\rightarrow\\) “R Script” from the menu bar (left in the image below) or simply clicking the “New File” icon () and choose “R Script” (right in the image below).\n\nOnce you create a new R script, you should of course save it. You can save it by choosing “File” from the pull down menu and then “Save As” (left in the image below) or clicking the save file icon (right in the image below).\n\nYou should choose an informative name for your R script. For the current purpose, name your R script “POL232_Lab1_YourLastName.R.”\n\n\n2.3.2 Very Basic Math\nFirst, write the following mathematical operations in your R script and execute them from within the R script. See Section 2.2.1 if you forget how to run functions from within an R script.\n\n  1 + 5     # Addition\n  2 - 3     # Subtraction\n  4 * 7     # Multiplication\n  2735 / 45 # Division\n  2^4       # Exponents\n  sqrt(16)  # Square root\n  abs(-5)   # Absolute value\n  1:100     # Sequence of integers from 1 to 100\n\nThen, these mathematical operations will be carried out in the R Console. Each of them returns the output of the operation — for example, 6 for 1 + 5, and -1 for 2 - 3.\nRecall that R ignores everything after #, so you can annotate your R script after #.\nNext, write 5:100 as follows in your R script and execute it. You will get the output that follows — a sequence of numbers from 5 to 100.\n\n  5:100    # Sequence of integers from 5 to 100\n\n [1]   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23\n[20]  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n[39]  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61\n[58]  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n[77]  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n[96] 100\n\n\nIn the output, numbers in square brackets at the beginning of each line represent a position of the first entry of each line. As you see in the above output, 5 is the first entry of 5:100, and 24 is the 20th entry of 5:100, 43 is the 39th, and so forth.\n\n\n2.3.3 Create a Variable Using the Assignment Operator (&lt;-)\nWe can create a variable and assign a number or multiple numbers to this variable using the assignment operator, &lt;-. First, let’s assign a single number to a variable.\nFor example, the following operation will assign the result of 1 + 5, which is 6, to a variable named y. Write this operation in your R script and then execute it (once again, see Section 2.2.1 if you forget how to run a function from within an R script).\n\n  y &lt;- 1 + 5  # The assignment operator, &lt;-, will assign the values on the right-hand-side \n              # to a variable named y.\n\nTyping in the variable name in the R Console will print its content. Try this.\n\n  y\n\n[1] 6\n\n\nIt returns 6.\nNow write the following operation in your R script and execute it to create a different variable x.\n\n  x &lt;- 7\n\nCheck its content by typing the variable name, x, in the R Console.\n\n  x\n\n[1] 7\n\n\nIt returns 7. You can overwrite a variable by assigning a different number to the variable. Write the following operation in your R script and execute it.\n\n  x &lt;- 10\n\nNow your x should be changed to 10. Type in x in the R Console to confirm.\n\n  x\n\n[1] 10\n\n\nYou can apply mathematical operations on variables. For example, write the following operations — sqrt() to take a square root — in your R script and execute them.\n\n  y + x        # Because y = 6 & x = 10, this is 16.\n\n[1] 16\n\n  sqrt(y + x)  # This will take a square root of 16, which is 4.\n\n[1] 4\n\n\nYou may assign the result of a mathematical operation on variables to another variable. Write the following operations in your R script and execute them.\n\n  z &lt;- y + x  # z will be the result of y + x. Since y = 6 and x = 10, z = 16.\n\n  z           # Executing this from your R script is equivalent to typing in `z` into the R Console.\n\n[1] 16\n\n\n\n\n2.3.4 See What’s in Your Workspace (= Working Memory): ls() or objects()\nWhat you have created so far (called “objects”) in the current R session have been stored in the R’s working memory, called workspace. You can see what is available in your workspace by executing ls() or objects() without arguments (= nothing in the parentheses). objects() may be more intuitive because anything you construct in R is called an object.\nWrit the following functions in your R script and execute them.\n\n  objects()  # This function will list everything in your workspace.\n\n[1] \"anes2020\"     \"ces2019\"      \"ipe2010\"      \"ipe2015\"      \"us\"          \n[6] \"usstates2010\" \"x\"            \"y\"            \"z\"           \n\n\n\n  ls()       # This function does the same thing as the objects() function.\n\n[1] \"anes2020\"     \"ces2019\"      \"ipe2010\"      \"ipe2015\"      \"us\"          \n[6] \"usstates2010\" \"x\"            \"y\"            \"z\"           \n\n\nYou can also see what’s stored in your workspace at the Environment tab at the upper right pane.\n\nNote that everything you created and stored in your workspace will be gone, once you quit R. This is fine, as you can always recreate the objects you created in the current R session easily by running the functions recorded in your R script.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.5 Remove a Variable from Your Workspace: remove() or rm()\nIf you want to remove or erase a variable from your workspace, use remove() or its abbreviation rm(). For example, remove(x) or rm(x) will erase x from your workspace. Write the following function in your R script and execute it.\n\n  remove(x)   # This function will remove the variable `x` from your workspace.\n\nType in x in the R Console to see that this variable is not available anymore. The error message will suggest that the variable x cannot be found.\n\n\n2.3.6 Remove Everything: remove(list=ls()) or rm(list=ls())\nIf you want to remove everything from your workspace, you may use the following function. Write this function in your R script and execute it.\n\n  remove(list=ls())  # This will erase everything from your workspace.\n\nRun objects() or ls() to see that everything is gone. character{0} means there is nothing in your workspace.\n\n  ls()\n\ncharacter(0)\n\n\nMake sure you save your R script. This R script may be used as your reference in your later work.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Use of RStudio</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "setup.html#sec-jupyterhub",
    "href": "setup.html#sec-jupyterhub",
    "title": "1  Setting Up R & RStudio",
    "section": "1.2 Use RStudio from JupyterHub",
    "text": "1.2 Use RStudio from JupyterHub\nAs a UofT student, you have an access to JupyterHub. While you can download and install R and RStudio on your computer, you may also use RStudio online from JupyterHub. In this option, you can avoid all the troubles in installing R and RStudio. Especially if you encounter any issues in installing R and RStudio on your computer, this will be a viable alternative.\nIn this section, I explain how to use RStudio online through JupyterHub.\nTo access RStudio from JupyterHub, go to https://datatools.utoronto.ca/ and choose RStudio.\n\n\n\n\n\nClick “Log On” and login using your utorid.\n\n\n\n\n\nThen, RStudio Server will open on your browser.\n\n\n\n\n\nNow you can use RStudio online.\n\n1.2.1 Prepare for POL232 on JupyterHub\nFirst, I suggest you create a folder for POL232.\nClick “New Folder” in the lower right pane.\n\n\n\n\n\n\n\n\n\nType in a name of the folder. Here I use “POL232.”\n\n\n\n\n\n\n\n\n\nThen, the new folder appears in the lower right pane.\n\n\n\n\n\n\n\n\n\nAs we use the datasets in POL232.RData, we first need to upload this file to RStudio on JupyterHub. If you haven’t downloaded it yet, go to the class Quercus site and download POL232.RData.\nThen, let’s upload POL232.RData to RStudio on JupyterHub.\nClick the “Upload” icon.\n\n\n\n\n\n\n\n\n\nThen, the following pop-up window appears. You first need to choose the target directory, which is a folder to which you upload POL232.RData.\nClick “Browse”…\n\n\n\n\n\n\n\n\n\nand choose the folder you just created. Here I choose the “POL232” folder.\n\n\n\n\n\n\n\n\n\nThen, select POL232.RData on your local drive to upload.\nClick “Browse”…\n\n\n\n\n\n\n\n\n\nLocate POL232.RData on your local drive and select it. Note that the location of POL232.RData on your local drive is different from mine shown below.\n\n\n\n\n\n\n\n\n\nHit “OK” to upload.\n\n\n\n\n\n\n\n\n\nThen, POL232.RData appears in the folder you created in the lower right pane (the “POL232” folder in my case shown below).\n\n\n\n\n\n\n\n\n\nYou can upload other files, if necessary, to RStudio on JupyterHub in the same way.\nFor example, to complete Section 2.2, you may want to upload POL232_R_Lab1_Example1.R.\nClick these files in your folder in the lower right pane to open them. Below I opened POL232_R_Lab1_Example1.R that I have uploaded.\n\n\n\n\n\n\n\n\n\nThen, you can use RStudio online from your browser, as you do in RStudio Desktop on lab computers.\n\n\n1.2.2 Save Output Online\nYou can save what you create in RStudio on JupyterHub online in the folder you just created. In the example shown below, I save a scatterplot produced by the functions in POL232_R_Lab1_Example1.R (see Section 2.2.1).\nTo save the scatterplot, first choose “Export” on the Plots tab in the lower right pane and choose “Save as Image”.\n\n\n\n\n\n\n\n\n\nThen, choose the folder to which you will save the plot and specify a name of the plot.\n\n\n\n\n\n\n\n\n\nClick the “Files” tab in the lower right pane, then you can see that the plot you have saved appears there.\n\n\n\n\n\n\n\n\n\nThese files saved in your folder is saved in your cloud account for JupyterHub. They will stay there after you log out, and you can use them when you come back to JupyterHub.\n\n\n1.2.3 Download Output\nYou can also download the files you saved online in RStudio on JupyterHub to your computer.\nCheck the file you want to download, and click “More.” Then, choose “Export” from the pull-down menu.\n\n\n\n\n\n\n\n\n\nIn the pop-up window, you may change a file name, if you want. Click “Download” to save the file on your computer locally.\n\n\n\n\n\n\n\n\n\nIn R lab sessions during the class time or tutorial sessions, you will be required to upload the R script or some other files that you create during the sessions to the class Querus site. For this purpose, you first need to download these files to your local computer, and then, you will upload these files to Quercus from the local computer.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "setup.html#sec-install",
    "href": "setup.html#sec-install",
    "title": "1  Setting Up R & RStudio",
    "section": "1.3 Download and Install R & RStudio",
    "text": "1.3 Download and Install R & RStudio\nYou may also download and install R and RStudio onto your computer. While you will open RStudio only, you need to install both R and RStudio on your computer. This is because RStudio is a GUI for R. When we open RStudio, it also quietly opens R behind.\nYou can download R onto your own computer from the CRAN (Comprehensive R Archive Network) mirror site closest to your place. You may choose one of the mirror sites listed under Canada.\n\n1.3.1 R for a Windows user\n\nClick “Download R for Windows.”\nChoose “base” (or “install R for the first time”) .\nClick “Download R 4.4.2 for Windows” (“4.4.2” here refers to the version number. If the version on this site is newer — the version number is greater than 4.4.2 — then it is the latest version so download that latest version instead).\nInstall R onto your computer.\n\n\n\n1.3.2 R and XQuartz for a Mac user\n\nClick “Download R for macOS.”\nDownload an appropriate release of R for your Mac. In particular, there are different releases for Apple silicon (M1,M2,…) Macs and older Intel Macs.\nInstall R onto your computer.\nMake sure you also download and install XQuartz in order to use graphic functions of R on your Mac computer.\n\n\n\n1.3.3 RStudio\nDownload and install RStudio Desktop from the RStudio’s website. Note that there is also a commercial license of R Studio Desktop Pro, but a free Open Source Edition will suffice our purpose. Choose installers appropriate for your operating system (OS).\n\n\n1.3.4 Update\nR and RStudio are frequently updated. You don’t need to update them during the current semester, but in your future use, it is recommended that you update the versions of R and RStudio occasionally.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "setup.html#sec-rpackages",
    "href": "setup.html#sec-rpackages",
    "title": "1  Setting Up R & RStudio",
    "section": "1.4 R Packages",
    "text": "1.4 R Packages\nA package is a collection of user-written R functions, which you may download and install into your R library (i.e., onto your computer). There are thousands of packages available. You can see the currently available packages in this list.\nYou can see which packages were already downloaded in your R library in the Packages tab in the lower right pane of RStudio.\n\nYou may also use the library() function without an argument. If you run this function in RStudio, the R packages available tab will appear in the upper left pane.\n\n  library()\n\n\nIf this is the first time you use R, what you see here is the list of default R packages which came together with the installation of R. If we want to use R packages not included in this default list, we first need to download and install them on our computer.\n\n1.4.1 Install Package: install.packages()\nIn POL232, we are going to use a few packages included in tidyverse, a popular collection of multiple R packages. If you download and install tidyverse, multiple packages included therein will be installed on your computer. In particular, we will often use dplyr and ggplot2 from the tidyverse family of packages in this course.\nTo install a package, you can use the install.packages() function.\n\n  install.packages(\"tidyverse\")\n\nOr you may choose Install Packages… from the Tools menu.\n\nThen, type in the name of a package you want in the pop up window, and hit Install.\n\nAnother way to launch the above pop up window is to hit the Install icon () on the Packages tab at the lower right pane of RStudio.\n\n\n\n1.4.2 Load Package to Current R Session: library()\nTo use an R package you installed on your computer, you need to first load this package to your current R session using the library() function. For example, the following function loads all packages in tidyverse.\n\n  library(tidyverse)\n\nWe can now use the functions included in the family of tidyverse packages, including dplyr and ggplot2. These functions are accessible during your current R session.\nIf you quit R and restart an R session, you need to load tidyverse again by the library() function.\nNote that you don’t need to download and install the package you need every time you want to use it — once you have downloaded and installed it, it stays in your computer. You just need to load it into your current R session by the library() function, every time you start R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "basic.html#sec-rscript",
    "href": "basic.html#sec-rscript",
    "title": "2  Basic Use of RStudio",
    "section": "2.2 R Script",
    "text": "2.2 R Script\nWhen you conduct an analysis in R, you should write a series of functions in an R script file and save it.\nLet’s look at a simple example. Go to the class Quercus site and download the following file.\n\n    POL232_R_Lab1_Example1.R\n\nPOL232_R_Lab1_Example1.R is an R script. The file extension .R is used for R scripts. Open this R script file in RStudio by choosing “File” \\(\\rightarrow\\) “Open File…” from the menu bar or clicking the open folder icon () at the upper left corner. (Make sure you do NOT click the open folder icon () at the Environment tab on the upper right pane, because you cannot open an R script from there. Note that if you hover your cursor over the open folder icon at the upper left corner, the following message, “Open an existing file,” should appear as shown below. If you hover your cursor over the icon at the Environment tab on the upper right, the description to appear is “Load Workspace.”)\n\nThen, this R script appears in the top left window of RStudio.\n\n\n\n\n\n\n\n\n\nPOL232_R_Lab1_Example1.R contains functions to draw a scatterplot using the usstates2010 data frame. Don’t worry about these functions for now. You will learn how to draw a similar scatterplot later in the semester.\n\n2.2.1 Execute Functions from an R Script\nIf you write a series of functions in an R script like this one, you can easily repeat your analysis. From an R script file, you can execute the functions.\nIn POL232_R_Lab1_Example1.R, go to a line or highlight a line (or a set of lines), and then press Ctrl + Enter in Windows or Command + Return in Mac. Then, the functions chosen will be implemented in the R Console. Alternatively, you may click the “Run” icon ().\n\n\n\n\n\n\n\n\n\nIf you execute all the functions in POL232_R_Lab1_Example1.R, RStudio will draw the following scatterplot on the lower right pane.\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Write Comments After #\nPOL232_R_Lab1_Example1.R produced a scatterplot with a linear regression line for the relationship between the proportion of two-party vote share for a democratic gubernatorial candidate and the percent of Democratic identifiers, individuals who identify themselves as Democrats, across US states.\nBelow is a copy of this R script. As I suggested above, don’t worry about what these functions in the R script are doing. I am showing the content of the R script below only to explain how you can write comments in your R script file.\n\n# Estimate a simple linear regression model for the relationship\n# between the proportion of two-party vote share for a democratic gubernatorial\n# candidate (ranney3_gub_prop) and the percent of Democratic identifiers\n# (democrat), individuals who identify themselves as Democrats, across\n# US states, and assign its result to the object named \"us.\"\nus &lt;- lm(formula = ranney3_gub_prop*100 ~ democrat, data=usstates2010)\n\n# Draw a scatterplot using presidential election years.\nplot(usstates2010$democrat, usstates2010$ranney3_gub_prop*100,\n     type=\"n\",\n     ylim=c(0,100), xlim=c(15, 75),\n     main=\"US Gubernatorial Elections\",\n     ylab=\"Vote Share (%) of Dem Candidate\",\n     xlab=\"Democratic Identifiers (%)\",\n     cex.main=1.0, cex.lab=1.0, cex.axis=1.0)\ntext(x=usstates2010$democrat, y=usstates2010$ranney3_gub_prop*100,\n    usstates2010$st, col=\"blue\", cex=0.75)\n\n# Add a linear regression line.\nabline(a=us$coefficients[1],b=us$coefficients[2],\n    col=\"red\", lwd=3)\n\nIn the above R script, you may notice that some descriptions are given after #. In an R script file, everything after # will not be executed by R. When R implements these functions, it ignores everything after #. Therefore, we can write comments after #.\nI suggest you sufficiently annotate your R script using # so that you can understand what you did when you come back to work on your R project after a while.\n\n\n2.2.3 Always Write an R Script\nI suggest you always create an R script file, write functions and comments in this R script, and save this script when you conduct analysis in R, because this may be the most transparent and effective way to save and reproduce your analysis.\nTherefore, in every R lab session, I will ask you to write an R script file and submit it to Quercus by the end of the lab session to earn a participation mark, so that you can develop the habit of writing R scripts.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Use of RStudio</span>"
    ]
  },
  {
    "objectID": "setup.html#install-package-install.packages",
    "href": "setup.html#install-package-install.packages",
    "title": "1  Setting Up R & RStudio",
    "section": "1.5 Install Package: install.packages()",
    "text": "1.5 Install Package: install.packages()\nIn POL232, we are going to use a few packages included in tidyverse, a popular collection of multiple R packages. If you download and install tidyverse, multiple packages included therein will be installed on your computer. In particular, we will often use dplyr and ggplot2 from the tidyverse family of packages in this course.\nTo install a package, you can use the install.packages() function.\n\n  install.packages(\"tidyverse\")\n\nOr you may choose Install Packages… from the Tools menu.\n\nThen, type in the name of a package you want in the pop up window, and hit Install.\n\nAnother way to launch the above pop up window is to hit the Install icon () on the Packages tab at the lower right pane of RStudio.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "setup.html#load-package-to-current-r-session-library",
    "href": "setup.html#load-package-to-current-r-session-library",
    "title": "1  Setting Up R & RStudio",
    "section": "1.6 Load Package to Current R Session: library()",
    "text": "1.6 Load Package to Current R Session: library()\nTo use an R package you installed on your computer, you need to first load this package to R using the library() function. For example, the following function loads all packages in tidyverse.\n\n  library(tidyverse)\n\nWe can now use the functions included in the family of tidyverse packages, including dplyr and ggplot2. These functions are accessible during your current R session. If you quit R and restart an R session, you need to load tidyverse again to your search path by the library() function. Note that you don’t need to download and install the package you need every time you want to use it — once you have downloaded and installed it, it stays in your computer. You just need to load it into your current R session by the library() function, when you start the R session.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setting Up R & RStudio</span>"
    ]
  },
  {
    "objectID": "des1.html",
    "href": "des1.html",
    "title": "3  Descriptive Statistics (1)",
    "section": "",
    "text": "3.1 Preparation\nBefore you start working on this chapter, you need to do the following.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#preparation",
    "href": "des1.html#preparation",
    "title": "3  Descriptive Statistics (1)",
    "section": "",
    "text": "3.1.1 Launch RStudio\n\nLaunch RStudio. Recall that you don’t need to launch R because RStudio quietly opens R behind its GUI.\nIf you use RStudio on JupyterHub and don’t remember how to use it, see Section 1.2.\n\n\n\n3.1.2 Load POL232..RData\n\nMake sure you load POL232.RData into your current R session. If you forget how to load POL232.RData into your current R session, see Section 2.1.3.\nIf you use RStudio on JupyterHub or your own computer, you are likely to have already downloaded and stored POL232.RData in your local folder either on your JupyterHub account or your own computer.\nHowever, if you use RStudio on a lab computer in SS 561, you first need to download POL232.RData from the class Quercus site because everything you saved on the lab computer is gone once you logged out from it.\n\n\n\n3.1.3 Prepare R Script\n\nI suggest you write everything you do in RStudio in an R script and run R functions from within the R script. If you need a refresher for R script, read Section 2.2 and Section 2.3.\nFor the current purpose, start a new R script and name it “POL232_Lab#_YourLastName.R” in which # is the number of the current lab session (e.g., POL232_Lab2_YourLastName.R, POL232_Lab3_YourLastName.R). See Section 2.3.1 for how to start a new R script.\n\n\n\n3.1.4 Load Packages\n\nFor the current chapter, you also need to load tidyverse package into your current R session (Section 1.4.2).\n\n\n  library(tidyverse)\n\n\nIf you don’t know about or forget about R packages, read Section 1.4.\nIf library(tidyverse) returns an error message suggesting there is no package called 'tidyverse', this means that tidyverse is not installed on your computer. In this case, you first need to install it. See Section 1.4.1 for how to dowonload and install R packages.\n\n\n\n3.1.5 Actually Write R Functions\n\nI suggest you actually write the R functions used below in your R script instead of copying and pasting them. By actually writing them and occasionally making mistakes and correcting them, you can learn how R languages work more effectively.\nIn your R script, leave descriptions of the functions after the # sign (see Section 2.2.2). Then, you can use your R script later as your reference when you conduct analysis using these R functions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#histogram-ggplot-geom_histogram",
    "href": "des1.html#histogram-ggplot-geom_histogram",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.2 Histogram: ggplot() + geom_histogram()",
    "text": "3.2 Histogram: ggplot() + geom_histogram()\nLet’s draw a histogram for the Trudeau thermometer in the Canadian Election Study 2019 (ces2019), which records how a respondent feels about Justin Trudeau, the incumbent prime minister in 2019, on a scale from 0 (coldest feeling) to 100 (warmest feeling).\nWe use the ggplot() function for this purpose.\nRecall that an R function mostly takes the form of function.name(...), and we specify arguments in the ... within the parentheses. A basic syntax of the ggplot() function to draw a histogram is as follows. (Don’t implement the code below, which is intended only to show the syntax of the ggplot function and is not intended to be implemented. You will get an error message if you implement the following code.)\n\n  ggplot(name-of-data-frame, aes(name-of-variable)) + \n      geom_histogram()\n\nFirst, the ggplot function takes two arguments at minimum. (Once again, recall that what a function takes in its parentheses () is called an argument.) The first argument is the name of the data frame that contains the variable we want to visualize, and the second argument is the aes() function. Since the second argument is a function, it also takes arguments. The aes() function takes one argument at minimum, the name of the variable which we want to visualize.\nIn summary, the ggplot function tells R which variable from which data frame we want to visualize.\nThen, the ggplot function should be followed by the geom_histogram() function connected by a plus sign (+). We may also specify arguments for the geom_histogram() function, but it still works without any arguments.\nLet’s try this function. There are two Trudeau thermometers in ces2019: the one asked during the election campaign, truedau_therm_cps, and the other asked after the election, truedau_therm_pes. Here we use the one asked during the campaign, truedeau_therm_cps.\nRun the following function — in particular, write it in your R script and run it from there. See ?sec-execute-rscript for how ti execute R functions from your R script.\nThen, a histogram will appear in the Plots tab at the lower right pane.\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) +\n    geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.\n\n\nWarning: Removed 45 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nAs you can see, there is a warning message suggesting that R removed “45 rows containing non-finite values.” What this means is that when it drew this histogram, R removed 45 observations for which trudeau_therm_cps is missing.1\n\nWhile the above simple specification of the ggplot() function can produce the histogram above, it doesn’t look great. We should edit this histogram further such that it looks better. To do this, we may add further functions connected by a plus sign (+) to the ggplot() function and/or specify more arguments to these functions.\nLet’s try what we can do step by step.\n\n3.2.1 Location and Width (or Number) of Bins: boundary, binwidth, bins\nFirst, you may have noticed that the left most bin is centered at 0, and the right most bin is centered at 100, although the value of trudeau_therm_cps ranges from 0 to 100 — i.e., there are no observations with the values smaller than 0 or greater than 100. We may want to adjust the histogram such that the bins are drawn within the possible values of the variable — in this case, between 0 and 100. We can do this by setting the boundary argument in the geom_histogram() function.\nIf you set the boundary argument at the minimum value of the variable — 0 in the current case — then the histogram is adjusted such that the left most bin starts from this minimum value, rather than starting just before this minimum value.\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n      geom_histogram(boundary=0)\n\n\n\n\n\n\n\n\nNow the histogram looks slightly better, but you may think that the bin width is too narrow, or equivalently, the number of bins is too many. We can adjust this by specifying either the bin width by the binwidth argument or the number of bins by the bins argument in the geom_histogram() function.\nBelow I use the binwidth argument to specify the width of each bin as 10 points.\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n      geom_histogram(boundary=0, binwidth = 10)\n\n\n\n\n\n\n\n\nNow the histogram looks much better.\n\n\n3.2.2 Color of Bins: fill, color\nSuppose you want to change the color of the bins. We can specify the fill argument in the geom_histogram function as below. You may specify the name of the color you want. You can find the color names used in R online, here and here, for example.\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\")\n\n\n\n\n\n\n\n\nNow the boundaries of each bin are not clear. Let’s draw a line around each bin. We can do this by specifying the color argument in the geom_histogram function. I made these lines black below, but you may of course choose a different color.\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\")\n\n\n\n\n\n\n\n\n\n\n3.2.3 Title and Axis Labels: labs(), ylab(), xlab()\nWe can add a title by adding the labs() function, and we can change the axis labels by the ylab() and xlab() functions. Below I added a title that reads “Feelings about JUSTIN TRUDEAU” and changed the Y-axis label from the default “count” to “Number of Observations” and the X-axis label from the default variable name (trudeau_therm_cps) to nothing. Don’t forget to connect all these functions by a plus sign (+).\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\n\n\n3.2.4 Values and Tick Marks Appearing on the X and Y Axes: scale_x_continuous(), scale_y_continuous()\nWe can also change the values of the variable on the X-axis at which tick marks and numbers appear by the scale_x_continuous() function with the breaks argument. In the histograms above, the tick marks and numbers appear at 0 to 100 with an interval of 25. Below I change them to 0 to 100 with an interval of 10. For this purpose, the breaks argument is set to seq(0, 100, 10).\nThe seq(starting-number, ending-number, interval) function is another function which produces a sequence of numbers from starting-number to ending-number with the specified interval. That is, seq(0, 100, 10) produces a sequence from 0 to 100 with an interval of 10.\nAs you can see in the X-axis of the histogram below, setting breaks = seq(0, 100, 10) in the scale_x_continuous function (the last line of the code below) changes the values and tick marks at the X-axis to 0 to 100 with an interval of 10.\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\") +\n    scale_x_continuous(breaks = seq(0, 100, 10))\n\n\n\n\n\n\n\n\nTry other values to see how the values and tick marks change on the X-axis. For example, if you change this to seq(20, 60, 20) (the last line of the code below), then the values and tick marks appear only from 20 to 60 with an interval of 20.\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\") +\n    scale_x_continuous(breaks = seq(20, 60, 20))\n\n\n\n\n\n\n\n\nTo change the values and tick marks on the Y-axis, we can add the scale_y_continuous function with the same breaks argument. Below I change the values and tick marks to 0 to 1000 with an interval of 200 (the last line).\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\") +\n    scale_x_continuous(breaks = seq(0, 100, 10)) +\n    scale_y_continuous(breaks = seq(0, 1000, 200))  \n\n\n\n\n\n\n\n\n\n\n3.2.5 Range of Values at the X and Y Axes: coord_cartesian()\nWe can also change the range of values appearing on both X and Y axes by adding the coord_cartesian() function with the xlim and ylim arguments, respectively. In the code below at the last line, I added coord_cartesian(ylim = c(0,1200)) to change the range of values on the Y-axis to 0 from 1200. Accordingly, I also changed the ending value of the breaks argument in the scale_y_continuous function to 1200 (the second to the last line).\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\") +\n    scale_x_continuous(breaks = seq(0, 100, 10)) +\n    scale_y_continuous(breaks = seq(0, 1200, 200)) +\n    coord_cartesian(ylim = c(0, 1200))\n\n\n\n\n\n\n\n\nJust as an example, I also added the xlim argument to the coord_cartesian() function below (the last line) to shorten the range of X-axis.\n\n  ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\") +\n    scale_x_continuous(breaks = seq(0, 100, 10)) +\n    scale_y_continuous(breaks = seq(0, 1200, 200)) +\n    coord_cartesian(ylim = c(0, 1200), xlim = c(20,80))\n\n\n\n\n\n\n\n\nNow you can draw a pretty nice histogram for the variable of your interest.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "basic.html#sec-write-rscript",
    "href": "basic.html#sec-write-rscript",
    "title": "2  Basic Use of RStudio",
    "section": "2.3 Practic Writing an R Script",
    "text": "2.3 Practic Writing an R Script\n\nLet’s write a very simple R script to try some very basic (mathematical) operations in R.\n\n2.3.1 How to Start a New R Script\nYou may start a new file by choosing “File” \\(\\rightarrow\\) “New File” \\(\\rightarrow\\) “R Script” from the menu bar (left in the image below) or simply clicking the “New File” icon () and choose “R Script” (right in the image below).\n\nOnce you create a new R script, you should of course save it. You can save it by choosing “File” from the pull down menu and then “Save As” (left in the image below) or clicking the save file icon (right in the image below).\n\nYou should choose an informative name for your R script. For the current purpose, name your R script “POL232_Lab1_YourLastName.R.”\n\n\n2.3.2 Very Basic Math\nFirst, write the following mathematical operations in your R script and execute them from within the R script. See Section 2.2.1 if you forget how to run functions from within an R script.\n\n  1 + 5     # Addition\n  2 - 3     # Subtraction\n  4 * 7     # Multiplication\n  2735 / 45 # Division\n  2^4       # Exponents\n  sqrt(16)  # Square root\n  abs(-5)   # Absolute value\n  1:100     # Sequence of integers from 1 to 100\n\nThen, these mathematical operations will be carried out in the R Console. Each of them returns the output of the operation — for example, 6 for 1 + 5, and -1 for 2 - 3.\nRecall that R ignores everything after #, so you can annotate your R script after #.\nNext, write 5:100 as follows in your R script and execute it. You will get the output that follows — a sequence of numbers from 5 to 100.\n\n  5:100    # Sequence of integers from 5 to 100\n\n [1]   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23\n[20]  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42\n[39]  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61\n[58]  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80\n[77]  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99\n[96] 100\n\n\nIn the output, numbers in square brackets at the beginning of each line represent a position of the first entry of each line. As you see in the above output, 5 is the first entry of 5:100, and 24 is the 20th entry of 5:100, 43 is the 39th, and so forth.\n\n\n2.3.3 Create a Variable Using the Assignment Operator (&lt;-)\nWe can create a variable and assign a number or multiple numbers to this variable using the assignment operator, &lt;-. First, let’s assign a single number to a variable.\nFor example, the following operation will assign the result of 1 + 5, which is 6, to a variable named y. Write this operation in your R script and then execute it (once again, see Section 2.2.1 if you forget how to run a function from within an R script).\n\n  y &lt;- 1 + 5  # The assignment operator, &lt;-, will assign the values on the right-hand-side \n              # to a variable named y.\n\nTyping in the variable name in the R Console will print its content. Try this.\n\n  y\n\n[1] 6\n\n\nIt returns 6.\nNow write the following operation in your R script and execute it to create a different variable x.\n\n  x &lt;- 7\n\nCheck its content by typing the variable name, x, in the R Console.\n\n  x\n\n[1] 7\n\n\nIt returns 7. You can overwrite a variable by assigning a different number to the variable. Write the following operation in your R script and execute it.\n\n  x &lt;- 10\n\nNow your x should be changed to 10. Type in x in the R Console to confirm.\n\n  x\n\n[1] 10\n\n\nYou can apply mathematical operations on variables. For example, write the following operations — sqrt() to take a square root — in your R script and execute them.\n\n  y + x        # Because y = 6 & x = 10, this is 16.\n\n[1] 16\n\n  sqrt(y + x)  # This will take a square root of 16, which is 4.\n\n[1] 4\n\n\nYou may assign the result of a mathematical operation on variables to another variable. Write the following operations in your R script and execute them.\n\n  z &lt;- y + x  # z will be the result of y + x. Since y = 6 and x = 10, z = 16.\n\n  z           # Executing this from your R script is equivalent to typing in `z` into the R Console.\n\n[1] 16\n\n\n\n\n2.3.4 See What’s in Your Workspace (= Working Memory): ls() or objects()\nWhat you have created so far (called “objects”) in the current R session have been stored in the R’s working memory, called workspace. You can see what is available in your workspace by executing ls() or objects() without arguments (= nothing in the parentheses). objects() may be more intuitive because anything you construct in R is called an object.\nWrit the following functions in your R script and execute them.\n\n  objects()  # This function will list everything in your workspace.\n\n[1] \"anes2020\"     \"ces2019\"      \"ipe2010\"      \"ipe2015\"      \"us\"          \n[6] \"usstates2010\" \"x\"            \"y\"            \"z\"           \n\n\n\n  ls()       # This function does the same thing as the objects() function.\n\n[1] \"anes2020\"     \"ces2019\"      \"ipe2010\"      \"ipe2015\"      \"us\"          \n[6] \"usstates2010\" \"x\"            \"y\"            \"z\"           \n\n\nYou can also see what’s stored in your workspace at the Environment tab at the upper right pane.\n\nNote that everything you created and stored in your workspace will be gone, once you quit R. This is fine, as you can always recreate the objects you created in the current R session easily by running the functions recorded in your R script.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.5 Remove a Variable from Your Workspace: remove() or rm()\nIf you want to remove or erase a variable from your workspace, use remove() or its abbreviation rm(). For example, remove(x) or rm(x) will erase x from your workspace. Write the following function in your R script and execute it.\n\n  remove(x)   # This function will remove the variable `x` from your workspace.\n\nType in x in the R Console to see that this variable is not available anymore. The error message will suggest that the variable x cannot be found.\n\n\n2.3.6 Remove Everything: remove(list=ls()) or rm(list=ls())\nIf you want to remove everything from your workspace, you may use the following function. Write this function in your R script and execute it.\n\n  remove(list=ls())  # This will erase everything from your workspace.\n\nRun objects() or ls() to see that everything is gone. character{0} means there is nothing in your workspace.\n\n  ls()\n\ncharacter(0)\n\n\nMake sure you save your R script. This R script may be used as your reference in your later work.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Use of RStudio</span>"
    ]
  },
  {
    "objectID": "des1.html#footnotes",
    "href": "des1.html#footnotes",
    "title": "3  Descriptive Statistics (1)",
    "section": "",
    "text": "This variable is missing for these 45 respondents because they didn’t answer this question, didn’t know Truedeau, etc.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#assign-histogram-to-new-object-and-print-print",
    "href": "des1.html#assign-histogram-to-new-object-and-print-print",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.4 Assign Histogram to New Object and Print: print()",
    "text": "3.4 Assign Histogram to New Object and Print: print()\nYou can also assign your histogram to a new object and keep it in your R workspace (recall that the R workspace is a working memory in which the objects you created are stored).\n\n  hist_trudeau &lt;- ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\") +\n    scale_x_continuous(breaks = seq(0, 100, 10)) +\n    scale_y_continuous(breaks = seq(0, 1200, 200)) +\n    coord_cartesian(ylim = c(0, 1200))\n\nRecall that &lt;- is an assignment operator. In the above code, we assigned the ggplot() functions to a new object named hist_trudeau. You may have noticed that running the above code did not produce a histogram. Instead, the above code assigned the above chunk of functions to hist_trudeau and kept it in your R workspace. Run ls() or objects() to see that you have hist_trudeau as a new object in your R workspace.\n\n  ls()\n\n[1] \"anes2020\"     \"ces2019\"      \"hist_trudeau\" \"ipe2010\"      \"ipe2015\"     \n[6] \"usstates2010\"\n\n\nTo draw/produce a histogram using hist_trudeau, you may use the print() function with hist_trudeau as its argument.\n\n  print(hist_trudeau)\n\n\n\n\n\n\n\n\nOr you can simply type hist_trudeau.\n\n  hist_trudeau",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#erase-all-histograms-produced",
    "href": "des1.html#erase-all-histograms-produced",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.3 Erase All Histograms Produced",
    "text": "3.3 Erase All Histograms Produced\nIf you want to erase all the histograms you drew on the Plots tab on the lower right pane, you can delete all of them by using the dev.off() function without arguments.\n\n  dev.off()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#mean-and-median",
    "href": "des1.html#mean-and-median",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.5 Mean and Median",
    "text": "3.5 Mean and Median\nIn addition to visualization, we may want to compute some sample statistics (= numerical summaries of a variable). Let’s compute the mean and median of a variable using RStudio. We use the mean() and median() functions, respectively.\n\n3.5.1 Compute Mean and Median: mean(), median()\nLet’s compute the mean of the variable trudeau_therm_cps. The mean() function takes a variable name as their argument.\nAs trudeau_therm_cps is one column of the data frame ces2019, we need to use $ to access it — more specifically, we can refer to trudeau_therm_cps as ces2019$trudeau_therm_cps.\nIf you type in ces2019$trudeau_therm_cps in the R Console (try this), R will print the values of this variable (or the corresponding column of ces2019) in the Console. In general, the syntax to access a variable in a data frame is name-of-data-frame$name-of-variable. We connect the name of the data frame and the name of the variable by a dollar sign ($).\nThe mean() function takes the name of a variable specified this way as their argument. In addition, we should specify another argument, na.rm, as shown below.\n\n  mean(ces2019$trudeau_therm_cps, na.rm = TRUE)\n\n[1] 43.71655\n\n\nHere, na.rm means “remove NA.”\nIn R’s data frame, all missing values are recorded as NA. The na.rm = TRUE tells R to remove all missing values (NA) when it computes the mean of a variable by the mean() function.\nIf you don’t specify na.rm = TRUE and there are missing values (NA) in the variable of your choice, then R doesn’t compute the mean and instead returns NA as shown below.\n\n  mean(ces2019$trudeau_therm_cps)\n\n[1] NA\n\n\nSo, it is important to specify the na.rm argument in the mean() function.\n\n\n3.5.2 Compute Median: median()\nThe median() function takes the same arguments as the mean() function. The code below computes the median of trudeau_therm_cps.\n\n  median(ces2019$trudeau_therm_cps, na.rm = TRUE)\n\n[1] 50",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#assign-hist-new-object",
    "href": "des1.html#assign-hist-new-object",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.4 Assign Histogram to New Object and Print: print()",
    "text": "3.4 Assign Histogram to New Object and Print: print()\nYou can also assign your histogram to a new object and keep it in your R workspace (recall that the R workspace is a working memory in which the objects you created are stored).\n\n  hist_trudeau &lt;- ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\") +\n    scale_x_continuous(breaks = seq(0, 100, 10)) +\n    scale_y_continuous(breaks = seq(0, 1200, 200)) +\n    coord_cartesian(ylim = c(0, 1200))\n\nRecall that &lt;- is an assignment operator. In the above code, we assigned the ggplot() functions to a new object named hist_trudeau. You may have noticed that running the above code did not produce a histogram. Instead, the above code assigned the above chunk of functions to hist_trudeau and kept it in your R workspace. Run ls() or objects() to see that you have hist_trudeau as a new object in your R workspace.\n\n  ls()\n\n[1] \"anes2020\"     \"ces2019\"      \"hist_trudeau\" \"ipe2010\"      \"ipe2015\"     \n[6] \"usstates2010\"\n\n\nTo draw/produce a histogram using hist_trudeau, you may use the print() function with hist_trudeau as its argument.\n\n  print(hist_trudeau)\n\n\n\n\n\n\n\n\nOr you can simply type hist_trudeau.\n\n  hist_trudeau",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#mean-and-median-on-histogram",
    "href": "des1.html#mean-and-median-on-histogram",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.6 Mean and Median on Histogram",
    "text": "3.6 Mean and Median on Histogram\nNow that we know the mean and median of trudeau_therm_cps, let’s draw the lines corresponding to them on its histogram.\n\n3.6.1 Draw Vertical Lines for Mean and Median: geom_vline()\nWe computed above that the mean of trudeau_therm_cps is 43.72 and the median is 50. Let’s draw lines for these values on its histogram. We are going to draw a vertical line using the geom_vline() function.\nWe can add this function to the previous chunk of code that we stored in the object hist_trudeau in Section 3.4.\nThe xintercept argument is set to the value at which a vertical line is drawn, the linetype argument is the type of line to be used, and the color argument is the color of the line that you want to use. You can find the names of the line types used in R online, for example, here.\n\n  hist_trudeau2 &lt;- hist_trudeau + \n    geom_vline(xintercept = 43.72, linetype =  \"dashed\", color = \"red\") +\n    geom_vline(xintercept = 50, linetype = \"solid\", color = \"blue\")\n  print(hist_trudeau2)\n\n\n\n\n\n\n\n\nNote that in the above code, we created a new object hist_trudeau2, which updates the ggplot() functions in hist_trudeau with the geom_vline() function, and then used the print() function to draw this new histogram.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#sec-assign-hist-new-object",
    "href": "des1.html#sec-assign-hist-new-object",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.4 Assign Histogram to New Object and Print: print()",
    "text": "3.4 Assign Histogram to New Object and Print: print()\nYou can also assign your histogram to a new object and keep it in your R workspace (recall that the R workspace is a working memory in which the objects you created are stored).\n\n  hist_trudeau &lt;- ggplot(ces2019, aes(trudeau_therm_cps)) + \n    geom_histogram(boundary=0, binwidth = 10, fill = \"palegreen\", color = \"black\") +\n    labs(title=\"Feelings about JUSTIN TRUDEAU\") +\n    ylab(\"Number of Observations\") +\n    xlab(\"\") +\n    scale_x_continuous(breaks = seq(0, 100, 10)) +\n    scale_y_continuous(breaks = seq(0, 1200, 200)) +\n    coord_cartesian(ylim = c(0, 1200))\n\nRecall that &lt;- is an assignment operator. In the above code, we assigned the ggplot() functions to a new object named hist_trudeau. You may have noticed that running the above code did not produce a histogram. Instead, the above code assigned the above chunk of functions to hist_trudeau and kept it in your R workspace. Run ls() or objects() to see that you have hist_trudeau as a new object in your R workspace.\n\n  ls()\n\n[1] \"anes2020\"     \"ces2019\"      \"hist_trudeau\" \"ipe2010\"      \"ipe2015\"     \n[6] \"usstates2010\"\n\n\nTo draw/produce a histogram using hist_trudeau, you may use the print() function with hist_trudeau as its argument.\n\n  print(hist_trudeau)\n\n\n\n\n\n\n\n\nOr you can simply type hist_trudeau.\n\n  hist_trudeau",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#add-texts-to-histogram-annotatetext",
    "href": "des1.html#add-texts-to-histogram-annotatetext",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.7 Add Texts to Histogram: annotate(\"text\")",
    "text": "3.7 Add Texts to Histogram: annotate(\"text\")\nWe can also add texts to a histogram with the annotate() function. This function annotates a histogram with several different elements, one of which is texts. To add texts to our histogram, we specify the first argument of the annotate() function as \"text\". The function also takes the x and y arguments, which specifies the location of the texts, and the label argument, which specifies the content of the texts we want to add. The values of the x and y arguments are from the values of the Y-axis (the vertical axis) and the X-axis (the horizontal axis) of the histogram we have drawn. Recall that in our histogram about the Justin Trudeau thermometer variable, the values of the Y-axis range from 0 to 1200 and those of the X-axis range from 0 to 100. Based on these values, the x and y arguments determine the location of the center of the texts. I also added the color argument to specify the text color.\n\n  hist_trudeau3 &lt;- hist_trudeau2 +   \n    annotate(\"text\", x = 80, y = 1100, label = \"Mean = 43.72\", color = \"red\") +\n    annotate(\"text\", x = 80, y =  900, label = \"Median = 50\", color = \"blue\")\n  print(hist_trudeau3)\n\n\n\n\n\n\n\n\nBelow, I tried other values for the x and y arguments to demonstrate how the texts move. As you can see, the text for the median is now outside the range of the histogram. I’d suggest you try other values for the x and y arguments to see how the location of the texts changes.\n\n  hist_trudeau3 &lt;- hist_trudeau2 +   \n    annotate(\"text\", x = 20, y = 1200, label = \"Mean = 43.72\", color = \"red\") +\n    annotate(\"text\", x = 95, y =  700, label = \"Median = 50\", color = \"blue\")\n  print(hist_trudeau3)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#practice",
    "href": "des1.html#practice",
    "title": "3  Descriptive Statistics (1)",
    "section": "3.8 Practice",
    "text": "3.8 Practice\nDraw a histogram of the variable growth_WDI_PW from the ipe2015 data frame. Look it up in the dataset’s codebook (ipe2010&2015_codebook.pdf) available on the class Quercus site to find what this variable is. Edit the histogram so that it appears easily interpretable. For example, add a title and labels on the Y-axis and X-axis, such as “Number of Observations,” and choose an appropriate bin width that makes the histogram easily interpretable. Also, add the mean to the histogram.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des1.html#sec-preparation",
    "href": "des1.html#sec-preparation",
    "title": "3  Descriptive Statistics (1)",
    "section": "",
    "text": "3.1.1 Launch RStudio\n\nLaunch RStudio. Recall that you don’t need to launch R because RStudio quietly opens R behind its GUI.\nIf you use RStudio on JupyterHub and don’t remember how to use it, see ?sec-jupyterhub.\n\n\n\n3.1.2 Load POL232..RData\n\nMake sure you load POL232.RData into your current R session. If you forget how to load POL232.RData into your current R session, see ?sec-load-dataset.\nIf you use RStudio on JupyterHub or your own computer, you are likely to have already downloaded and stored POL232.RData in your local folder either on your JupyterHub account or your own computer.\nHowever, if you use RStudio on a lab computer in SS 561, you first need to download POL232.RData from the class Quercus site because everything you saved on the lab computer is gone once you logged out from it.\n\n\n\n3.1.3 Prepare R Script\n\nI suggest you write everything you do in RStudio in an R script and run R functions from within the R script. If you need a refresher for R script, read ?sec-rscript and ?sec-write-rscript.\nFor the current purpose, start a new R script and name it “POL232_Lab#_YourLastName.R” in which # is the number of the current lab session (e.g., POL232_Lab2_YourLastName.R, POL232_Lab3_YourLastName.R). See ?sec-new-rscript for how to start a new R script.\n\n\n\n3.1.4 Load Packages\n\nFor the current chapter, you also need to load tidyverse package into your current R session (?sec-load-packages).\n\n\n  library(tidyverse)\n\n\nIf you don’t know about or forget about R packages, read ?sec-rpackages.\nIf library(tidyverse) returns an error message suggesting there is no package called 'tidyverse', this means that tidyverse is not installed on your computer. In this case, you first need to install it. See ?sec-install-packages for how to dowonload and install R packages.\n\n\n\n3.1.5 Actually Write R Functions\n\nI suggest you actually write the R functions used below in your R script instead of copying and pasting them. By actually writing them and occasionally making mistakes and correcting them, you can get used to how RStudio works more quickly and effectively.\nIf you simply copy and paste them, you will not learn much about RStudio and will not get used to it.\nIn your R script, leave sufficient descriptions of the functions after the # sign (see ?sec-r-comments) so that you can use your R script later as your reference when you conduct analysis using these R functions.\nThese descriptions are notes for yourself. Organize these descriptions/notes so that they are convenient for your futur use.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Descriptive Statistics (1)</span>"
    ]
  },
  {
    "objectID": "des2.html",
    "href": "des2.html",
    "title": "4  Descriptive Statistics (2)",
    "section": "",
    "text": "4.1 Preparation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "des2.html#preparation",
    "href": "des2.html#preparation",
    "title": "4  Descriptive Statistics (2)",
    "section": "",
    "text": "4.1.1 Before You Start\nBefore you start working on this chapter, you need to do the following. If you need a help for each step, see Section 3.1.\n\nLaunch RStudio.\nLoad POL232.RData into your current R session.\nPrepare an R Script to save all your work in this chapter. I suggest you name it “POL232_Lab#_YourLastName.R” in which # is the number of the current lab session.\nYou also need to load tidyverse package into your current R session (?sec-load-packages).\n\n\n  library(tidyverse)\n\n\n\n4.1.2 Actually Write R Functions\nI repeat below the suggestions I made in Section 3.1.5.\n\nI suggest you actually write the R functions used below in your R script instead of copying and pasting them. By actually writing them and occasionally making mistakes and correcting them, you can get used to how RStudio works more quickly and effectively.\nIf you simply copy and paste them, you will not learn much about RStudio and will not get used to it.\nIn your R script, leave sufficient descriptions of the functions after the # sign (see ?sec-r-comments) so that you can use your R script later as your reference when you conduct analysis using these R functions.\nThese descriptions are notes for yourself. Organize these descriptions/notes so that they are convenient for your futur use.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "basic.html#when-you-quit-r-quit-or-q-dont-save-workspace-images",
    "href": "basic.html#when-you-quit-r-quit-or-q-dont-save-workspace-images",
    "title": "2  Basic Use of RStudio",
    "section": "2.4 When You Quit R: quit() or q() — Don’t Save Workspace Images",
    "text": "2.4 When You Quit R: quit() or q() — Don’t Save Workspace Images\nYou may quit R by typing quit() or q() in the R Console or choose “File” \\(\\rightarrow\\) “Quit Session…”\n\n  quit()\n\n  q()\n\nWhen you quit, you may be asked the following question.\n\nIf you are NOT asked this question, then that is fine. You can skip the following. Since this question is no longer asked in the recent versions of RStudio Desktop, you may not see this question when you quit your R session.\nHowever, I want to give the following explanations in case you encounter this question when you quit your R session, because this is a default behaviour of R, which is run quietly behind RStudio. There may be an occasion in which you will see this question.\nBy clicking “Save,” you can save all your R session in a workspace image (.RData file) and can open it the next time you start R.\nHowever, I do NOT recommend using this option. It is much better to record all your work in an R script and replicate all your work by executing the R script.\nUsing R scripts allows you to correct your mistakes easily, and all the steps of your work will be transparent. You may also allow others to replicate your work by running your R script.\nAlways choose “Don’t Save” when you quit R and write an R script instead.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Use of RStudio</span>"
    ]
  },
  {
    "objectID": "des2.html#bar-chart-ggplot-geom_bar",
    "href": "des2.html#bar-chart-ggplot-geom_bar",
    "title": "4  Descriptive Statistics (2)",
    "section": "4.2 Bar Chart: ggplot() + geom_bar()",
    "text": "4.2 Bar Chart: ggplot() + geom_bar()\nIn Chapter 3, we learned how to draw a histogram using the ggplot() function.\nA histogram is an appropriate visualization if the variable of interest takes many values and/or is continuous. If the variable takes only a small number of values and/or is categorical, a bar chart may be more appropriate. Let’s draw a bar chart for the variable on the respondent’s perception of economy (percep_economy_cps) from the Canadian Election Study 2019 (ces2019).\nTo draw a bar chart, we augment the ggplot() function with the geom_bar() function (as opposed to the geom_histogram() function we used to draw a histogram).\nFirst, try the simplest implementation of these functions as shown below.\n\n  ggplot(ces2019, aes(percep_economy_cps)) + geom_bar()\n\n\n\n\n\n\n\n\nWe can apply many of the additional arguments and functions we learned for a histogram to a bar chart. Let’s see an example.\n\n  bar_econ &lt;- ggplot(ces2019, aes(percep_economy_cps)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n  print(bar_econ)\n\n\n\n\n\n\n\n\nNote that in the above code, I assigned the ggplot() functions for a bar chart to a new object bar_econ and then used the print() function to draw it.\nTry to identify what each line of the above code accomplishes. If you need a refresher, see Chapter 3. You can also use a keyword search over the entire webbook from the left menu.\nBy the way, as we saw in Section 3.4, instead of using the print()function, you can also simply type in bar_econ in the R Console to run the ggplot() functions assigned to bar_econ.\n\n  bar_econ\n\n\n\n\n\n\n\n\n\n4.2.1 Change Angle of Value Labels on X Axis: theme(), axis.text.x, element_text()\nIn the X-axis of the above bar chart, notice that the names of the categories (or values) of the variable cannot be read because of an overlap. This is because the names are too long to be properly displayed in a horizontal direction.\nWe can change the angle of the names of the categories (or values) of a variable (= value labels of a variable) by the theme function as shown below.\n\n  bar_econ +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nIf you specify a different number to angle, then value labels are presented in a different angle. For example, try the following.\n\n  bar_econ +\n    theme(axis.text.x = element_text(angle = 60))\n\n\n\n\n\n\n\n\nWe may want to edit this bar chart further. First, instead of “Better,” “Worse,” and “About the Same” in the above bar chart, we may want to re-order them from “Worse,” “About the Same” to “Better.” Second, we may want to change the name of the categories — more specifically, we may want to remove the numbers and parentheses and shorten the name from “About the same” to “same.” Third, we may want to remove “NA” from the bar chart.\nWe will do these edits one by one.\n\n\n4.2.2 NA: Missing Observations\nBy the way, NA indicates the observations for which the variable of interest is missing. We call such observations “missing observations” and those NAs “missing values.”\nTo know more about missing observations, browse ces2019 using the View() function or clicking ces2019 in the Environment tab on the upper right pane.\n\n  View(ces2019)\n\nThen, you can find that for some observations, the values of some variables are NA, as shown below. These entries (NAs) indicate that the values of these variables are missing for these observations.\n\nThe ggplot() + geom_bar() functions include these missing observations in the bar chart they draw. However, we may want to exclude these missing observations from the bar chart.\n\n\n4.2.3 Factor for Categorical Variables: glimpse()\nDepending on their characteristics, variables in a data frame may be stored in different formats in R. Normally, our dataset includes both quantitative (or numeric) variables, which take numbers (numerical values), and categorical variables, which take a set of categories. Of the variables from ces2019 that we have examined so far, the Trudeau thermometer (truedeau_therm_cps) is a quantitative (or numeric) variable, as it takes a number between 0 and 100. Respondent’s perception of the state of the national economy (percep_economy_cps) is a categorical variable, as it takes three categories indicating the respondents’ perception of economy. These two types of variables are stored in different formats in a data frame.\nTo see different formats for variables, try the glimpse() function below with the name of a data frame as its argument.\n\n  glimpse(ces2019)\n\n\n\nRows: 4,021\nColumns: 5\n$ sample_id         &lt;dbl&gt; 18, 32, 39, 59, 61, 69, 157, 158, 165, 167, 185, 220…\n$ birth_year        &lt;dbl&gt; 1963, 1973, 1994, 2000, 1984, 1939, 1999, 1995, 1963…\n$ gender            &lt;fct&gt; (1) Male, (1) Male, (1) Male, (1) Male, (1) Male, (1…\n$ province          &lt;fct&gt; QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, …\n$ satisfied_dem_cps &lt;fct&gt; (3) Not very satisfied, (2) Fairly satisfied, (1) Ve…\n\n\nYour R Console prints a list like the one above for all variables in ces2019. For brevity, I printed only the first five variables above. As its name suggests, the glimpse() function offers a glimpse into your data frame — names of variables, their format, and the values of the first few observations.\nIn this list, you can see that the format1 of the variables are either &lt;dbl&gt; or &lt;fct&gt;.\n&lt;dbl&gt; is for numeric (or quantitative) variables,2 for which each value is number, and &lt;fct&gt; is for categorical variables, which is stored in a format called factor. For example, sample_id and birth_year are numbers (numeric variables), hence they are given &lt;dbl&gt; in the list above. gender, province, and satisfied_dem_cps are categorical variables, and the list above indicates &lt;fct&gt; for these variables. A factor is a special format for categorical variables in R, which offers convenient functionalities for this type of variable. We will use these functionalities of factor to edit percep_eonomy_cps.\n\n\n4.2.4 Create New Variable: mutate(), head()\nSuppose we want to create a new variable for which the order of categories of percep_economy_cps will appear from “Worse,” “Same” to “Better” when we draw a bar chart.\nWe will create such a variable step by step in the next few sections.\nIn this section, I will explain how we can create a new variable in our data frame. For simplicity, we will create a new variable percep_economy_cps_copy which is exactly the same as percep_economy_cps. We can do this by the mutate() function.\n\n  ces2019 &lt;- mutate(ces2019, \n              percep_economy_cps_copy = percep_economy_cps)\n\nThe first argument of the mutate() function is the data frame to which we want to add a new variable. Its second argument specifies the content of this new variable by name-of-new-variable = its-content. In the above code, it is specified that the new variable percep_economy_cps_copy equals percep_economy_cps.\nThe right hand side of &lt;- (the assignment operator3, see Section 2.3.3) in the above code mutated the data frame ces2019 by adding a new variable percep_economy_cps_copy. Then, this new, mutated data frame is assigned to ces2019 on the left hand side of &lt;-. In other words, ces2019 is now updated with an additional variable percep_economy_cps_copy.\nCheck if the new variable percep_economy_cps_copy is added to your data frame using the glimpse() function. If you apply the glimpse() function to ces2019, now you can see this new variable percep_economy_cps_copy at the end of the data frame. For brevity, I show only percep_economy_cps and percep_economy_cps_copy below. They are exactly the same.\n\n  glimpse(ces2019)\n\n\n\nRows: 4,021\nColumns: 2\n$ percep_economy_cps      &lt;fct&gt; (2) Worse, (3) About the same, (1) Better, (3)…\n$ percep_economy_cps_copy &lt;fct&gt; (2) Worse, (3) About the same, (1) Better, (3)…\n\n\nWe can also use the head() function to see the first few observations of a variable. Try the code below.\n\n  head(ces2019$percep_economy_cps)\n\n[1] (2) Worse          (3) About the same (1) Better         (3) About the same\n[5] (1) Better         (2) Worse         \nLevels: (1) Better (2) Worse (3) About the same\n\n  head(ces2019$percep_economy_cps_copy)\n\n[1] (2) Worse          (3) About the same (1) Better         (3) About the same\n[5] (1) Better         (2) Worse         \nLevels: (1) Better (2) Worse (3) About the same\n\n\nAs you can see, the values for each observation are exactly the same between percep_economy_cps and percep_economy_cps_copy.\nBy specifying the right hand side of = in the second argument of the mutate() function in different ways, we can create different types of new variables.\nThe mutate() function may also be used to edit the existing variables in our data frame.\nWe will see a few examples in this chapter and subsequent chapters.\n\n\n4.2.5 Change Levels of Factor: levels(), fct_relevel()\nLet’s explore the characteristics of factor a little further.\nWhen categorical variables are stored as factor in R, they are associated with levels, which represent the name of each category, such as “(1) Better” and “(2) Worse”, and assigns a specific order to these categories.\nYou can find levels of categorical variables stored as factor by the levels() function with the name of the variable as its argument.\nRecall that as percep_economy_cps is one column of the data frame ces2019, we use $ to access it — more specifically, we refer to percep_economy_cps as ces2019percep_economy_cps.\n\n  levels(ces2019$percep_economy_cps)\n\n[1] \"(1) Better\"         \"(2) Worse\"          \"(3) About the same\"\n\n\nThe output lists the three categories, or levels, taken by percep_economy_cps. Also, these levels are associated with the order that appears above. So, if we draw a bar chart of this variable, bars are ordered by this order associated with levels.\n\n  ggplot(ces2019, aes(percep_economy_cps)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\") +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nBars appeared from “(1) Better”, “(2) Worse”, to “(3) About the same”. To change the order of bars, we need to change the order of levels for percep_econ_cps. We can do this by the fct_relevel() function.\nA basic syntax of the fct_relevel() function is the following. Don’t execute the code below because it is not intended to be implemented; it is used only to show the syntax of this R function.\n\n      fct_relevel( factor_variable, \n          \"First Level\", \"Second Level\", \"Third Level\")\n\nThe first argument of the fct_relevel() function is the categorical variable stored as factor that we want to “relevel” (i.e., change the order of categories).\nThen, it is followed by the levels or categories of this variable in the order we want.\nBelow, I use the mutate() function to create a new variable percep_economy_cps2 in which percep_economy_cps is releveled or reordered.\n\n  ces2019 &lt;- mutate(ces2019, \n      percep_economy_cps2 = fct_relevel(percep_economy_cps, \n          \"(2) Worse\", \"(3) About the same\", \"(1) Better\") )\n\nAs we saw in the previous section, the mutate() function on the right hand side of &lt;- creates a new variable percep_economy_cps2 in the data frame ces2019. In its second argument, the fct_relevel() function is used to specify the content of the new variable. By this fct_relevel() function, percep_economy_cps2 equals percep_economy_cps but with different ordering of its levels or categories. The order of the levels or categories of percep_economy_cps2 is now from “(2) Worse” to “(3) About the same” to “(1) Better”.\nBy the above code, ces2019 is now updated with an additional variable percep_economy_cps2, with the desired order of its levels or categories. Let’s check that the new variable percep_economy_cps2 is releveled or reordered as we wanted using the levels() function.\n\n  levels(ces2019$percep_economy_cps2)\n\n[1] \"(2) Worse\"          \"(3) About the same\" \"(1) Better\"        \n\n\nThe variable is indeed releveled or reordered as we specified.\nLet’s draw a bar chart for this releveled variable.\n\n  ggplot(ces2019, aes(percep_economy_cps2)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\") +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nNow the bars appeared in the order we wanted.\n\n\n4.2.6 Change Names of Categories/Levels: fct_recode()\nNext we will remove numbers, such as (1) and (2), from each category of percep_economy_cps2 and change “About the Same” to “Same.” Specifically, we will create a new variable named percep_economy_cps3 with our desired names of levels or categories of percep_economy_cps2. For this purpose, we use the fct_recode() function. A basic syntax of the fct_recode() function is as follows. Once again, don’t implement the code below, as it is not intended to be implemented; it is used only to show a syntax of this R function).\n\nfct_recode(factor_variable, \n              \"New Name of Level 1\" = \"Original Name of Level 1\", \n              \"New Name of Level 2\" = \"Original Name of Level 2\", \n              \"New Name of Level 3\" = \"Original Name of Level 3\") \n\nLet’s create a new variable percep_economy_cps3 using this function.\n\n  ces2019 &lt;- mutate(ces2019, \n      percep_economy_cps3 = fct_recode(percep_economy_cps2, \n                                \"Worse\" = \"(2) Worse\", \n                                \"Same\" = \"(3) About the same\", \n                                \"Better\" = \"(1) Better\") )\n\nThis code adds a new variable percep_eocnomy_cps3 to ces2019. The first argument of the fct_recode() function above is the name of the variable whose levels or categories are changed (precep_economy_cps2). The following arguments specify the new name of each level and the old name of each level.\nLet’s check the levels of percep_economy_cps3 by the levels() function to see whether the names of levels or categories were changed as specified.\n\n  levels(ces2019$percep_economy_cps3)\n\n[1] \"Worse\"  \"Same\"   \"Better\"\n\n\nThe names of levels or categories were indeed changed as we wanted.\nLet’s draw a histogram using this new variable.\n\n  ggplot(ces2019, aes(percep_economy_cps3)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nThe bar chart looks much better now. Note that we didn’t need to use theme(axis.text.x = element_text(angle = 90)) anymore in the above code, because the names of categories are short enough to appear horizontally.\n\n\n4.2.7 Remove NA: drop_na()\nNow we will remove NA from the bar chart. For this purpose, we use the drop_na() function. A basic syntax of the drop_na() function is this (the code below is not intended to be implemented).\n\n  drop_na(name_of_data_frame, name_of_variable)\n\nThe first argument is the name of the data frame from which we want to remove missing observations, and the second argument is the name of the variable for which we want to eliminate missing observations.\nIn other words, the drop_na() function looks for the observations for which the variable in the second argument is missing (NA) and removes these observations from the data frame in the first argument.\nTherefore, if we specify the drop_na() function as below, then the drop_na() function looks for the observations in ces2019 for which percep_economy_cps3 is missing (NA), and removes these observations from ces2019.\n\n  drop_na(ces2019, percep_economy_cps3)\n\nTo draw a bar chart of percep_economy_cps3, we may replace ces2019 in the first argument of the ggplot() function with drop_na(ces2019, percep_economy_cps3). In this way, the ggplot() function will use a version of ces2019 from which the observations with percep_economy_cps3 missing are removed. Let’s try this.\n\n  ggplot(drop_na(ces2019, percep_economy_cps3), aes(percep_economy_cps3)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nNow we were able to draw a bar chart without NA.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "des2.html#footnotes",
    "href": "des2.html#footnotes",
    "title": "4  Descriptive Statistics (2)",
    "section": "",
    "text": "Here I use the term “format” loosely. There are more precise technical terms, such as “type” and “class”, to refer to the characteristics of R objects, but I don’t use them to avoid unnecessary technical details.↩︎\n&lt;dbl&gt; stands for “double-precision,” which refers to the level of precision of numbers stored in a variable. For our purposes, you just need to understand that &lt;dbl&gt; is for a numeric variable.↩︎\nRecall that the assignment operator (&lt;-) assigns the right hand side of &lt;- to the left hand side of &lt;-.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "des2.html#computing-summary-statistics",
    "href": "des2.html#computing-summary-statistics",
    "title": "4  Descriptive Statistics (2)",
    "section": "4.3 Computing Summary Statistics",
    "text": "4.3 Computing Summary Statistics\n\n4.3.1 Standard Deviation and IQR: sd(), IQR()\nIn Chapter 3, we computed the mean and the median of a variable using the mean() and median() functions. Here I introduce the sd() and IQR() functions to compute the standard deviation and IQR of a variable.\nA basic syntax of the sd() and IQR() functions is the same as the mean() and median() functions. The first argument of these functions is the variable for which we want to compute this summary statistic. We should also specify na.rm = TRUE (na.rm stands for “remove NA”). Otherwise, these functions do not compute the summary statistics if there are missing observations for the specified variable.\nBelow I compute the standard deviation and IQR for the Trudeau thermometer variable (trudeau_therm_cps) in ces2019.\n\n  sd(ces2019$trudeau_therm_cps, na.rm = TRUE)\n\n[1] 30.68348\n\n\n\n  IQR(ces2019$trudeau_therm_cps, na.rm = TRUE)\n\n[1] 60\n\n\nThe standard deviation of the Trudeau thermometer (trudeau_therm_cps) is approximately 31, and its IQR is 60.\n\n\n4.3.2 Mode for Categorical Variables\nNote that the mean(), median(), sd(), and IQR() functions work for quantitative or numeric variables, such as trudeau_therm_cps, but do not work for categorical variables or factors, such as percep_economy_cps. Let’s try the mean() function for percep_economy_cps.\nWe will get NA and an error message saying that we cannot compute this summary statistic for categorical variables or factors.\n\n  mean(ces2019$percep_economy_cps, na.rm = TRUE)\n\nWarning in mean.default(ces2019$percep_economy_cps, na.rm = TRUE): argument is\nnot numeric or logical: returning NA\n\n\n[1] NA\n\n\nIn fact, while these summary statistics are useful and appropriate for quantitative or numeric variables, they may not be useful or appropriate for categorical variables.\nEspecially for nominal, categorical variables, neither the mean nor the median makes sense. For example, consider the variable on individual’s vote intention, in which the possible choices are Liberals, Conservative, NDP, BQ, Greens, and others. It is impossible to conceptualize the average of this variable. As there is no natural order among these choices, we cannot conceptualize the median for this variable, either. Instead, an appropriate summary statistic for the center of distribution for nominal, categorical variables like this one is the mode.\nThe mode is also an appropriate summary of the center of distribution for ordinal categorical variables. In addition, the median is useful for ordinal variables, because there is a natural order among the categories of this type of variables.\nThe mode of a categorical variable may easily be identified from a bar chart. Consider the bar chart of percep_economy_cps that we drew above.\n\n\n\n\n\n\n\n\n\nAs the mode is the category with the largest number of observations, we can easily identify “Same” as the mode for this variable.\n\n\n4.3.3 Median for Ordinal Catagorical Variables — Change Factor to Numeric: as.numeric()\npercep_economy_cps is an ordinal, categorical variable because there is a natural order among each category from “Worse” to “Same” to “Better.” Therefore, we may also want to find the median for this variable. As we have seen, however, the median() function does not work for a categorical variable stored as a factor. Therefore, to apply the median() function to an ordinal, categorical variable, we first need to transform the categorical variable stored as a factor to a numeric variable. We use the as.numeric() function for this purpose. We specify the name of the variable which we want to transform to a numeric variable as the argument for the as.numeric() function.\nLet’s create a numeric version of percep_economy_cps using the mutate() and the as.numeric() functions. In the code below, I call the new variable percep_ceonomy_cps_n, in which n stands for a numeric variable.\n\n  ces2019 &lt;- mutate(ces2019, \n                  percep_economy_cps_n = as.numeric(percep_economy_cps3))\n\nLet’s compare percep_economy_cps3 and percep_economy_cps_n. Below I show the first few observations of each variable, respectively, by the glimpse() function.\n\n  glimpse(ces2019)\n\n\n\nRows: 4,021\nColumns: 2\n$ percep_economy_cps3  &lt;fct&gt; Worse, Same, Better, Same, Better, Worse, NA, Bet…\n$ percep_economy_cps_n &lt;dbl&gt; 1, 2, 3, 2, 3, 1, NA, 3, 2, 2, 1, 2, 2, 2, 1, 3, …\n\n\nYou may also use the head() function to check the first few observations of percep_economy_cps3 and percep_economy_cps_n.\n\n  head(ces2019$percep_economy_cps3)\n\n[1] Worse  Same   Better Same   Better Worse \nLevels: Worse Same Better\n\n  head(ces2019$percep_economy_cps_n)\n\n[1] 1 2 3 2 3 1\n\n\nAs you can see above, now each category is replaced by numbers from 1 to 3 in percep_economy_cps_n. More specifically, percep_economy_cps_n equals 1 for “Worse”, 2 for “Same”, and 3 for “Better.”\nThese numbers correspond to the order of categories or levels in percep_economy_cps3. Let’s check the order of levels in percep_economy_cps.\n\n  levels(ces2019$percep_economy_cps3)\n\n[1] \"Worse\"  \"Same\"   \"Better\"\n\n\nAs demonstrated in this example, if we apply the as.numeric() function to a categorical variable stored as a factor to transform it to a numeric variable, the numbers that appear in the resulting variable is in the order of the levels of the original categorical variable stored as a factor.\nSince percep_economy_cps_n is a numeric variable, we can apply the functions for summary statistics for numeric variables. For example, we can use the median() function to find the median category for percep_economy_cps_n.\n\n  median(ces2019$percep_economy_cps_n, na.rm = TRUE)\n\n[1] 2\n\n\nThe median we got above is 2. Since percep_economy_cps_n = 2 if percep_economy_cps3 = “Same,” the median of the perception of economy is “Same.”",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "des2.html#mode-for-categorical-variables",
    "href": "des2.html#mode-for-categorical-variables",
    "title": "4  Descriptive Statistics (2)",
    "section": "4.4 Mode for Categorical Variables",
    "text": "4.4 Mode for Categorical Variables\nNote that the mean(), median(), sd(), and IQR() functions work for quantitative or numeric variables, such as trudeau_therm_cps, but do not work for categorical variables or factors, such as percep_economy_cps. Let’s try the mean() function for percep_economy_cps.\nWe will get NA and an error message saying that we cannot compute this summary statistic for categorical variables or factors.\n\n  mean(ces2019$percep_economy_cps, na.rm = TRUE)\n\nWarning in mean.default(ces2019$percep_economy_cps, na.rm = TRUE): argument is\nnot numeric or logical: returning NA\n\n\n[1] NA\n\n\nIn fact, while these summary statistics are useful and appropriate for quantitative or numeric variables, they may not be useful or appropriate for categorical variables.\nEspecially for nominal, categorical variables, neither the mean nor the median makes sense. For example, consider the variable on individual’s vote intention, in which the possible choices are Liberals, Conservative, NDP, BQ, Greens, and others. It is impossible to conceptualize the average of this variable. As there is no natural order among these choices, we cannot conceptualize the median for this variable, either. Instead, an appropriate summary statistic for the center of distribution for nominal, categorical variables like this one is the mode.\nThe mode is also an appropriate summary of the center of distribution for ordinal categorical variables. In addition, the median is useful for ordinal variables, because there is a natural order among the categories of this type of variables.\nThe mode of a categorical variable may easily be identified from a bar chart. Consider the bar chart of percep_economy_cps that we drew above.\n\n\n\n\n\n\n\n\n\nAs the mode is the category with the largest number of observations, we can easily identify “Same” as the mode for this variable.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "des2.html#median-for-ordinal-catagorical-variables-change-factor-to-numeric-as.numeric",
    "href": "des2.html#median-for-ordinal-catagorical-variables-change-factor-to-numeric-as.numeric",
    "title": "4  Descriptive Statistics (2)",
    "section": "4.5 Median for Ordinal Catagorical Variables — Change Factor to Numeric: as.numeric()",
    "text": "4.5 Median for Ordinal Catagorical Variables — Change Factor to Numeric: as.numeric()\npercep_economy_cps is an ordinal, categorical variable because there is a natural order among each category from “Worse” to “Same” to “Better.” Therefore, we may also want to find the median for this variable. As we have seen, however, the median() function does not work for a categorical variable stored as a factor. Therefore, to apply the median() function to an ordinal, categorical variable, we first need to transform the categorical variable stored as a factor to a numeric variable. We use the as.numeric() function for this purpose. We specify the name of the variable which we want to transform to a numeric variable as the argument for the as.numeric() function.\nLet’s create a numeric version of percep_economy_cps using the mutate() and the as.numeric() functions. In the code below, I call the new variable percep_ceonomy_cps_n, in which n stands for a numeric variable.\n\n  ces2019 &lt;- mutate(ces2019, \n                  percep_economy_cps_n = as.numeric(percep_economy_cps3))\n\nLet’s compare percep_economy_cps3 and percep_economy_cps_n. Below I show the first few observations of each variable, respectively, by the glimpse() function.\n\n  glimpse(ces2019)\n\n\n\nRows: 4,021\nColumns: 2\n$ percep_economy_cps3  &lt;fct&gt; Worse, Same, Better, Same, Better, Worse, NA, Bet…\n$ percep_economy_cps_n &lt;dbl&gt; 1, 2, 3, 2, 3, 1, NA, 3, 2, 2, 1, 2, 2, 2, 1, 3, …\n\n\nYou may also use the head() function to check the first few observations of percep_economy_cps3 and percep_economy_cps_n.\n\n  head(ces2019$percep_economy_cps3)\n\n[1] Worse  Same   Better Same   Better Worse \nLevels: Worse Same Better\n\n  head(ces2019$percep_economy_cps_n)\n\n[1] 1 2 3 2 3 1\n\n\nAs you can see above, now each category is replaced by numbers from 1 to 3 in percep_economy_cps_n. More specifically, percep_economy_cps_n equals 1 for “Worse”, 2 for “Same”, and 3 for “Better.”\nThese numbers correspond to the order of categories or levels in percep_economy_cps3. Let’s check the order of levels in percep_economy_cps.\n\n  levels(ces2019$percep_economy_cps3)\n\n[1] \"Worse\"  \"Same\"   \"Better\"\n\n\nAs demonstrated in this example, if we apply the as.numeric() function to a categorical variable stored as a factor to transform it to a numeric variable, the numbers that appear in the resulting variable is in the order of the levels of the original categorical variable stored as a factor.\nSince percep_economy_cps_n is a numeric variable, we can apply the functions for summary statistics for numeric variables. We can use the median() function to find the median category for percep_economy_cps_n.\n\n  median(ces2019$percep_economy_cps_n, na.rm = TRUE)\n\n[1] 2\n\n\nThe median we got above is 2. Since percep_economy_cps_n = 2 if percep_economy_cps3 = “Same,” the median of the perception of economy is “Same.”",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "des2.html#box-plot-geom_boxplot",
    "href": "des2.html#box-plot-geom_boxplot",
    "title": "4  Descriptive Statistics (2)",
    "section": "4.4 Box Plot: geom_boxplot()",
    "text": "4.4 Box Plot: geom_boxplot()\nIn this section, we are going to use the ipe2015 dataset. We will draw a box plot of trade_WDI, which is a volume of trade (export + import) as % of GDP across countries around the world.\nTo draw a box plot, we add the geom_boxplot() function to the ggplot() function. Below is the simplest implementation without any arguments for the geom_boxplot() function.\n\n  ggplot(ipe2015, aes(trade_WDI)) + \n    geom_boxplot()\n\n\n\n\n\n\n\n\nAs we can see, the default option of the geom_boxplot() function produces a horizontal box plot. Let’s change it to a vertical box plot. For this purpose, we should specify y = trade_WDI in the aes() function inside the ggplot() function. This instructs the ggplot() function that the values of trade_WDI should appear in the vertical or y axis.\n\n  ggplot(ipe2015, aes(y = trade_WDI)) +              # Add \"y =\". \n    geom_boxplot()\n\n\n\n\n\n\n\n\nThe box in this boxplot may be too wide. It would look better if we can make it thinner. Below I added two new arguments: x = factor(0) in the aes() function and width = 0.2 in the geom_boxplot() function. The width argument in the geom_boxplot() function controls the width of the box. To let this argument work, you also need to specify x = factor(0) in the aes() function. You may change the width of the box further by specifying a different value for the width argument for the geom_boxplot function. I’d suggest you try a few different values to see how the box width changes.\n\n  ggplot(ipe2015, aes(y = trade_WDI, x = factor(0))) +  # Add x = factor(0). \n    geom_boxplot(width = 0.2)                           # Specify the width argument.\n\n\n\n\n\n\n\n\nAs suggested in the lecture, a default length of whisker is 1.5 times IQR. While this length of whisker looks good to this box plot, let’s change it to see how it appears differently. For this purpose, we specify the coef argument in the geom_boxplot() function. We specify the number of times of IQR that we want for the length of whisker in the coef argument. Below, I specify it at 3. Then, the length of whisker to be drawn is 3 times IQR.\n\n  ggplot(ipe2015, aes(y = trade_WDI, x = factor(0))) +  \n    geom_boxplot(width = 0.2, coef = 3)       # Add the coef argument.\n\n\n\n\n\n\n\n\nAs you can see, the length of the upper whisker is longer than before, and the two outliers that appeared above the upper whisker disappeared because these outliers are now behind the upper whisker. I’d suggest you try a few different values to see how the length of whisker changes.\nPerhaps, you noticed that the length of the lower whisker didn’t change. Moreover, in the original box plot where we didn’t specify the coef argument and therefore, we used the default length of 1.5 times IQR, the length of the lower whisker was shorter than the length of the upper whisker, or 1.5 times IQR. This is because the lower (or upper) whisker extends only to the minimum (or maximum) value of a variable. In other words, the minimum value of trade_WDI is within 1.5 times IQR, and therefore, the lower whisker was shorter than the upper whisker in the original box plot, and its length didn’t change when we changed the length of whisker to 3 by the coef argument.\nWe can further edit the box plot using the functions we learned in Chapter 3. (I don’t use the coef argument here because 1.5 times IQR seems to be reasonable for this variable.)\n\n  trade_box &lt;- ggplot(ipe2015, aes(y = trade_WDI, x = factor(0))) + \n    geom_boxplot(width = 0.2, fill=\"cyan4\") +\n    labs(title = \"Trade (% of GDP)\") +\n    xlab(\"\") +\n    ylab(\"\")\n  print(trade_box)\n\n\n\n\n\n\n\n\nNote that in the above code, I assigned the ggplot() + geom_boxplot() functions to a new object trade_box and then used the print() function to draw the box plot.\nYou may want to remove 0 on the horizontal axis. We can do this by specifying the axis.text.x argument for the theme() function as follows. Recall that trade_box includes all ggplot() + geom_boxplot() functions assigned above, and we can add additional functions to trade_box.\n\n  trade_box +\n    theme(axis.text.x = element_blank())\n\n\n\n\n\n\n\n\nYou may further want to remove the tick mark on the horizontal axis. We can do this by specifying the axis.ticks.x argument for the theme() function as follows.\n\n  trade_box +\n    theme(axis.text.x = element_blank(),\n         axis.ticks.x = element_blank())\n\n\n\n\n\n\n\n\nNow this box plot looks pretty good.\nA box plot may also be drawn horizontally. I suggest you identify what is different in the following code for a horizontal box plot from the previous code for a vertical box plot.\n\n  ggplot(ipe2015, aes(x = trade_WDI, y = factor(0))) + \n    geom_boxplot(width = 0.2, fill=\"cyan4\") +\n    labs(title = \"Trade (% of GDP)\") +\n    xlab(\"\") +\n    ylab(\"\") +\n    theme(axis.text.y = element_blank(),\n          axis.ticks.y = element_blank())",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "bivariate.html",
    "href": "bivariate.html",
    "title": "5  Bivariate Analysis",
    "section": "",
    "text": "5.1 Mosaic Plot\nWhen two variables are both categorical variables, we may use a mosaic plot to visualize the relationship.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate.html#preparation",
    "href": "bivariate.html#preparation",
    "title": "5  Bivariate Analysis",
    "section": "",
    "text": "5.1.1 Before You Start\nBefore you start working on this chapter, you need to do the following. If you need a help for each step, see Section 3.1.\n\nLaunch RStudio.\nLoad POL232.RData into your current R session.\nPrepare an R Script to save all your work in this chapter. I suggest you name it “POL232_Lab#_YourLastName.R” in which # is the number of the current lab session.\nYou also need to load tidyverse package into your current R session (Section 1.4.2).\n\n\n  library(tidyverse)\n\n\n\n5.1.2 Actually Write R Functions",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate.html#mosaic-plot",
    "href": "bivariate.html#mosaic-plot",
    "title": "5  Bivariate Analysis",
    "section": "",
    "text": "5.1.1 New Package: ggmosaic\nTo draw a mosaic plot, we also need a new package ggmosaic, which works with the ggplot() function.\nInstall ggmosaic first if it has not been downloaded and installed on your computer. See Section 1.4.1 for how to install an R package.\nThen, load ggmosaic (Section 1.4.2).\n\n  library(ggmosaic)\n\n\n\n5.1.2 Prepare Variables\nWe are going to draw a mosaic plot for satisfied_fedgovt and percep_economy_cps from the ces2019 data frame. This can be considered as a simple test of the theory of economic voting. In this analysis, percep_economy_cps is the independent variable, and satisfied_fedgovt is the dependent variable.\nBefore visualizing the relationship, we first edit these two variables. Recall what we did for percep_economy_cps in Section 4.2. We change the names of their categories or levels to simpler ones (Section 4.2.6) and change the order of the categories or levels (Section 4.2.5).\nTo change the names of the categories or levels, we use the fct_recode() function (Section 4.2.6). Recall its basic syntax.\n\nfct_recode(factor_variable, \n              \"New Name of Level 1\" = \"Original Name of Level 1\", \n              \"New Name of Level 2\" = \"Original Name of Level 2\", \n              \"New Name of Level 3\" = \"Original Name of Level 3\") \n\nTo change the order of categories or levels, we use the fct_relevel() function (Section 4.2.5). Recall the following basic syntax.\n\n      fct_relevel(factor_variable, \n          \"First Level\", \"Second Level\", \"Third Level\")\n\nLet’s edit precep_economy_cps using these functions. In Section 4.2, we created a new variable to reflect the edits, but here we instead update percep_economy_cps with these edits. In the following code, the left hand side of = in the mutate() function is percep_economy_cps instead of precep_economy_cps2 or percep_economy_cps3 used in the previous lab session. In this way, we can update the content of percep_economy_cps.\n\nces2019 &lt;- mutate(ces2019,\n  percep_economy_cps = fct_recode(percep_economy_cps,\n    \"Worse\" = \"(2) Worse\",\n    \"Same\" = \"(3) About the same\",\n    \"Better\" = \"(1) Better\") )\n\n\nces2019 &lt;- mutate(ces2019,\n  percep_economy_cps = fct_relevel(percep_economy_cps,\n    \"Worse\", \"Same\", \"Better\") )\n\nWe also edit satisfied_fedgovt as follows.\n\nces2019 &lt;- mutate(ces2019,\n  satisfied_fedgovt = fct_recode(satisfied_fedgovt,\n    \"Not At All\" = \"(4) Not satisfied at all\",\n    \"Not Very\" = \"(3) Not very satisfied\",\n    \"Fairly\" = \"(2) Fairly satisfied\",\n    \"Very\" = \"(1) Very satisfied\") )\n\n\nces2019 &lt;- mutate(ces2019, \n  satisfied_fedgovt = fct_relevel(satisfied_fedgovt, \n    \"Not At All\", \"Not Very\", \"Fairly\", \"Very\")) \n\n\n\n5.1.3 Draw a Mosaic Plot: ggplot() + geom_mosaic()\nLet’s draw a mosaic plot for percep_economy_cps and satisfied_govt. Below is the minimum specification for the ggplot() + geom_mosaic() functions. Read the comments in the code below for an explanation for the basic syntax.\n\n                    # Specify the data frame used inside ggplot(). \nggplot(ces2019) +   # aes() is now specified in geom_mosaic() instead of ggplot().\n  geom_mosaic( aes(x = product(percep_economy_cps),  # x = product(independent_variable)\n                   fill = satisfied_fedgovt) )       # fill = dependent_variable\n\n\n\n\n\n\n\n\n\n\n5.1.4 Remove NA: drop_na()\nThe mosaic plot drawn above includes missing observations (NA). As we did before in Section 4.2.7, let’s remove these missing observations using the drop_na() function. Recall the basic syntax of the drop_na() function below.\n\n  drop_na(name_of_data_frame, name_of_variable)\n\nThe drop_na() function looks for the observations for which the variable in the second argument (name_of_variable above) is missing (NA) and removes these observations from the data frame in the first argument (name_of_data_frame). So in the code below, the drop_na() function looks for the observations in ces2019 for which percep_economy_cps is missing (NA), and removes these observations from ces2019.\n\n  drop_na(ces2019, percep_economy_cps)\n\nUse drop_na(ces2019, percep_economy_cps) instead of ces2019 inside the ggplot() function.\n\n    # drop_na() here removes the missing observations (NA) for percep_economy_cps from ces2019.\nggplot( drop_na(ces2019, percep_economy_cps) ) +    \n  geom_mosaic( aes(x = product(percep_economy_cps),  \n                   fill = satisfied_fedgovt) )        \n\n\n\n\n\n\n\n\nAs you see in the above plot, now the missing observations for percep_economy_cps were removed, but those for satisfied_fedgovt still remain. To remove the missing observations for satisfied_fedgovt, we also need to include this variable in the drop_na() function.\n\n    # drop_na() here removes the missing observations (NA) for both percep_economy_cps \n    # and satisfied_fedgovt from ces2019.\nggplot( drop_na(ces2019, percep_economy_cps, satisfied_fedgovt) ) +    \n  geom_mosaic( aes(x = product(percep_economy_cps),  \n                   fill = satisfied_fedgovt) )        \n\n\n\n\n\n\n\n\nNow the missing observations for satisfied_fedgove are removed as well.\n\n\n5.1.5 Other Edits: show.legend, scale_fill_manual()\nPerhaps we don’t need the legend, as the category names are also shown on the vertical axis. We can remove the legend by specifying show.legend = FALSE in the geom_mosaic() function.\n\nggplot(drop_na(ces2019, percep_economy_cps, satisfied_fedgovt)) +\n  geom_mosaic(aes(x = product(percep_economy_cps), fill = satisfied_fedgovt), \n              show.legend = FALSE)          # show.legend = FALSE removes the legend.\n\n\n\n\n\n\n\n\nYou can also specify the colors of the mosaic tiles by adding the scale_fill_manual() function. Recall that you can look up the names of the colors used in R online, for example, here and here.\n\nggplot(drop_na(ces2019, percep_economy_cps, satisfied_fedgovt)) +\n  geom_mosaic(aes(x = product(percep_economy_cps), fill = satisfied_fedgovt), \n              show.legend = FALSE) +\n          # Below, you need to specify the colors for each category of your dependent variable.\n          # Don't forget to include the names of the colors in c().\n  scale_fill_manual(values = c(\"lightsteelblue2\", \"steelblue1\", \"steelblue3\", \"steelblue4\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can of course use the functions you learned before to further edit the plot. For example, below I added the labels for both y and x axes.\n\nggplot(drop_na(ces2019, percep_economy_cps, satisfied_fedgovt)) +\n  geom_mosaic(aes(x = product(percep_economy_cps), fill = satisfied_fedgovt), \n              show.legend = FALSE) +\n  scale_fill_manual(values = c(\"lightsteelblue2\", \"steelblue1\", \"steelblue3\", \"steelblue4\")) +\n  ylab(\"Satisfied with Government\") +   # Change the label at y-axis.\n  xlab(\"Perception of Economy\")         # Change the label at x-axis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "des2.html#bar-chart-ggplot-geom_bar-edit-variables",
    "href": "des2.html#bar-chart-ggplot-geom_bar-edit-variables",
    "title": "4  Descriptive Statistics (2)",
    "section": "4.2 Bar Chart: ggplot() + geom_bar() & Edit Variables",
    "text": "4.2 Bar Chart: ggplot() + geom_bar() & Edit Variables\nIn Chapter 3, we learned how to draw a histogram using the ggplot() function.\nA histogram is an appropriate visualization if the variable of interest takes many values and/or is continuous. If the variable takes only a small number of values and/or is categorical, a bar chart may be more appropriate. Let’s draw a bar chart for the variable on the respondent’s perception of economy (percep_economy_cps) from the Canadian Election Study 2019 (ces2019).\nTo draw a bar chart, we augment the ggplot() function with the geom_bar() function (as opposed to the geom_histogram() function we used to draw a histogram).\nFirst, try the simplest implementation of these functions as shown below.\n\n  ggplot(ces2019, aes(percep_economy_cps)) + geom_bar()\n\n\n\n\n\n\n\n\nWe can apply many of the additional arguments and functions we learned for a histogram to a bar chart. Let’s see an example.\n\n  bar_econ &lt;- ggplot(ces2019, aes(percep_economy_cps)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n  print(bar_econ)\n\n\n\n\n\n\n\n\nNote that in the above code, I assigned the ggplot() functions for a bar chart to a new object bar_econ and then used the print() function to draw it.\nTry to identify what each line of the above code accomplishes. If you need a refresher, see Chapter 3. You can also use a keyword search over the entire webbook from the left menu.\nBy the way, as we saw in Section 3.4, instead of using the print()function, you can also simply type in bar_econ in the R Console to run the ggplot() functions assigned to bar_econ.\n\n  bar_econ\n\n\n\n\n\n\n\n\n\n4.2.1 Change Angle of Value Labels on X Axis: theme(), axis.text.x, element_text()\nIn the X-axis of the above bar chart, notice that the names of the categories (or values) of the variable cannot be read because of an overlap. This is because the names are too long to be properly displayed in a horizontal direction.\nWe can change the angle of the names of the categories (or values) of a variable (= value labels of a variable) by the theme function as shown below.\n\n  bar_econ +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nIf you specify a different number to angle, then value labels are presented in a different angle. For example, try the following.\n\n  bar_econ +\n    theme(axis.text.x = element_text(angle = 60))\n\n\n\n\n\n\n\n\nWe may want to edit this bar chart further. First, instead of “Better,” “Worse,” and “About the Same” in the above bar chart, we may want to re-order them from “Worse,” “About the Same” to “Better.” Second, we may want to change the name of the categories — more specifically, we may want to remove the numbers and parentheses and shorten the name from “About the same” to “same.” Third, we may want to remove “NA” from the bar chart.\nWe will do these edits one by one.\n\n\n4.2.2 NA: Missing Observations\nBy the way, NA indicates the observations for which the variable of interest is missing. We call such observations “missing observations” and those NAs “missing values.”\nTo know more about missing observations, browse ces2019 using the View() function or clicking ces2019 in the Environment tab on the upper right pane.\n\n  View(ces2019)\n\nThen, you can find that for some observations, the values of some variables are NA, as shown below. These entries (NAs) indicate that the values of these variables are missing for these observations.\n\nThe ggplot() + geom_bar() functions include these missing observations in the bar chart they draw. However, we may want to exclude these missing observations from the bar chart.\n\n\n4.2.3 Factor for Categorical Variables: glimpse()\nDepending on their characteristics, variables in a data frame may be stored in different formats in R. Normally, our dataset includes both quantitative (or numeric) variables, which take numbers (numerical values), and categorical variables, which take a set of categories. Of the variables from ces2019 that we have examined so far, the Trudeau thermometer (truedeau_therm_cps) is a quantitative (or numeric) variable, as it takes a number between 0 and 100. Respondent’s perception of the state of the national economy (percep_economy_cps) is a categorical variable, as it takes three categories indicating the respondents’ perception of economy. These two types of variables are stored in different formats in a data frame.\nTo see different formats for variables, try the glimpse() function below with the name of a data frame as its argument.\n\n  glimpse(ces2019)\n\n\n\nRows: 4,021\nColumns: 5\n$ sample_id         &lt;dbl&gt; 18, 32, 39, 59, 61, 69, 157, 158, 165, 167, 185, 220…\n$ birth_year        &lt;dbl&gt; 1963, 1973, 1994, 2000, 1984, 1939, 1999, 1995, 1963…\n$ gender            &lt;fct&gt; (1) Male, (1) Male, (1) Male, (1) Male, (1) Male, (1…\n$ province          &lt;fct&gt; QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, …\n$ satisfied_dem_cps &lt;fct&gt; (3) Not very satisfied, (2) Fairly satisfied, (1) Ve…\n\n\nYour R Console prints a list like the one above for all variables in ces2019. For brevity, I printed only the first five variables above. As its name suggests, the glimpse() function offers a glimpse into your data frame — names of variables, their format, and the values of the first few observations.\nIn this list, you can see that the format1 of the variables are either &lt;dbl&gt; or &lt;fct&gt;.\n&lt;dbl&gt; is for numeric (or quantitative) variables,2 for which each value is number, and &lt;fct&gt; is for categorical variables, which is stored in a format called factor. For example, sample_id and birth_year are numbers (numeric variables), hence they are given &lt;dbl&gt; in the list above. gender, province, and satisfied_dem_cps are categorical variables, and the list above indicates &lt;fct&gt; for these variables. A factor is a special format for categorical variables in R, which offers convenient functionalities for this type of variable. We will use these functionalities of factor to edit percep_eonomy_cps.\n\n\n4.2.4 Create New Variable: mutate(), head()\nSuppose we want to create a new variable for which the order of categories of percep_economy_cps will appear from “Worse,” “Same” to “Better” when we draw a bar chart.\nWe will create such a variable step by step in the next few sections.\nIn this section, I will explain how we can create a new variable in our data frame. For simplicity, we will create a new variable percep_economy_cps_copy which is exactly the same as percep_economy_cps. We can do this by the mutate() function.\n\n  ces2019 &lt;- mutate(ces2019, \n              percep_economy_cps_copy = percep_economy_cps)\n\nThe first argument of the mutate() function is the data frame to which we want to add a new variable. Its second argument specifies the content of this new variable by name-of-new-variable = its-content. In the above code, it is specified that the new variable percep_economy_cps_copy equals percep_economy_cps.\nThe right hand side of &lt;- (the assignment operator3, see Section 2.3.3) in the above code mutated the data frame ces2019 by adding a new variable percep_economy_cps_copy. Then, this new, mutated data frame is assigned to ces2019 on the left hand side of &lt;-. In other words, ces2019 is now updated with an additional variable percep_economy_cps_copy.\nCheck if the new variable percep_economy_cps_copy is added to your data frame using the glimpse() function. If you apply the glimpse() function to ces2019, now you can see this new variable percep_economy_cps_copy at the end of the data frame. For brevity, I show only percep_economy_cps and percep_economy_cps_copy below. They are exactly the same.\n\n  glimpse(ces2019)\n\n\n\nRows: 4,021\nColumns: 2\n$ percep_economy_cps      &lt;fct&gt; (2) Worse, (3) About the same, (1) Better, (3)…\n$ percep_economy_cps_copy &lt;fct&gt; (2) Worse, (3) About the same, (1) Better, (3)…\n\n\nWe can also use the head() function to see the first few observations of a variable. Try the code below.\n\n  head(ces2019$percep_economy_cps)\n\n[1] (2) Worse          (3) About the same (1) Better         (3) About the same\n[5] (1) Better         (2) Worse         \nLevels: (1) Better (2) Worse (3) About the same\n\n  head(ces2019$percep_economy_cps_copy)\n\n[1] (2) Worse          (3) About the same (1) Better         (3) About the same\n[5] (1) Better         (2) Worse         \nLevels: (1) Better (2) Worse (3) About the same\n\n\nAs you can see, the values for each observation are exactly the same between percep_economy_cps and percep_economy_cps_copy.\nBy specifying the right hand side of = in the second argument of the mutate() function in different ways, we can create different types of new variables.\nThe mutate() function may also be used to edit the existing variables in our data frame.\nWe will see a few examples in this chapter and subsequent chapters.\n\n\n4.2.5 Change Levels of Factor: levels(), fct_relevel()\nLet’s explore the characteristics of factor a little further.\nWhen categorical variables are stored as factor in R, they are associated with levels, which represent the name of each category, such as “(1) Better” and “(2) Worse”, and assigns a specific order to these categories.\nYou can find levels of categorical variables stored as factor by the levels() function with the name of the variable as its argument.\nRecall that as percep_economy_cps is one column of the data frame ces2019, we use $ to access it — more specifically, we refer to percep_economy_cps as ces2019percep_economy_cps.\n\n  levels(ces2019$percep_economy_cps)\n\n[1] \"(1) Better\"         \"(2) Worse\"          \"(3) About the same\"\n\n\nThe output lists the three categories, or levels, taken by percep_economy_cps. Also, these levels are associated with the order that appears above. So, if we draw a bar chart of this variable, bars are ordered by this order associated with levels.\n\n  ggplot(ces2019, aes(percep_economy_cps)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\") +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nBars appeared from “(1) Better”, “(2) Worse”, to “(3) About the same”. To change the order of bars, we need to change the order of levels for percep_econ_cps. We can do this by the fct_relevel() function.\nA basic syntax of the fct_relevel() function is the following. Don’t execute the code below because it is not intended to be implemented; it is used only to show the syntax of this R function.\n\n      fct_relevel( factor_variable, \n          \"First Level\", \"Second Level\", \"Third Level\")\n\nThe first argument of the fct_relevel() function is the categorical variable stored as factor that we want to “relevel” (i.e., change the order of categories).\nThen, it is followed by the levels or categories of this variable in the order we want.\nBelow, I use the mutate() function to create a new variable percep_economy_cps2 in which percep_economy_cps is releveled or reordered.\n\n  ces2019 &lt;- mutate(ces2019, \n      percep_economy_cps2 = fct_relevel(percep_economy_cps, \n          \"(2) Worse\", \"(3) About the same\", \"(1) Better\") )\n\nAs we saw in the previous section, the mutate() function on the right hand side of &lt;- creates a new variable percep_economy_cps2 in the data frame ces2019. In its second argument, the fct_relevel() function is used to specify the content of the new variable. By this fct_relevel() function, percep_economy_cps2 equals percep_economy_cps but with different ordering of its levels or categories. The order of the levels or categories of percep_economy_cps2 is now from “(2) Worse” to “(3) About the same” to “(1) Better”.\nBy the above code, ces2019 is now updated with an additional variable percep_economy_cps2, with the desired order of its levels or categories. Let’s check that the new variable percep_economy_cps2 is releveled or reordered as we wanted using the levels() function.\n\n  levels(ces2019$percep_economy_cps2)\n\n[1] \"(2) Worse\"          \"(3) About the same\" \"(1) Better\"        \n\n\nThe variable is indeed releveled or reordered as we specified.\nLet’s draw a bar chart for this releveled variable.\n\n  ggplot(ces2019, aes(percep_economy_cps2)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\") +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nNow the bars appeared in the order we wanted.\n\n\n4.2.6 Change Names of Categories/Levels: fct_recode()\nNext we will remove numbers, such as (1) and (2), from each category of percep_economy_cps2 and change “About the Same” to “Same.” Specifically, we will create a new variable named percep_economy_cps3 with our desired names of levels or categories of percep_economy_cps2. For this purpose, we use the fct_recode() function. A basic syntax of the fct_recode() function is as follows. Once again, don’t implement the code below, as it is not intended to be implemented; it is used only to show a syntax of this R function).\n\nfct_recode(factor_variable, \n              \"New Name of Level 1\" = \"Original Name of Level 1\", \n              \"New Name of Level 2\" = \"Original Name of Level 2\", \n              \"New Name of Level 3\" = \"Original Name of Level 3\") \n\nLet’s create a new variable percep_economy_cps3 using this function.\n\n  ces2019 &lt;- mutate(ces2019, \n      percep_economy_cps3 = fct_recode(percep_economy_cps2, \n                                \"Worse\" = \"(2) Worse\", \n                                \"Same\" = \"(3) About the same\", \n                                \"Better\" = \"(1) Better\") )\n\nThis code adds a new variable percep_eocnomy_cps3 to ces2019. The first argument of the fct_recode() function above is the name of the variable whose levels or categories are changed (precep_economy_cps2). The following arguments specify the new name of each level and the old name of each level.\nLet’s check the levels of percep_economy_cps3 by the levels() function to see whether the names of levels or categories were changed as specified.\n\n  levels(ces2019$percep_economy_cps3)\n\n[1] \"Worse\"  \"Same\"   \"Better\"\n\n\nThe names of levels or categories were indeed changed as we wanted.\nLet’s draw a histogram using this new variable.\n\n  ggplot(ces2019, aes(percep_economy_cps3)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nThe bar chart looks much better now. Note that we didn’t need to use theme(axis.text.x = element_text(angle = 90)) anymore in the above code, because the names of categories are short enough to appear horizontally.\n\n\n4.2.7 Remove NA: drop_na()\nNow we will remove NA from the bar chart. For this purpose, we use the drop_na() function. A basic syntax of the drop_na() function is this (the code below is not intended to be implemented).\n\n  drop_na(name_of_data_frame, name_of_variable)\n\nThe first argument is the name of the data frame from which we want to remove missing observations, and the second argument is the name of the variable for which we want to eliminate missing observations.\nIn other words, the drop_na() function looks for the observations for which the variable in the second argument is missing (NA) and removes these observations from the data frame in the first argument.\nTherefore, if we specify the drop_na() function as below, then the drop_na() function looks for the observations in ces2019 for which percep_economy_cps3 is missing (NA), and removes these observations from ces2019.\n\n  drop_na(ces2019, percep_economy_cps3)\n\nTo draw a bar chart of percep_economy_cps3, we may replace ces2019 in the first argument of the ggplot() function with drop_na(ces2019, percep_economy_cps3). In this way, the ggplot() function will use a version of ces2019 from which the observations with percep_economy_cps3 missing are removed. Let’s try this.\n\n  ggplot(drop_na(ces2019, percep_economy_cps3), aes(percep_economy_cps3)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nNow we were able to draw a bar chart without NA.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "des2.html#sec-bar-chart-edit-vars",
    "href": "des2.html#sec-bar-chart-edit-vars",
    "title": "4  Descriptive Statistics (2)",
    "section": "4.2 Bar Chart: ggplot() + geom_bar() & Edit Variables",
    "text": "4.2 Bar Chart: ggplot() + geom_bar() & Edit Variables\nIn Chapter 3, we learned how to draw a histogram using the ggplot() function.\nA histogram is an appropriate visualization if the variable of interest takes many values and/or is continuous. If the variable takes only a small number of values and/or is categorical, a bar chart may be more appropriate. Let’s draw a bar chart for the variable on the respondent’s perception of economy (percep_economy_cps) from the Canadian Election Study 2019 (ces2019).\nTo draw a bar chart, we augment the ggplot() function with the geom_bar() function (as opposed to the geom_histogram() function we used to draw a histogram).\nFirst, try the simplest implementation of these functions as shown below.\n\n  ggplot(ces2019, aes(percep_economy_cps)) + geom_bar()\n\n\n\n\n\n\n\n\nWe can apply many of the additional arguments and functions we learned for a histogram to a bar chart. Let’s see an example.\n\n  bar_econ &lt;- ggplot(ces2019, aes(percep_economy_cps)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n  print(bar_econ)\n\n\n\n\n\n\n\n\nNote that in the above code, I assigned the ggplot() functions for a bar chart to a new object bar_econ and then used the print() function to draw it.\nTry to identify what each line of the above code accomplishes. If you need a refresher, see Chapter 3. You can also use a keyword search over the entire webbook from the left menu.\nBy the way, as we saw in Section 3.4, instead of using the print()function, you can also simply type in bar_econ in the R Console to run the ggplot() functions assigned to bar_econ.\n\n  bar_econ\n\n\n\n\n\n\n\n\n\n4.2.1 Change Angle of Value Labels on X Axis: theme(), axis.text.x, element_text()\nIn the X-axis of the above bar chart, notice that the names of the categories (or values) of the variable cannot be read because of an overlap. This is because the names are too long to be properly displayed in a horizontal direction.\nWe can change the angle of the names of the categories (or values) of a variable (= value labels of a variable) by the theme function as shown below.\n\n  bar_econ +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nIf you specify a different number to angle, then value labels are presented in a different angle. For example, try the following.\n\n  bar_econ +\n    theme(axis.text.x = element_text(angle = 60))\n\n\n\n\n\n\n\n\nWe may want to edit this bar chart further. First, instead of “Better,” “Worse,” and “About the Same” in the above bar chart, we may want to re-order them from “Worse,” “About the Same” to “Better.” Second, we may want to change the name of the categories — more specifically, we may want to remove the numbers and parentheses and shorten the name from “About the same” to “same.” Third, we may want to remove “NA” from the bar chart.\nWe will do these edits one by one.\n\n\n4.2.2 NA: Missing Observations\nBy the way, NA indicates the observations for which the variable of interest is missing. We call such observations “missing observations” and those NAs “missing values.”\nTo know more about missing observations, browse ces2019 using the View() function or clicking ces2019 in the Environment tab on the upper right pane.\n\n  View(ces2019)\n\nThen, you can find that for some observations, the values of some variables are NA, as shown below. These entries (NAs) indicate that the values of these variables are missing for these observations.\n\nThe ggplot() + geom_bar() functions include these missing observations in the bar chart they draw. However, we may want to exclude these missing observations from the bar chart.\n\n\n4.2.3 Factor for Categorical Variables: glimpse()\nDepending on their characteristics, variables in a data frame may be stored in different formats in R. Normally, our dataset includes both quantitative (or numeric) variables, which take numbers (numerical values), and categorical variables, which take a set of categories. Of the variables from ces2019 that we have examined so far, the Trudeau thermometer (truedeau_therm_cps) is a quantitative (or numeric) variable, as it takes a number between 0 and 100. Respondent’s perception of the state of the national economy (percep_economy_cps) is a categorical variable, as it takes three categories indicating the respondents’ perception of economy. These two types of variables are stored in different formats in a data frame.\nTo see different formats for variables, try the glimpse() function below with the name of a data frame as its argument.\n\n  glimpse(ces2019)\n\n\n\nRows: 4,021\nColumns: 5\n$ sample_id         &lt;dbl&gt; 18, 32, 39, 59, 61, 69, 157, 158, 165, 167, 185, 220…\n$ birth_year        &lt;dbl&gt; 1963, 1973, 1994, 2000, 1984, 1939, 1999, 1995, 1963…\n$ gender            &lt;fct&gt; (1) Male, (1) Male, (1) Male, (1) Male, (1) Male, (1…\n$ province          &lt;fct&gt; QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, QC, …\n$ satisfied_dem_cps &lt;fct&gt; (3) Not very satisfied, (2) Fairly satisfied, (1) Ve…\n\n\nYour R Console prints a list like the one above for all variables in ces2019. For brevity, I printed only the first five variables above. As its name suggests, the glimpse() function offers a glimpse into your data frame — names of variables, their format, and the values of the first few observations.\nIn this list, you can see that the format1 of the variables are either &lt;dbl&gt; or &lt;fct&gt;.\n&lt;dbl&gt; is for numeric (or quantitative) variables,2 for which each value is number, and &lt;fct&gt; is for categorical variables, which is stored in a format called factor. For example, sample_id and birth_year are numbers (numeric variables), hence they are given &lt;dbl&gt; in the list above. gender, province, and satisfied_dem_cps are categorical variables, and the list above indicates &lt;fct&gt; for these variables. A factor is a special format for categorical variables in R, which offers convenient functionalities for this type of variable. We will use these functionalities of factor to edit percep_eonomy_cps.\n\n\n4.2.4 Create New Variable: mutate(), head()\nSuppose we want to create a new variable for which the order of categories of percep_economy_cps will appear from “Worse,” “Same” to “Better” when we draw a bar chart.\nWe will create such a variable step by step in the next few sections.\nIn this section, I will explain how we can create a new variable in our data frame. For simplicity, we will create a new variable percep_economy_cps_copy which is exactly the same as percep_economy_cps. We can do this by the mutate() function.\n\n  ces2019 &lt;- mutate(ces2019, \n              percep_economy_cps_copy = percep_economy_cps)\n\nThe first argument of the mutate() function is the data frame to which we want to add a new variable. Its second argument specifies the content of this new variable by name-of-new-variable = its-content. In the above code, it is specified that the new variable percep_economy_cps_copy equals percep_economy_cps.\nThe right hand side of &lt;- (the assignment operator3, see ?sec-assignment-operator) in the above code mutated the data frame ces2019 by adding a new variable percep_economy_cps_copy. Then, this new, mutated data frame is assigned to ces2019 on the left hand side of &lt;-. In other words, ces2019 is now updated with an additional variable percep_economy_cps_copy.\nCheck if the new variable percep_economy_cps_copy is added to your data frame using the glimpse() function. If you apply the glimpse() function to ces2019, now you can see this new variable percep_economy_cps_copy at the end of the data frame. For brevity, I show only percep_economy_cps and percep_economy_cps_copy below. They are exactly the same.\n\n  glimpse(ces2019)\n\n\n\nRows: 4,021\nColumns: 2\n$ percep_economy_cps      &lt;fct&gt; (2) Worse, (3) About the same, (1) Better, (3)…\n$ percep_economy_cps_copy &lt;fct&gt; (2) Worse, (3) About the same, (1) Better, (3)…\n\n\nWe can also use the head() function to see the first few observations of a variable. Try the code below.\n\n  head(ces2019$percep_economy_cps)\n\n[1] (2) Worse          (3) About the same (1) Better         (3) About the same\n[5] (1) Better         (2) Worse         \nLevels: (1) Better (2) Worse (3) About the same\n\n  head(ces2019$percep_economy_cps_copy)\n\n[1] (2) Worse          (3) About the same (1) Better         (3) About the same\n[5] (1) Better         (2) Worse         \nLevels: (1) Better (2) Worse (3) About the same\n\n\nAs you can see, the values for each observation are exactly the same between percep_economy_cps and percep_economy_cps_copy.\nBy specifying the right hand side of = in the second argument of the mutate() function in different ways, we can create different types of new variables.\nThe mutate() function may also be used to edit the existing variables in our data frame.\nWe will see a few examples in this chapter and subsequent chapters.\n\n\n4.2.5 Change Levels and Their Order of Factor: levels(), fct_relevel()\nLet’s explore the characteristics of factor a little further.\nWhen categorical variables are stored as factor in R, they are associated with levels, which represent the name of each category, such as “(1) Better” and “(2) Worse”, and assigns a specific order to these categories.\nYou can find levels of categorical variables stored as factor by the levels() function with the name of the variable as its argument.\nRecall that as percep_economy_cps is one column of the data frame ces2019, we use $ to access it — more specifically, we refer to percep_economy_cps as ces2019$percep_economy_cps.\n\n  levels(ces2019$percep_economy_cps)\n\n[1] \"(1) Better\"         \"(2) Worse\"          \"(3) About the same\"\n\n\nThe output lists the three categories, or levels, taken by percep_economy_cps. Also, these levels are associated with the order that appears above. So, if we draw a bar chart of this variable, bars are ordered by this order associated with levels.\n\n  ggplot(ces2019, aes(percep_economy_cps)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\") +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nBars appeared from “(1) Better”, “(2) Worse”, to “(3) About the same”. To change the order of bars, we need to change the order of levels for percep_econ_cps. We can do this by the fct_relevel() function.\nA basic syntax of the fct_relevel() function is the following. Don’t execute the code below because it is not intended to be implemented; it is used only to show the syntax of this R function.\n\n      fct_relevel( factor_variable, \n          \"First Level\", \"Second Level\", \"Third Level\")\n\nThe first argument of the fct_relevel() function is the categorical variable stored as factor that we want to “relevel” (i.e., change the order of categories).\nThen, it is followed by the levels or categories of this variable in the order we want.\nBelow, I use the mutate() function to create a new variable percep_economy_cps2 in which percep_economy_cps is releveled or reordered.\n\n  ces2019 &lt;- mutate(ces2019, \n      percep_economy_cps2 = fct_relevel(percep_economy_cps, \n          \"(2) Worse\", \"(3) About the same\", \"(1) Better\") )\n\nAs we saw in the previous section, the mutate() function on the right hand side of &lt;- creates a new variable percep_economy_cps2 in the data frame ces2019. In its second argument, the fct_relevel() function is used to specify the content of the new variable. By this fct_relevel() function, percep_economy_cps2 equals percep_economy_cps but with different ordering of its levels or categories. The order of the levels or categories of percep_economy_cps2 is now from “(2) Worse” to “(3) About the same” to “(1) Better”.\nBy the above code, ces2019 is now updated with an additional variable percep_economy_cps2, with the desired order of its levels or categories. Let’s check that the new variable percep_economy_cps2 is releveled or reordered as we wanted using the levels() function.\n\n  levels(ces2019$percep_economy_cps2)\n\n[1] \"(2) Worse\"          \"(3) About the same\" \"(1) Better\"        \n\n\nThe variable is indeed releveled or reordered as we specified.\nLet’s draw a bar chart for this releveled variable.\n\n  ggplot(ces2019, aes(percep_economy_cps2)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\") +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n\nNow the bars appeared in the order we wanted.\n\n\n4.2.6 Change Names of Categories/Levels: fct_recode()\nNext we will remove numbers, such as (1) and (2), from each category of percep_economy_cps2 and change “About the Same” to “Same.” Specifically, we will create a new variable named percep_economy_cps3 with our desired names of levels or categories of percep_economy_cps2. For this purpose, we use the fct_recode() function. A basic syntax of the fct_recode() function is as follows. Once again, don’t implement the code below, as it is not intended to be implemented; it is used only to show a syntax of this R function.\n\nfct_recode(factor_variable, \n              \"New Name of Level 1\" = \"Original Name of Level 1\", \n              \"New Name of Level 2\" = \"Original Name of Level 2\", \n              \"New Name of Level 3\" = \"Original Name of Level 3\") \n\nLet’s create a new variable percep_economy_cps3 using this function.\n\n  ces2019 &lt;- mutate(ces2019, \n      percep_economy_cps3 = fct_recode(percep_economy_cps2, \n                                \"Worse\" = \"(2) Worse\", \n                                \"Same\" = \"(3) About the same\", \n                                \"Better\" = \"(1) Better\") )\n\nThis code adds a new variable percep_eocnomy_cps3 to ces2019. The first argument of the fct_recode() function above is the name of the variable whose levels or categories are changed (precep_economy_cps2). The following arguments specify the new name of each level and the old name of each level.\nLet’s check the levels of percep_economy_cps3 by the levels() function to see whether the names of levels or categories were changed as specified.\n\n  levels(ces2019$percep_economy_cps3)\n\n[1] \"Worse\"  \"Same\"   \"Better\"\n\n\nThe names of levels or categories were indeed changed as we wanted.\nLet’s draw a histogram using this new variable.\n\n  ggplot(ces2019, aes(percep_economy_cps3)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nThe bar chart looks much better now. Note that we didn’t need to use theme(axis.text.x = element_text(angle = 90)) anymore in the above code, because the names of categories are short enough to appear horizontally.\n\n\n4.2.7 Remove NA: drop_na()\nNow we will remove NA from the bar chart. For this purpose, we use the drop_na() function. A basic syntax of the drop_na() function is this (the code below is not intended to be implemented).\n\n  drop_na(name_of_data_frame, name_of_variable)\n\nThe first argument is the name of the data frame from which we want to remove missing observations, and the second argument is the name of the variable for which we want to eliminate missing observations.\nIn other words, the drop_na() function looks for the observations for which the variable in the second argument is missing (NA) and removes these observations from the data frame in the first argument.\nTherefore, if we specify the drop_na() function as below, then the drop_na() function looks for the observations in ces2019 for which percep_economy_cps3 is missing (NA), and removes these observations from ces2019.\n\n  drop_na(ces2019, percep_economy_cps3)\n\nTo draw a bar chart of percep_economy_cps3, we may replace ces2019 in the first argument of the ggplot() function with drop_na(ces2019, percep_economy_cps3). In this way, the ggplot() function will use a version of ces2019 from which the observations with percep_economy_cps3 missing are removed. Let’s try this.\n\n  ggplot(drop_na(ces2019, percep_economy_cps3), aes(percep_economy_cps3)) + \n    geom_bar(fill = \"dodgerblue\", color = \"black\") +\n    labs(title=\"Perception of Economy\") +\n    ylab(\"\") +\n    xlab(\"\")\n\n\n\n\n\n\n\n\nNow we were able to draw a bar chart without NA.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Descriptive Statistics (2)</span>"
    ]
  },
  {
    "objectID": "bivariate.html#cross-tabulation",
    "href": "bivariate.html#cross-tabulation",
    "title": "5  Bivariate Analysis",
    "section": "5.2 Cross Tabulation",
    "text": "5.2 Cross Tabulation\nA mosaic plot is a wonderful visualization, but we may also want to know the actual proportions of each tile. For this purpose, we may use R to produce a cross tabulation (or a crosstab). One way to do this requires two steps. First, we use the table() function to produce a cross tabulation in terms of the number of observations. Then, we apply the prop.table() function to transform the output of the table() function to the crosstab in terms of proportion or percentage.\n\n5.2.1 Cross Tabulation in Number of Observations: table()\nA basic syntax of the table() function is as follows.\n\n  table(variable_in_rows, variable_in_columns)\n\nIn other words, the first argument of the table() function is the variable that will appear in the rows, and the second argument is the variable in the columns. For the current purpose of examining the theory of economic voting, we want our dependent variable to appear in rows and independent variable in columns. Hence, the basic syntax of the table() function may also be written as below.\n\n  table(dependent_variable, independent_variable)\n\nLet’s apply this function to percep_economy_cps and satisfied_fedgovt.\n\n  table(ces2019$satisfied_fedgovt,   # table(dependent_variable, independent_variable)\n        ces2019$percep_economy_cps)\n\n            \n             Worse Same Better\n  Not At All   673  275     47\n  Not Very     399  554    178\n  Fairly       214  836    483\n  Very          17   67    100\n\n\nYou may have noticed that the categories of the dependent variable appear in rows in the order of the categories (or levels) from top to bottom, which is the opposite to the order of appearance in the mosaic plot. To show the dependent variable in the same order as in the mosaic plot, we need to reverse the order of categories (or levels) of satisfied_fedgovt. Let’s create a new variable satisfied_fedgovt2 in which the order of categories (levels) is reversed. See Section 4.2.5 for how to change the order of categories (levels).\n\nces2019 &lt;- mutate( ces2019, \n                   satisfied_fedgovt2 = fct_relevel(satisfied_fedgovt, \n                   \"Very\", \"Fairly\", \"Not Very\", \"Not At All\" ) ) \n\nCheck the new order by the levels() function.\n\nlevels(ces2019$satisfied_fedgovt2)\n\n[1] \"Very\"       \"Fairly\"     \"Not Very\"   \"Not At All\"\n\n\nApply the table() function to percep_economy_cps and the new variable satisfied_fedgovt2.\n\ntable( ces2019$satisfied_fedgovt2,      # table(dependent_variable, independent_variable)\n         ces2019$percep_economy_cps )\n\n            \n             Worse Same Better\n  Very          17   67    100\n  Fairly       214  836    483\n  Not Very     399  554    178\n  Not At All   673  275     47\n\n\nNow the categories of satisfied_fedgovt2 appear in the same way as in the mosaic plot that we produced in Section 5.1.\n\n\n5.2.2 Cross Tabulation in Proportion: prop_table()\nSince the crosstab derived above is in number of observations, let’s convert it to one in terms of proportion. We can do this by using the prop.table() function with the output of the table() function as its argument.\nFor this purpose, first assign the output of the table() function to a new object called tab.\n\n    # Use the assignment operator (\"&lt;-\") to assign the output of the table() function \ntab &lt;- table( ces2019$satisfied_fedgovt2,   # to a new object named \"tab.\" \n              ces2019$percep_economy_cps )   \n\nThen, use the prop.table() function as below.\n\n      # The first argument of prop.table() is the output of the table() function.\n      # The second argument specifies the type of proportion to be derived.\n  prop.table(tab, 2)  # The second argument 2 = column proportions are calculated.\n\n            \n                  Worse       Same     Better\n  Very       0.01304682 0.03868360 0.12376238\n  Fairly     0.16423638 0.48267898 0.59777228\n  Not Very   0.30621642 0.31986143 0.22029703\n  Not At All 0.51650038 0.15877598 0.05816832\n\n\nAbove we derived the crosstab in terms of proportion. The second argument of the prop.table() function specifies the type of proportion to be derived. If this is 2, the prop.table() function calculates column proportions — if we add up the proportions within each column, they will sum to one. This is what we want for our present purpose.\nBut we can also compute row proportions — if we add up the proportions within each row, they will sum to one. We can do this by specifying 1 in the second argument of the prop.table() function.\n\n  prop.table(tab, 1)  # The second argument 1 = row proportions are calculated.\n\n            \n                  Worse       Same     Better\n  Very       0.09239130 0.36413043 0.54347826\n  Fairly     0.13959556 0.54533594 0.31506849\n  Not Very   0.35278515 0.48983201 0.15738285\n  Not At All 0.67638191 0.27638191 0.04723618\n\n\nWithout the second argument, the prop.table() function calculates cell proportions — if we add up the proportions of all of the cells, they will sum to one.\n\n  prop.table(tab) # Without second argument = cell proportions are calculated.\n\n            \n                   Worse        Same      Better\n  Very       0.004423627 0.017434296 0.026021337\n  Fairly     0.055685662 0.217538381 0.125683060\n  Not Very   0.103825137 0.144158210 0.046317981\n  Not At All 0.175123601 0.071558678 0.012230029\n\n\nFor our current purpose, what we need is column proportions, therefore, we specify 2 for the second argument of the prop.table() function.\n\n\n5.2.3 Add Column (or Row) Totals to Crosstab\nSince we computed the column proportions, we may also want to add the column totals, which must be 1 for all columns, for clarity. We can use the addmargins() function for this purpose.\nWe assign the output of the prop.table() function to a new object, and use this new object as the first argument of the addmargins() function.\nIn the code below, I assign the output of the prop.table() function to a new object, called ptab, and use ptab as the first argument of the addmargins() function. The second argument of the addmargins() function is specified at 1, which instructs R to compute total of values for each column, or equivalently, across rows.\n\n# Use the assignment operator (\"&lt;-\") to assign the output of \n# the prop.table() function to a new object named \"ptab.\" \n  ptab &lt;- prop.table(tab, 2)\n\n# The second argument of the addmargins() function is 1 \n#       = values are summed up across rows = total for each column.\n  addmargins(ptab, 1) \n\n            \n                  Worse       Same     Better\n  Very       0.01304682 0.03868360 0.12376238\n  Fairly     0.16423638 0.48267898 0.59777228\n  Not Very   0.30621642 0.31986143 0.22029703\n  Not At All 0.51650038 0.15877598 0.05816832\n  Sum        1.00000000 1.00000000 1.00000000\n\n\nAs you can see, column totals are 1 for all columns. Adding column totals makes it clear that what we have in our crosstab are column proportions.\nAs you may expect, if we specify the second argument of the addmargins() function at 2, R will calculate total of values for each row, or equivalently, across columns.\n\n# The second argument of the addmargins() function is 2 \n#       = values are summed up across columns = total for each row.\n  addmargins(ptab, 2) \n\n            \n                  Worse       Same     Better        Sum\n  Very       0.01304682 0.03868360 0.12376238 0.17549279\n  Fairly     0.16423638 0.48267898 0.59777228 1.24468764\n  Not Very   0.30621642 0.31986143 0.22029703 0.84637489\n  Not At All 0.51650038 0.15877598 0.05816832 0.73344468\n\n\n\n\n5.2.4 Round Values in Crosstab\nIn the above crosstab, the values have too many decimal places. We may want to round them to fewer decimal places. We can use the round() function for this purpose. A basic syntax of the round() function is as follows.\n\n  round(object, number-of-desired-decimal-places) \n\nIt rounds the object specified in its first argument to the number of decimal places specified in its second argument.\nIn the code below, I assign the output of the addmargins() function to a new object, called ptab_total, and use ptab_total as the first argument of the round() function. The second argument of the round() function is specified at 2.\n\n  ptab_total &lt;- addmargins(ptab, 1) \n  round(ptab_total, 2)\n\n            \n             Worse Same Better\n  Very        0.01 0.04   0.12\n  Fairly      0.16 0.48   0.60\n  Not Very    0.31 0.32   0.22\n  Not At All  0.52 0.16   0.06\n  Sum         1.00 1.00   1.00\n\n\nSince the number specified in the second argument is 2, the values in the crosstab are rounded to two decimal places. By changing the number in the second argument, we can round the values in the corsstab to different decimal places. For example, below we round them to four decimal places.\n\n  round(ptab_total, 4)\n\n            \n              Worse   Same Better\n  Very       0.0130 0.0387 0.1238\n  Fairly     0.1642 0.4827 0.5978\n  Not Very   0.3062 0.3199 0.2203\n  Not At All 0.5165 0.1588 0.0582\n  Sum        1.0000 1.0000 1.0000\n\n\n\n\n5.2.5 Cross Tabulation in Percentage\nThe crosstab derived above is in terms of proportion. We can change this to one in terms of percentage by simply multiplying the result by 100.\n\n  round(ptab_total, 4) * 100  # We multiply the output of round(ptab_total, 4) by 100.\n\n            \n              Worse   Same Better\n  Very         1.30   3.87  12.38\n  Fairly      16.42  48.27  59.78\n  Not Very    30.62  31.99  22.03\n  Not At All  51.65  15.88   5.82\n  Sum        100.00 100.00 100.00\n\n\nThis crosstab shows the column percentage of each tile for the mosaic plot drawn before in Section 5.1.\n\n\n5.2.6 Sequential Operations on R Objects\nNote that when we derived the crosstab above, we created R objects sequentially by applying different R functions in each step. Below is a summary of these sequantial operations.\n\n  tab &lt;- table( ces2019$satisfied_fedgovt2,   \n                ces2019$percep_economy_cps )   \n  ptab &lt;- prop.table(tab, 2)\n  ptab_total &lt;- addmargins(ptab, 1) \n  round(ptab_total, 4) * 100  \n\n            \n              Worse   Same Better\n  Very         1.30   3.87  12.38\n  Fairly      16.42  48.27  59.78\n  Not Very    30.62  31.99  22.03\n  Not At All  51.65  15.88   5.82\n  Sum        100.00 100.00 100.00\n\n\nSpecifically, we first created an object called tab by the table() function. Then, we applied the prop.table() function to tab to create a new object named ptab. After that, the addmargins() function was applied to ptab to create ptab_total. Finally, the round function was applied to ptab_total to produce the crosstab shown above.\nIt is not unusual to use sequantial operations like this to edit R objects to produce the final object that we need.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate.html#sec-mosaic-plot",
    "href": "bivariate.html#sec-mosaic-plot",
    "title": "5  Bivariate Analysis",
    "section": "",
    "text": "5.1.1 New Package: ggmosaic\nTo draw a mosaic plot, we also need a new package ggmosaic, which works with the ggplot() function.\nInstall ggmosaic first if it has not been downloaded and installed on your computer. See Section 1.4.1 for how to install an R package.\nThen, load ggmosaic (Section 1.4.2).\n\n  library(ggmosaic)\n\n\n\n5.1.2 Prepare Variables\nWe are going to draw a mosaic plot for satisfied_fedgovt and percep_economy_cps from the ces2019 data frame. This can be considered as a simple test of the theory of economic voting. In this analysis, percep_economy_cps is the independent variable, and satisfied_fedgovt is the dependent variable.\nBefore visualizing the relationship, we first edit these two variables. Recall what we did for percep_economy_cps in Section 4.2. We change the names of their categories or levels to simpler ones (Section 4.2.6) and change the order of the categories or levels (Section 4.2.5).\nTo change the names of the categories or levels, we use the fct_recode() function (Section 4.2.6). Recall its basic syntax. (Don’t execute the following code, which is intended to show you the syntax only.)\n\nfct_recode(factor_variable, \n              \"New Name of Level 1\" = \"Original Name of Level 1\", \n              \"New Name of Level 2\" = \"Original Name of Level 2\", \n              \"New Name of Level 3\" = \"Original Name of Level 3\") \n\nTo change the order of categories or levels, we use the fct_relevel() function (Section 4.2.5). Recall the following basic syntax. (Once again, don’t run the following code, which is intended to show you the syntax only.)\n\n      fct_relevel(factor_variable, \n          \"First Level\", \"Second Level\", \"Third Level\")\n\nLet’s edit precep_economy_cps using these functions. In Section 4.2, we created a new variable to reflect the edits, but here we instead update percep_economy_cps with these edits. In the following code, the left hand side of = in the mutate() function is percep_economy_cps instead of precep_economy_cps2 or percep_economy_cps3 used in the previous lab session. In this way, we can update the content of percep_economy_cps.\n\nces2019 &lt;- mutate(ces2019,\n  percep_economy_cps = fct_recode(percep_economy_cps,\n    \"Worse\" = \"(2) Worse\",\n    \"Same\" = \"(3) About the same\",\n    \"Better\" = \"(1) Better\") )\n\n\nces2019 &lt;- mutate(ces2019,\n  percep_economy_cps = fct_relevel(percep_economy_cps,\n    \"Worse\", \"Same\", \"Better\") )\n\nWe also edit satisfied_fedgovt as follows.\n\nces2019 &lt;- mutate(ces2019,\n  satisfied_fedgovt = fct_recode(satisfied_fedgovt,\n    \"Not At All\" = \"(4) Not satisfied at all\",\n    \"Not Very\" = \"(3) Not very satisfied\",\n    \"Fairly\" = \"(2) Fairly satisfied\",\n    \"Very\" = \"(1) Very satisfied\") )\n\n\nces2019 &lt;- mutate(ces2019, \n  satisfied_fedgovt = fct_relevel(satisfied_fedgovt, \n    \"Not At All\", \"Not Very\", \"Fairly\", \"Very\")) \n\n\n\n5.1.3 Draw a Mosaic Plot: ggplot() + geom_mosaic()\nLet’s draw a mosaic plot for percep_economy_cps and satisfied_govt. Below is the minimum specification for the ggplot() + geom_mosaic() functions. Read the comments in the code below for an explanation for the basic syntax.\n\n                    # Specify the data frame used inside ggplot(). \nggplot(ces2019) +   # aes() is now specified in geom_mosaic() instead of ggplot().\n  geom_mosaic( aes(x = product(percep_economy_cps),  # x = product(independent_variable)\n                   fill = satisfied_fedgovt) )       # fill = dependent_variable\n\n\n\n\n\n\n\n\n\n\n5.1.4 Remove NA: drop_na()\nThe mosaic plot drawn above includes missing observations (NA). As we did before in Section 4.2.7, let’s remove these missing observations using the drop_na() function. Recall the basic syntax of the drop_na() function below.\n\n  drop_na(name_of_data_frame, name_of_variable)\n\nThe drop_na() function looks for the observations for which the variable in the second argument (name_of_variable above) is missing (NA) and removes these observations from the data frame in the first argument (name_of_data_frame). So in the code below, the drop_na() function looks for the observations in ces2019 for which percep_economy_cps is missing (NA), and removes these observations from ces2019.\n\n  drop_na(ces2019, percep_economy_cps)\n\nUse drop_na(ces2019, percep_economy_cps) instead of ces2019 inside the ggplot() function.\n\n    # drop_na() here removes the missing observations (NA) for percep_economy_cps from ces2019.\nggplot( drop_na(ces2019, percep_economy_cps) ) +    \n  geom_mosaic( aes(x = product(percep_economy_cps),  \n                   fill = satisfied_fedgovt) )        \n\n\n\n\n\n\n\n\nAs you see in the above plot, now the missing observations for percep_economy_cps were removed, but those for satisfied_fedgovt still remain. To remove the missing observations for satisfied_fedgovt, we also need to include this variable in the drop_na() function.\n\n    # drop_na() here removes the missing observations (NA) for both percep_economy_cps \n    # and satisfied_fedgovt from ces2019.\nggplot( drop_na(ces2019, percep_economy_cps, satisfied_fedgovt) ) +    \n  geom_mosaic( aes(x = product(percep_economy_cps),  \n                   fill = satisfied_fedgovt) )        \n\n\n\n\n\n\n\n\nNow the missing observations for satisfied_fedgove are removed as well.\n\n\n5.1.5 Other Edits: show.legend, scale_fill_manual()\nPerhaps we don’t need the legend, as the category names are also shown on the vertical axis. We can remove the legend by specifying show.legend = FALSE in the geom_mosaic() function.\n\nggplot(drop_na(ces2019, percep_economy_cps, satisfied_fedgovt)) +\n  geom_mosaic(aes(x = product(percep_economy_cps), fill = satisfied_fedgovt), \n              show.legend = FALSE)          # show.legend = FALSE removes the legend.\n\n\n\n\n\n\n\n\nYou can also specify the colors of the mosaic tiles by adding the scale_fill_manual() function. Recall that you can look up the names of the colors used in R online, for example, here and here.\n\nggplot(drop_na(ces2019, percep_economy_cps, satisfied_fedgovt)) +\n  geom_mosaic(aes(x = product(percep_economy_cps), fill = satisfied_fedgovt), \n              show.legend = FALSE) +\n          # Below, you need to specify the colors for each category of your dependent variable.\n          # Don't forget to include the names of the colors in c().\n  scale_fill_manual(values = c(\"lightsteelblue2\", \"steelblue1\", \"steelblue3\", \"steelblue4\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can of course use the functions you learned before to further edit the plot. For example, below I added the labels for both y and x axes.\n\nggplot(drop_na(ces2019, percep_economy_cps, satisfied_fedgovt)) +\n  geom_mosaic(aes(x = product(percep_economy_cps), fill = satisfied_fedgovt), \n              show.legend = FALSE) +\n  scale_fill_manual(values = c(\"lightsteelblue2\", \"steelblue1\", \"steelblue3\", \"steelblue4\")) +\n  ylab(\"Satisfied with Government\") +   # Change the label at y-axis.\n  xlab(\"Perception of Economy\")         # Change the label at x-axis.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate.html#scatterplot",
    "href": "bivariate.html#scatterplot",
    "title": "5  Bivariate Analysis",
    "section": "5.3 Scatterplot",
    "text": "5.3 Scatterplot\nWhen two variables are both quantitative variables taking many values, we may use a scatterplot to visualize the relationship.\n\n5.3.1 Basic Scatterplot: ggplot() + geom_point()\nBelow we will draw a scatterplot for democrat and ranney3_gub_prop from the usstates2020 data frame. As you can see in the codebook for usstates2020, democrat is the percent of Democratic identifiers — individuals who identify themselves as Democrats — in each state, and ranney3_gub_prop is the proportion of two-party vote for a democratic gubernatorial candidate. We would expect a positive relationship between these two variables. Let’s see whether there is indeed a positive relationship by drawing a scatterplot.\nWe can draw a scatterplot by adding the geom_point() function to the ggplot() function. Note that the aes() function is the argument of the ggplot() function this time. Within the aes() function, we need to specify the independent variable (x = ) and the dependent variable (y = ).\n\n      # aes() is specified in the ggplot() function. It should indicate the independent \nggplot(usstates2010,           # variable (x = ) and the dependent variable (y = ).\n       aes(x = democrat, y = ranney3_gub_prop)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe scatterplot above suggests that there seems to be a positive relationship, but there are some outliers in the upper left quadrant — some states recorded a very high two party vote share for a Democratic gubernatorial candidate even with a relatively low proportion of Democratic identifiers. The warning message above indicates that there are two observations removed from the visualization because they have missing values for either ranney3_gub_prop or democrat.\nWe can change the shape, size, and color of the points by specifying the shape, col, and size arguments in the geom_point() function as follows.\n\nggplot( usstates2010, \n        aes(x = democrat, y = ranney3_gub_prop) ) +\n  geom_point( shape = 21, col = \"blue\", size = 3 ) # shape, col, and size arguments added.\n\n\n\n\n\n\n\n\nR uses numbers and a few symbols to specify the shape of points. You can look up the shape of points used in R online, for example here (see Figure 5.6, and ignore the rest). As we have already seen, you can find the colors used in R online as well, for example, here and here. You may specify a different number for size to see how the points will change.\nWe may want to display both variables in percentage by multiplying ranney3_gub_prop by 100.\n\nggplot( usstates2010,       # ranney3_gub_prop is multiplied by 100.\n        aes(x = democrat, y = ranney3_gub_prop * 100) ) + \n  geom_point( shape = 21, col = \"blue\", size = 3 )\n\n\n\n\n\n\n\n\nYou can further edit this scatterplot using the functions you have learned. See an example below.\n\nggplot( usstates2010,       \n        aes(x = democrat, y = ranney3_gub_prop * 100) ) + \n  geom_point( shape = 21, col = \"blue\", size = 3 ) +\n  xlab(\"Democratic Identifiers (%)\") +\n  ylab(\"Two-Party Vote Share (%) \\nDemocratic Gubernatorial Candidate\") +\n  coord_cartesian(ylim = c(0, 100), xlim=c(15,75)) +\n  scale_x_continuous(breaks = seq(0, 100, 10)) +\n  scale_y_continuous(breaks = seq(0, 100, 10))\n\n\n\n\n\n\n\n\n\n\n5.3.2 Scatterplot by Name of Observations: ggplot() + geom_text()\nSo far we have seen scatterplots by points. We can also use texts instead of points to draw scatterplots. For this purpose, we replace the geom_point() function with the geom_text() function and specify the texts used in a scatterplot in the label argument in the aes() function inside the ggplot() function.\nSee the example below.\n\nggplot(usstates2010, \n       aes(x = democrat, y = ranney3_gub_prop, \n           label = \"test\") ) +  # Specify texts in the label argument in the aes() function.\n  geom_text()                   # Then, use the geom_text() function.\n\n\n\n\n\n\n\n\nIf we specify a single text for the label argument as in the above example, that text is used for all data points. In the above example, I specified label = \"test\", then as you can see, test was used for all data points.\nOr we can specify a variable in the data frame for the label argument. Then, the values of this variable are used for each observation. For the present example, it is useful if we have the name of states for each data point. In the usstates2010 data frame, state is a variable on the name of states, and st is state postal codes. Look up these variables in the usstates2010 data frame by the View() function (alternatively, you can click the name of the data frame in the Environment tab in the upper right pane).\n\n  View(usstates2010)\n\n\nBelow I used st in the label argument.\n\nggplot(usstates2010, \n       aes(x = democrat, y = ranney3_gub_prop, \n           label = st) ) +     # Specify a variable in the label argument in the aes() function.\n  geom_text()                  # Then, use the geom_text() function.\n\n\n\n\n\n\n\n\nWe can change the size and color of texts by specifying the size and col arguments in the geom_text() function as follows.\n\nggplot( usstates2010, \n        aes( x = democrat, y = ranney3_gub_prop, \n             label = st ) ) +\n              # Try other numbers for the size argument to see \n  geom_text( size=2.5, col=\"blue\" )  # how the size of texts changes.\n\n\n\n\n\n\n\n\nNow we can see that the outliers in the upper left quadrant are Colorado (CO), West Virginia (WV), Montana (MT), and Arkansas (AR).\nWe can of course further edit this scatterplot using the functions we have learned.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate.html#line-chart-conditional-means",
    "href": "bivariate.html#line-chart-conditional-means",
    "title": "5  Bivariate Analysis",
    "section": "5.4 Line Chart & Conditional Means",
    "text": "5.4 Line Chart & Conditional Means\nNow we consider the case in which the dependent variable (y) is a quantitative variable and the independent variable (x) is a categorical variable or a quantitative variable taking a relatively small number of values. In this combination of the types of variables, we may examine the conditional distributions of y across different values of x. In this example, we examine the relationship between percep_economy_cps and trudeau_therm_cps in the ces2019 data frame. This is another simple test of the theory of economic voting.\nFirst, let’s try a scatterplot.\n\nggplot( ces2019, \n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n  geom_point( size = 0.05 )\n\n\n\n\n\n\n\n\nRemove the missing observations from the plot using the drop_na() function.\n\nggplot( drop_na(ces2019, percep_economy_cps),   # Use drop_na() to remove missing observations.\n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n  geom_point( size = 0.05 )\n\n\n\n\n\n\n\n\nFor this combination of variables, this scatterplot doesn’t seem to be very informative.\n\n5.4.1 Jittered Scatterplot: ggplot() + geom_jitter()\nOne problem in the above plot is that there seem to be many observations taking the same or very close values, so that multiple observations fall upon exactly the same or very close place. We cannot gauge how many observations are taking which values in this plot.\nOne possible remedy is to jitter the plots. By jittering, we add some random noise to the values of each point, so that the observations taking the same value are spread around this value. To draw a jittered scatterplot, we replace the geom_point() function with the geom_jitter() function.\n\nggplot( drop_na(ces2019, percep_economy_cps), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n  geom_jitter( size = 0.05 )\n\n\n\n\n\n\n\n\nAs you can see, now the points taking the same values are spread around those values. There seems to be too much jittering in this plot, however. We can control the width and height arguments of the geom_jitter() function to control the amount of random noise added to each point. The width argument controls the amount of noise in the horizontal direction, and the height argument in the vertical direction.\n\nggplot( drop_na(ces2019, percep_economy_cps), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n    # width = the amount of noise added in the horizontal direction.\n    # height = the amount of noise in the vertical direction.\n  geom_jitter( size = 0.05, width = 0.2, height = 0.5 ) \n\n\n\n\n\n\n\n\nIn the above jittered plot, the observations are nicely spread out, so that we can gauge the number of observations falling on the same or similar values more intuitively. Now we can compare the conditional distributions of y across different values of x. From this comparison, there seems to be a positive relationship between these two variables. However, the relationship between these two variables may not be very clear from this visualization. Perhaps, it’s better to SUMMARIZE the conditional distributions of y across different values of x.\n\n\n5.4.2 Conditional Means: ggplot() + geom_point()\nFirst, let’s draw the conditional means of y = trudeau_therm_cps given x = percep_economy_cps. We can do this by modifying the geom_point() function. See an example below.\n\nggplot( drop_na(ces2019, percep_economy_cps), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps, \n             group = 1) ) +  # group = 1 is needed to draw summary statistics.\n         # stat = \"summary\" tells geom_point() to draw summary statistics.\n         # fun = mean specifies that the mean is used as the summary statistics.\n  geom_point( stat = \"summary\", fun = mean )\n\n\n\n\n\n\n\n\nThe stat = \"summary\" argument tells the geom_point() function to draw summary statistics instead of each observation point. The fun = mean argument tells the geom_point() function to use the (conditional) mean for the summary statistics. We also need to specify group = 1 in the aes() function inside the ggplot() function to draw the conditional means in a plot.\nThen, as you can see above, the ggplot() + geom_point() functions draw the plot of conditional means of y across different values of x.\n\n\n5.4.3 Line chart: ggplot() + geom_line()\nWe may also draw a line chart for the conditional means of y across different values of x. For this purpose, we replace the geom_point() function with the geom_line() function.\n\nggplot( drop_na(ces2019, percep_economy_cps), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps, \n             group = 1)) +  # group = 1 is needed to draw summary statistics.\n  # Use the geom_line() function instead of the geom_point() function.\n         # stat = \"summary\" tells geom_point() to draw summary statistics.\n         # fun = mean specifies that the mean is used as the summary statistics.\n  geom_line( stat = \"summary\", fun = mean )\n\n\n\n\n\n\n\n\nWe can also combine the plot and the line chart of the conditional means by simply connecting both geom_point() and geom_line() functions derived above.\n\nggplot( drop_na(ces2019, percep_economy_cps), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps, \n             group = 1 ) ) +\n  geom_point( stat = \"summary\", fun = mean ) + # Connect the geom_point() and geom_line()\n  geom_line( stat = \"summary\", fun = mean )   # functions using a plus sign \n\n\n\n\n\n\n\n\nWe can also add the shape, size, and color arguments to control the appearance of the points and line.\n\nggplot( drop_na(ces2019, percep_economy_cps), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps, \n             group = 1 ) ) +\n                                      # Use the shape, size, and color arguments.\n  geom_point( stat = \"summary\", fun = mean, shape = 17, size = 3.5, color = \"purple\" ) +\n  geom_line( stat = \"summary\", fun = mean, color = \"purple\" )\n\n\n\n\n\n\n\n\nBelow I further edit the line chart with the functions we have learned so far.\n\nggplot( drop_na(ces2019, percep_economy_cps), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps, \n             group = 1 ) ) +\n  geom_point( stat = \"summary\", fun = mean, shape = 17, size = 3.5, color = \"purple\" ) +\n  geom_line( stat = \"summary\", fun = mean, color = \"purple\" ) +\n  xlab( \"Perception of Economy\" ) +\n  ylab( \"Feeling Thermometer for Trudeau\" ) +\n  coord_cartesian( ylim = c(0, 100) ) +\n  scale_y_continuous(breaks = seq(0, 100, 10))\n\n\n\n\n\n\n\n\nThe above line chart of the conditional mean of y across values of x is an appropriate visualization to summarize the conditional distributions of y across x.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate.html#box-plots-ggplot-geom_boxplot",
    "href": "bivariate.html#box-plots-ggplot-geom_boxplot",
    "title": "5  Bivariate Analysis",
    "section": "5.5 Box Plots: ggplot() + geom_boxplot()",
    "text": "5.5 Box Plots: ggplot() + geom_boxplot()\n\n5.5.1 Box Plots\nAnother appropriate visualization of the conditional distributions of y across different values of x is box plots of y across x. We can draw such box plots by the ggplot() + geom_boxplot() functions with the independent variable (x) and the dependent variable (y) specified in the aes() function inside the ggplot() function, as in the example below.\n\nggplot( ces2019,   \n        aes( x = percep_economy_cps,       # Specify the independent variable ( x = ) and \n             y = trudeau_therm_cps  ) ) +  # the dependent variable ( y = ) in the aes()\n  geom_boxplot()                           # function inside the ggplot() function.\n\n\n\n\n\n\n\n\nLet’s remove the missing observations by the drop_na() function.\n\nggplot( drop_na( ces2019, percep_economy_cps ),  # Use drop_na() to remove missing observations.\n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n  geom_boxplot() \n\n\n\n\n\n\n\n\nWe can also control the width of the boxes by the width argument in the geom_boxplot() function.\n\nggplot( drop_na( ces2019, percep_economy_cps ), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n  geom_boxplot( width=0.45 )  # Use the width argument to control the width of boxes. \n\n\n\n\n\n\n\n\nWe can also reflect the relative frequency of each category of x in the width of each box by specifying the varwidth argument to equal TRUE in the geom_boxplot() function. The category with a larger number of observations will have a wider width than the category with a smaller number of observations.1\n\nggplot( drop_na( ces2019, percep_economy_cps ), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n  # Specifying varwidth = TRUE, the width of each box will reflect the relative frequency \n  geom_boxplot( varwidth = TRUE, width=0.45 ) # (the number of observations) in each category of x.    \n\n\n\n\n\n\n\n\nIn the above box plots, the width of each box reflects the relative frequency of each category of percep_economy_cps. Recall the bar chart we drew for this variable in Chapter 4, which I have redrawn below for your reference. As you can see, the mode is same, and better has the smallest number of observations. Reflecting this, the width of same is the widest in the box plots above, and that of better is the narrowest.\n\n\n\n\n\n\n\n\n\nSpecifying the varwidth = TRUE may be convenient as we can also see the relative frequency of each category of x at a glance in our box plots.\nWe can further edit the box plots by the functions we have learned.\n\nggplot( drop_na( ces2019, percep_economy_cps ), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n  geom_boxplot( varwidth = TRUE, width = 0.45, fill = \"cyan4\", coef = 0.75 ) +\n  xlab(\"Perception of Economy\") +\n  ylab(\"Feeling Thermometer for Trudeau\")\n\n\n\n\n\n\n\n\nBox plots nicely summarize the conditional distributions of y across x with the conditional medians, IQR, and outliers visualized succinctly.\n\n\n5.5.2 Horizontal Box Plots\nThe box plots we saw above are vertical box plots. It is also possible to change them to horizontal box plots. For example, if we want to flip the vertical box plots for the Trudeau thermometer and the perception of economy drawn above to horizontal box plots, we simply add “+ coord_flip()” to the ggplot() function.\n\nggplot( drop_na( ces2019, percep_economy_cps ), \n        aes( x = percep_economy_cps, y = trudeau_therm_cps ) ) +\n    geom_boxplot( varwidth = TRUE, width = 0.45, fill = \"cyan4\", coef = 0.75 ) +\n  xlab(\"Perception of Economy\") +\n  ylab(\"Feeling Thermometer for Trudeau\") +\n  coord_flip()        # Add the coord_flip() function.\n\n\n\n\n\n\n\n\nWe may not want to use the above horizontal box plots for the current purpose because the Trudeau thermometer is used as a dependent variable and we may prefer having the dependent variable on the vertical axis. On the other hand, if our dependent variable is a categorical variable or interval quantitative variable taking a small number of categories or values and our independent variable is an interval quantitative variable taking many values, then horizontal box plots may be useful to visualize their relationship.\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose our dependent variable is the perception of economy and the independent variable is respondent’s age (age in the ces2019 data frame). Then, we can visualize their relationship using the horizontal box plots as below.\n\nggplot( drop_na( ces2019, percep_economy_cps ), \n        # You need to specify x = dependent_variable, y = independent_variable\n        # for the current purpose.\n        aes( x = percep_economy_cps, y = age) ) +  \n    geom_boxplot( varwidth = TRUE, width = 0.45, fill = \"dodgerblue\", coef = 0.75 ) +\n  xlab(\"Perception of Economy\") +\n  ylab(\"Age\") +\n  coord_flip() +      # Add the coord_flip() function.\n  scale_y_continuous(breaks = seq(20, 100, 10))\n\n\n\n\n\n\n\n\nAn important trick here is that you need to specify your dependent variable for x = and your independent variable for y = in the aes() function because these variables are specified for vertical box plots first, and then they are flipped to horizontal box plots.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate.html#conditional-means-medians",
    "href": "bivariate.html#conditional-means-medians",
    "title": "5  Bivariate Analysis",
    "section": "5.6 Conditional Means & Medians",
    "text": "5.6 Conditional Means & Medians\nIn the previous sections, we visualized the conditional means using a line chart and the conditional medians using boxplots. However, we have not computed the numerical values of these summary statistics. Let’s learn how to compute actual values of the conditional means and medians.\n\n5.6.1 Conditional Means\nTo compute the conditional means and medians, it is convenient to use the pipe operator (|&gt;) together with the group_by() function and the summarize() function in tidyverse.2\nFor brevity, let me first present the code to compute the conditional means without explanation. I will explain it line by line later.\n\nces2019 |&gt; \n    group_by(percep_economy_cps) |&gt;  \n    summarize( cond_mean = mean(trudeau_therm_cps, na.rm = TRUE) )\n\n# A tibble: 4 × 2\n  percep_economy_cps cond_mean\n  &lt;fct&gt;                  &lt;dbl&gt;\n1 Worse                   25.1\n2 Same                    49.1\n3 Better                  61.9\n4 &lt;NA&gt;                    45.0\n\n\nThe above code produced a table of conditional means of trudeau_therm_cps for each category of percep_economy_cps. The conditional means are named cond_mean.\nThe pipe operator (|&gt;) sends an R object on its left-hand side into a function on its right-hand side as an argument. We say it pipes an R object to a function.\nBelow is a line-by-line explanation of how the above code works.\n\nces2019 |&gt;\n  # The ces2019 data frame is piped to the group_by() function by the pipe operator (|&gt;).\n    \n    group_by(percep_economy_cps) |&gt;\n      # Observations in the ces2019 data frame are grouped by the categories of percep_economy_cps\n      # by the group_by() function, and its output (the grouped data frame) is piped to the  \n      # summarize() function by the pipe operator (|&gt;).\n    \n    summarize(cond_mean = mean(trudeau_therm_cps, na.rm = TRUE))\n      # The summarize() function applies the mean() function to trudeau_therm_cps for each \n      # group in the ces2019 data frame created by the group_by() function. This generates \n      # the conditional means for each category of percep_economy_cps and assigns them to \n      # a new object named cond_mean.\n\n\n\n5.6.2 Conditional Medians\nSimilarly, we can compute the conditional medians. We just need to replace the mean() function in the above code with the median() function.\n\nces2019 |&gt;\n    group_by(percep_economy_cps) |&gt;\n    summarize(cond_median = median(trudeau_therm_cps, na.rm = TRUE) )\n\n# A tibble: 4 × 2\n  percep_economy_cps cond_median\n  &lt;fct&gt;                    &lt;dbl&gt;\n1 Worse                       15\n2 Same                        50\n3 Better                      70\n4 &lt;NA&gt;                        50\n\n\n\n\n5.6.3 Pipe Operator (|&gt;) for Sequantial Operations\nThe pipe operator (|&gt;) is convenient when we create R objects sequentially by applying different R functions in each step. For example, in Section 5.2.6, we have edited the crosstab by creating R objects sequentially. For your reference, I have recreated the code below.\n\n  tab &lt;- table( ces2019$satisfied_fedgovt2,   \n                ces2019$percep_economy_cps )   \n  ptab &lt;- prop.table(tab, 2)\n  ptab_total &lt;- addmargins(ptab, 1) \n  round(ptab_total, 4) * 100  \n\n            \n              Worse   Same Better\n  Very         1.30   3.87  12.38\n  Fairly      16.42  48.27  59.78\n  Not Very    30.62  31.99  22.03\n  Not At All  51.65  15.88   5.82\n  Sum        100.00 100.00 100.00\n\n\nIn this example, we have sequentially created tab, ptab, and ptab_total. Then, we have finally applied the round() function to ptabl_total and multiply it by 100 to print the crosstab in percentage rounded to two decimal places.\nThe same operations can be done using the pipe operator (|&gt;) as below. For brevity, I first present the code without explanation and will explain it line by line later.\n\n  table( ces2019$satisfied_fedgovt2,   \n                ces2019$percep_economy_cps ) |&gt;\n  prop.table(2) |&gt;\n  addmargins(1) |&gt; \n  round(4) * 100  \n\n            \n              Worse   Same Better\n  Very         1.30   3.87  12.38\n  Fairly      16.42  48.27  59.78\n  Not Very    30.62  31.99  22.03\n  Not At All  51.65  15.88   5.82\n  Sum        100.00 100.00 100.00\n\n\nBelow is a line by line explanation for this code. As this example clarifies, the R object sent by the pipe operator (|&gt;) to a function is used as the first argument of this function.\n\n  # First, use the table() function to produce the raw crosstab.  \n  table( ces2019$satisfied_fedgovt2,   \n                ces2019$percep_economy_cps ) |&gt;\n      # Then, use the pipe oprator (\"|&gt;\") to send the ouput of the table () function \n      # to the first argument of the prop.table() function.\n  prop.table(2) |&gt;\n      # Use the pipe oprator (\"|&gt;\") again to send the ouput of the prop.table () function \n      # to the first argument of the addmargins() function.\n  addmargins(1) |&gt; \n      # Use the pipe oprator (\"|&gt;\") one more time to send the ouput of the addmargins () function \n      # to the first argument of the round() function.\n  round(4) * 100  \n\n            \n              Worse   Same Better\n  Very         1.30   3.87  12.38\n  Fairly      16.42  48.27  59.78\n  Not Very    30.62  31.99  22.03\n  Not At All  51.65  15.88   5.82\n  Sum        100.00 100.00 100.00\n\n\nIn the above example, we have created and printed the crosstab in percentage rounded to two decimal places, but have not assigned this result to a specific object. Of course, we can use the assignment operator (&lt;-) to create it. Below we assign this crosstab to an object named percent_tab.\n\n  percent_tab &lt;- table( ces2019$satisfied_fedgovt2,   \n                ces2019$percep_economy_cps ) |&gt;\n  prop.table(2) |&gt;\n  addmargins(1) |&gt; \n  round(4) * 100  \n\nThen, we can use the print() function to print the crosstab on the Console.\n\n  print(percent_tab)\n\n            \n              Worse   Same Better\n  Very         1.30   3.87  12.38\n  Fairly      16.42  48.27  59.78\n  Not Very    30.62  31.99  22.03\n  Not At All  51.65  15.88   5.82\n  Sum        100.00 100.00 100.00\n\n\nOr we can simply type in the name of the object, precent_tab, in the Console to do the same.\n\n  percent_tab\n\n            \n              Worse   Same Better\n  Very         1.30   3.87  12.38\n  Fairly      16.42  48.27  59.78\n  Not Very    30.62  31.99  22.03\n  Not At All  51.65  15.88   5.82\n  Sum        100.00 100.00 100.00",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "bivariate.html#footnotes",
    "href": "bivariate.html#footnotes",
    "title": "5  Bivariate Analysis",
    "section": "",
    "text": "More precisely, the width of each box is made proportional to the square root of the number of observations in each category of x.↩︎\nAn alternative pipe operator (%&gt;%) is also available in tidyverse. You may use %&gt;% instead of |&gt; if you have loaded tidyverses into your current R session.↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "simp_linreg.html",
    "href": "simp_linreg.html",
    "title": "6  Simple Linear Regression",
    "section": "",
    "text": "6.1 Linear Regression for Bivariate Analysis",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "simp_linreg.html#linear-regression-for-bivariate-analysis",
    "href": "simp_linreg.html#linear-regression-for-bivariate-analysis",
    "title": "6  Simple Linear Regression",
    "section": "",
    "text": "6.1.1 Simple Linear Regression\nIn this chapter, we will estimate a simple linear regression model with only one independent variable. In other words, we examine a bivariate relationship between a dependent variable and an independent variable using linear regression.\nIn R, we use the lm() function to estimate a linear regression model. At minimum, the lm() function takes two arguments. A basic syntax of the lm() function in this case is as follows.\n\n  lm(formula = dependent_variable ~ independent_variable, data = data_frame_used)\n\nThe first argument of the lm() function is the formula argument. We specify our linear regression model in this argument. Suppose the model we try to estimate is given by the following formula. \\[\n  Y = \\alpha + \\beta X + u\n\\tag{6.1}\\]\nThen, we specify the formula argument in the lm function as formula = Y ~ X. That is, ignoring the coefficients, \\(\\alpha\\) and \\(\\beta\\), we write the dependent variable Y on the left-hand side of tilde, ~, and the independent variable X on the right-hand side.\nThe second argument of the lm() function is the data argument in which we specify the name of the data frame we are using.\nLet’s estimate a linear regression using the usstates2010 data frame, in which the dependent variable is ranney3_gub_prop and the independent variable is democrat. As we saw in Section 5.3, democrat is the percent of Democratic identifiers — individuals who identify themselves as Democrats — in each state, and ranney3_gub_prop is the proportion of two-party vote for a democratic gubernatorial candidate. We would expect a positive relationship between these two variables.\n\n  lm(formula = ranney3_gub_prop ~ democrat, data = usstates2010)\n\n\nCall:\nlm(formula = ranney3_gub_prop ~ democrat, data = usstates2010)\n\nCoefficients:\n(Intercept)     democrat  \n   0.267577     0.006604  \n\n\nAt the bottom of the output, we can see the list of coefficients estimated. The number below (Intercept) is the intercept of the linear regression model. This is an estimate of \\(\\alpha\\) in the linear regression model in Equation 6.1. The number below democrat is the coefficient of the democrat variable. This is an estimate of \\(\\beta\\) in the linear regression model in Equation 6.1.\nRecall that ranney3_gub_prop is measured in proportion, a number between 0 and 1, and democrat is measured in percentage, a number between 0 and 100. We can check this by the summary() function.\n\n  summary(usstates2010$ranney3_gub_prop)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.2402  0.4071  0.4708  0.4776  0.5355  0.8209       2 \n\n  summary(usstates2010$democrat)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  17.73   27.39   32.52   31.79   34.37   63.20 \n\n\nIt is better to measure them in the same unit. Let’s create a new variable for the two-party vote share of a democratic gubernatorial candidate measured in percentage. Below I create a new variable called gov_vts by using the mutate() function and multiplying ranney3_gub_prop by 100.\n\n  usstates2010 &lt;- mutate(usstates2010, gov_vts = ranney3_gub_prop * 100)\n\nThen, re-estimate the above linear regression model using this new variable.\n\n  lm(formula = gov_vts ~ democrat, data = usstates2010)\n\n\nCall:\nlm(formula = gov_vts ~ democrat, data = usstates2010)\n\nCoefficients:\n(Intercept)     democrat  \n    26.7577       0.6604  \n\n\nThe coefficient on democrat is 0.66. According to this model, a one percentage-point increase in the Democratic identifiers would lead to, on average, a 0.66 percentage-point increase in the two party vote share of a Democratic gubernatorial candidate.\n\n\n6.1.2 Scatterplot with Linear Regression Line\nIn Section 5.3, we drew a scatterplot of the percentage of Democratic identifiers and the Democratic gubernatorial candidate’s vote share. Let’s add a linear regression line to this scatterplot.\nFirst, let’s redraw the scatterplot.\n\nggplot( usstates2010, \n        aes( x = democrat, y = gov_vts, label = st ) ) +\n  geom_text( size = 2.5, col = \"blue\" ) \n\n\n\n\n\n\n\n\nTo draw a linear regression line, we add the geom_smooth() function with the arguments specified below to our scatterplot.\n\nggplot( usstates2010, \n        aes( x = democrat, y = gov_vts, label = st ) ) +\n  geom_text( size = 2.5, col = \"blue\" )  +  # Add geom_smooth() with two arguments,\n  geom_smooth( method = \"lm\", se = FALSE)   #   method = \"lm\" and se = FALSE.\n\n\n\n\n\n\n\n\nThe geom_smooth() function draws a “smoothed” line for the conditional means of y over the values of x in various methods. As we want to draw a linear regression line, we should specify the method argument to lm, which is the function name for a linear regression model in R. If we don’t set the se argument to FALSE, the geom_smooth() function also draws a confidence interval, which is one of the methods of statistical inference. You will learn about confidence intervals later in the semester. As you haven’t learned it yet, let’s set it aside for now.\nYou can also edit the appearance of a linear regression line by specifying the arguments in the geom_smooth() function. Below I used the col (or color or colour) argument to specify color of the line, linetype to set type of the line, and size to change line width. You can find different line types used in R online, for example here. Recall that you can also look up names of colors used in R online, for example, here and here.\n\nggplot( usstates2010, \n        aes( x = democrat, y = gov_vts, label = st ) ) +\n  geom_text( size = 2.5, col = \"blue\" )  +  \n  geom_smooth( method = \"lm\", se = FALSE,    # Add the col, linetype, and size arguments.\n               col =  \"red\", linetype = \"dashed\", size = 0.5)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "simp_linreg.html#ordinal-categorical-variable-in-simple-linear-regression",
    "href": "simp_linreg.html#ordinal-categorical-variable-in-simple-linear-regression",
    "title": "6  Simple Linear Regression",
    "section": "6.2 Ordinal Categorical Variable in Simple Linear Regression",
    "text": "6.2 Ordinal Categorical Variable in Simple Linear Regression\n\n6.2.1 Use Ordinal Categorical Variable As Independent Variable\nNext we use the ces2019 data frame and estimate a linear regression of trudeau_therm_cps on percep_economy_cps. Note that we say that we estimate (or fit) a linear regression of Y on X or we regress Y on X when Y is a dependent variable and X is an independent variable in our linear regression model.\nRecall that percep_economy_cps is an ordinal categorical variable. We cannot use this variable as it is in a linear regression model, because both dependent and independent variables in a linear regression model must be numbers. To estimate a linear regression of trudeau_therm_cps on percep_economy_cps, we first need to assign numbers to each category of percep_economy_cps. Since percep_economy_cps is an ordinal variable, it makes sense to assign numbers corresponding to the order of the categories. As an ordinal categorical variable is stored as a factor in R, we need to transform this variable to a numeric variable.\nAs we saw before in Section 4.3.3, we can transform a factor to a numeric by the as.numeric() function, which preserves the order of levels() (= categories) assigned to a factor variable.\nLet’s create percep_economy_cps_n as we did before.\n\n  ces2019 &lt;- mutate(ces2019, \n      percep_economy_cps = fct_relevel(percep_economy_cps, \n          \"(2) Worse\", \"(3) About the same\", \"(1) Better\") )\n\n  ces2019 &lt;- mutate(ces2019, \n      percep_economy_cps = fct_recode(percep_economy_cps, \n                                \"Worse\" = \"(2) Worse\", \n                                \"Same\" = \"(3) About the same\", \n                                \"Better\" = \"(1) Better\") )\n\n  ces2019 &lt;- mutate(ces2019, \n                  percep_economy_cps_n = as.numeric(percep_economy_cps))\n\nLet’s use the head() function to list the values of the first few observations for percep_economy_cps and percep_economy_cps_n to check how the variable was transformed.\n\n  head(ces2019$percep_economy_cps)\n\n[1] Worse  Same   Better Same   Better Worse \nLevels: Worse Same Better\n\n  head(ces2019$percep_economy_cps_n)\n\n[1] 1 2 3 2 3 1\n\n\nAs you can see in these first few observations, percep_economy_cps_n = 1 if percep_economy_cps is “Worse,” percep_economy_cps_n = 2 if percep_economy_cps is “Same,” and percep_economy_cps_n = 3 if percep_economy_cps is “Better.”\nAs it is transformed into a numeric variable with a proper order, we can use percep_economy_cps_n as the independent variable in our linear regression model.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\nAs you might have noticed, the values of percep_economy_cps_n are different from the numbers assigned to percep_economy_cps in my lecture. In the lecture, -1, 0, and 1 are used, but 1, 2, and 3 are assigned to percep_economy_cps_n above. As long as consecutive numbers are assigned, the coefficient of percep_economy_cps_n remains the same, although the intercept will be different.\nYou might have also noticed that the coefficient of percep_economy_cps_n produced above is slightly different from the coefficient of the perception of economy variable shown in my lecture. This is because there is a slight difference in the observations included in the analysis above and that presented in my lecture.\nBy the way, the lm() function can still accommodate an ordinal categorical variable, stored as factor, on the right hand side of a linear regression model even without transforming it into a numeric variable. The result, however, will be different from what’s reported above. We will see this in later chapters.\n\n\n6.2.2 Use Ordinal Categorical Variable As Dependent Variable\nNow let’s consider a linear regression model of satisfied_fedgovt on percep_economy_cps_n. Recall that satisfied_fedgovt is also an ordinal categorical variable. So in this application, we use an ordinal categorical variable as the dependent variable for a linear regression model. Again, we need to assign consecutive numbers to the categories of an ordinal categorical variable.\nFirst, construct a numeric version of satisfied_fedgovt. Below I call this new variable satisfied_fedgovt_n.\n\nces2019 &lt;- mutate(ces2019,\n  satisfied_fedgovt = fct_recode(satisfied_fedgovt,\n    \"Not At All\" = \"(4) Not satisfied at all\",\n    \"Not Very\" = \"(3) Not very satisfied\",\n    \"Fairly\" = \"(2) Fairly satisfied\",\n    \"Very\" = \"(1) Very satisfied\") )\n\nces2019 &lt;- mutate(ces2019, \n  satisfied_fedgovt = fct_relevel(satisfied_fedgovt, \n    \"Not At All\", \"Not Very\", \"Fairly\", \"Very\")) \n\nces2019 &lt;- mutate(ces2019, \n                  satisfied_fedgovt_n = as.numeric(satisfied_fedgovt))\n\nLet’s use the head() function to check how the variable was transformed. If you specify a number in the second argument of the head() function, then R will display this number of observations for the variable you specified. Below I set this argument to 20, so that the first 20 observations of satisfied_fedgovt are displayed.\n\n                                      # The second argument of the head() function specifies \n  head(ces2019$satisfied_fedgovt, 20) # the number of observations to be displayed.\n\n [1] Fairly     Fairly     Fairly     Fairly     Not At All Not At All\n [7] Not At All Fairly     Not Very   Fairly     Not Very   Not Very  \n[13] Fairly     Fairly     Very       Fairly     Fairly     Fairly    \n[19] Fairly     Fairly    \nLevels: Not At All Not Very Fairly Very\n\n  head(ces2019$satisfied_fedgovt_n, 20) \n\n [1] 3 3 3 3 1 1 1 3 2 3 2 2 3 3 4 3 3 3 3 3\n\n\nAs you can see above, 1 = Not At All, 2 = Not Very, 3 = Fairly, and 4 = Very. Now estimate a linear regression model of satisfied_fedgovt_n on percep_economy_cps_n. As we saw in lectures, linear regression is a model of the conditional means of y across the values of x. Since the current dependent variable is a score from 1 to 4, the conditional mean of this variable is the average score given a specific value of x.\n\n  lm(formula = satisfied_fedgovt_n ~ percep_economy_cps_n, data = ces2019)\n\n\nCall:\nlm(formula = satisfied_fedgovt_n ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n              1.1593                0.5753  \n\n\nThe coefficient on percep_economy_cps_n is 0.58, which suggests that the score of satisfaction with the federal government increases, on average, by 0.58 points from Worse to Same or from Same to Better in the respondent’s perception of economy. We can also say that the satisfaction of federal government (satisfied_fedgovt) improves, on average, by approximately one category as the respondent’s perception of economy improves from Worse to Better, because \\(0.58 \\times 2 = 1.16\\).\nBy the way, R can still estimate a linear regression model even without transforming an ordinal categorical variable from factor to numeric. Below I estimate the same model using satisfied_fedgovt, a factor version of this variable, as the dependent variable. In this case, R issues a warning message, as you see below, but it quietly transforms satisfied_fedgovt into a numeric version and estimates regression coefficients.\n\n      # Use satisfied_fedgovt instead of satisfied_fedgovt_n. The lm() function still \n      # estimates a linear regression model but issues a warning message.\n  lm(formula = satisfied_fedgovt ~ percep_economy_cps_n, data = ces2019)\n\nWarning in model.response(mf, \"numeric\"): using type = \"numeric\" with a factor\nresponse will be ignored\n\n\nWarning in Ops.factor(y, z$residuals): '-' not meaningful for factors\n\n\n\nCall:\nlm(formula = satisfied_fedgovt ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n              1.1593                0.5753  \n\n\nAlthough R allows us to use a factor as the dependent variable for the lm() function, as shown above, I’d still suggest you first transform a factor to a numeric variable and use a numeric version of your ordinal categorical variable so that you are fully aware of what you are doing — i.e., you are fully aware of using an ordinal categorical variable as your dependent variable.\nAs I mentioned in my lecture, there are also advanced statistical models when we use an ordinal categorical variable as our dependent variable.1 As such models are beyond the scope of this class, we will use a linear regression model for an ordinal categorical dependent variable in this class.\n\n\n6.2.3 Visualization\nIn Section 5.1, we used a mosaic plot to visualize the relationship between satisfied_fedgovt and percep_economy_cps. With satisfied_fedgovt_n — the numeric version of satisfied_fedgovt — it is also possible to draw a line chart and linear regression line for these variables. Below I used only the functions which you have already learned (so the code does not come with explanations.)\n\nggplot( drop_na(ces2019, percep_economy_cps), \n        aes( x = percep_economy_cps, y = satisfied_fedgovt_n, \n             group = 1 ) ) +\n  geom_point( stat = \"summary\", fun = mean, shape = 17, size = 3.5, color = \"blue\" ) +\n  geom_line( stat = \"summary\", fun = mean, color = \"blue\") +\n  geom_smooth( method = \"lm\", se = FALSE, col=\"red\", linetype = 2) +\n  xlab( \"Perception of Economy\" ) +\n  ylab( \"Satisfaction with Government Score\" ) +\n  coord_cartesian( ylim = c(0.75, 4.25) ) +\n  scale_y_continuous(breaks = seq(1, 4, 1))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "simp_linreg.html#dummy-variable-in-simple-linear-regression",
    "href": "simp_linreg.html#dummy-variable-in-simple-linear-regression",
    "title": "6  Simple Linear Regression",
    "section": "6.3 Dummy Variable in Simple Linear Regression",
    "text": "6.3 Dummy Variable in Simple Linear Regression\n\n6.3.1 Dummy Variable As Logical Variable in R\nRecall that when we have a dichotomous variable — a variable having a dichotomous outcome — we normally assign 1 to one category and 0 to the other category. Then, this variable is called a dummy variable.2\nConsider union in the ces2019 data frame. As you can see in the codebook for this dataset (ces2019_codebook.pdf), this variable records an answer to the question “Do you belong to a union?” Use the table() function to see its values (categories) and its relative frequency. Below I set the useNA argument to \"always\". Then, the table() function also displays the number of observations with a missing value (NA) for this variable.\n\n                                        # Set the useNA function to \"always\" to display \n  table(ces2019$union, useNA=\"always\")  # the number of observations with missing values.\n\n\n(1) Yes  (2) No    &lt;NA&gt; \n    613    2247    1161 \n\n\nAs you can see, union is a dichotomous variable, as its outcome is either Yes or No. There are many missing values (NA) for this variable, because this is a response to the question asked in the post-election survey (PES) of the Canadian Election Study (CES) in 2019. There are two components in the CES 2019 survey: the first is the campaign period survey (CPS) and the second is the PES. As their names suggest, CPS was conducted during the election campaign in 2019, and PES was conducted after the election. PES includes only a subset of respondents of CPS; i.e., the number of observations is smaller in PES than in CPS.\n\n\n\nFor a dummy variable, there is a more useful type — more precisely called class in R — of variable than factor. This variable class is called logical. A logical variable takes two categories TRUE or FALSE, each of which corresponds to number 1 and 0, respectively. If we use a logical variable in the lm() function, R will treat TRUE of the logical as 1 and FALSE of the logical as 0.\nTo transform the union variable to a logical, first we change the name of categories of union to TRUE and FALSE, and then apply the as.logical() function to change the variable from factor to logical. In the code below, I created a new variable — a logical version of union — called union_d (_d stands for a “d”ummy variable) in this way.\n\n  ces2019 &lt;- mutate(ces2019,  # Change the name of categories of union to TRUE and FALSE.\n      union_d = fct_recode(union, \"TRUE\" = \"(1) Yes\", \n                                  \"FALSE\" = \"(2) No\") )\n\n  ces2019 &lt;- mutate(ces2019,  # Then, apply the as.logical() function.\n      union_d = as.logical(union_d) )\n\nTo check if union_d is constructed as intended, apply the table() function to both uion and union_d to draw a cross table.\n\n      # Draw a cross table of union and union_d using the table() function.\n  table(ces2019$union, ces2019$union_d, useNA=\"always\") \n\n         \n          FALSE TRUE &lt;NA&gt;\n  (1) Yes     0  613    0\n  (2) No   2247    0    0\n  &lt;NA&gt;        0    0 1161\n\n\nAs you can see in the above output, all observations with Yes in union are TRUE in union_d, and those with No in union are FALSE in union_d. Therefore, union_d = TRUE if a respondent is a union member and FALSE otherwise.\nAlso check the class of union and union_d using the class() function. As you can see below, union is a factor but now union_d is a logical.\n\n  class(ces2019$union)\n\n[1] \"factor\"\n\n  class(ces2019$union_d)\n\n[1] \"logical\"\n\n\n\n\n\n\n\n\n\n6.3.2 Use Dummy Variable As Independent Variable\nNow we can use union_d — the logical version of union — as a dummy variable in the lm() function. Below, we use union_d as the independent variable for a linear regression of trudeau_therm_cps. We may expect that union members are likely to be more liberal than non-members, as Liberals have historically represented the interests of labour. Accordingly, we may expect that trudueau_therm_cps is, on average, higher among union members than otherwise, such that the coefficient on union_d is positive.\n\n  lm(formula = trudeau_therm_cps ~ union_d, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ union_d, data = ces2019)\n\nCoefficients:\n(Intercept)  union_dTRUE  \n     43.347        2.178  \n\n\nIn the output of the lm() function above, the coefficient of union_d is displayed as union_dTRUE, indicating that this variable is logical. The coefficient is 2.18 — a positive value as we hypothesized. Since uinon_d takes either 0 = FALSE, which represents a non-union member, or 1 = TRUE, which is a union member, a one unit increase in this variable is a switch from a non-union member to a union member. Therefore, the coefficient of union_d represents the difference in the conditional means of the trudeau_therm_cps between the union members and non-members. That is, on average, the Trudeau thermometer is 2.18 points higher among union members than non-union members. While it is positive as we expected, the magnitude of the difference may be too small, as the range of the thermometer is from 0 to 100. In other words, there may be little or no difference in the Trudeau thermometer between union members and non-members. Later in the course, we will learn the methods for statistical inference to aid us to consider if this difference is due to chance alone.\n\n\n6.3.3 Use Dummy Variable As Dependent Variable\nNow we consider the use of a dummy variable as the dependent variable in a linear regression model. Let’s fit a linear regression with union_d as the dependent variable and ideology as the independent variable. Since Liberals have historically represented the interests of labour unions, more liberal respondents may be more likely to be union members.\n\n  lm(formula = union_d ~ ideology, data = ces2019)\n\n\nCall:\nlm(formula = union_d ~ ideology, data = ces2019)\n\nCoefficients:\n(Intercept)     ideology  \n    0.29418     -0.01628  \n\n\nAs we saw in the lecture, when we use a dummy variable for the dependent variable of a linear regression, this will be a model for the probability of a dummy variable taking 1. In the current context, this is a model for the probability of respondents being union members. A model like this is called a Linear Probability Model or LPM.\nIn the above lm output, the coefficient on ideology is \\(-0.0163\\), which may be interpreted as the change in probability with respect to one unit increase in the independent variable. Since the dependent variable takes either 0 or 1, the coefficient is the change in probability measured in the range of 0 and 1. Hence, this coefficient may be interpreted that one unit increase in the ideological score would lead to the decrease in the probability of the respondents being union members by 0.0163 or 1.63 percentage points. Since the ideological score ranges from 0 to 10, or 11 points, the difference in the probability of being union members between the most liberal and most conservative respondents is \\(0.0163 \\times 10 = 0.163\\) or approximately 16 percentage points.\nBelow I computed the mean of union_d using the mean() function. As you see, the mean of union_d, which is a proportion of union members in the sample, is \\(0.214\\), or approximately 21%.\n\n  mean(ces2019$union_d, na.rm = TRUE)\n\n[1] 0.2143357\n\n\nThis means that if we randomly draw one individual from this sample, the probability of this individual being a union member is \\(0.214\\), or approximately 21%. Compared to this number, the estimated difference in the probability of being union members between the most liberal and most conservative respondents (\\(0.163\\) or approximately 16 percentage points) is a sizable difference in the probability of being union members.\n\n\n6.3.4 Dummy Dependent Variable Constructed from Nominal Categorical Variable\nAn LPM may also be used for a dummy variable created for one category of a nominal categorical variable. In my lecture, I constructed a dummy variable for the vote intention for the Liberal party from a nominal categorical variable of vote intention. Below I create this dummy variable from vote_choice_intended. For this purpose, I use the ifelse() function, which returns a specific value based on a certain condition.\nThe basic syntax for the ifelse() function is as follows.\n\n  ifelse(condition, value-if-true, value-if-false)\n\nThe ifelse() function returns value-if-true specified in the second argument, if the condition in the first argument is satisfied, but it returns value-if-false specified in the third argument otherwise.\nWe can use this ifelse() function to create a dummy variable for those who intended to vote for the Liberal party from the nominal categorical variable vote_choice_intended in the following way.\n\n  ces2019 &lt;- mutate(ces2019, \n                            # Create a new variable vote_lib using the ifelse() function.\n                    \n                    vote_lib = ifelse(vote_choice_intended == \"Lib\", \"TRUE\", \"FALSE\") )\n                            # This ifelse() function assigns \"TRUE\" to observations if their\n                            # vote_choice_intended is \"Lib\" but assigns \"FALSE\" otherwise.\n\n  ces2019 &lt;- mutate(ces2019, # Then, we transform vote_lib into a logical variable.\n                    vote_lib = as.logical(vote_lib) )\n\nIn the ifelse() function in the code above, the condition in the first argument is specified using a double equal sign (==), which is one of the logical operators used in R. Logical operators are used to specify a certain condition to evaluate. The double equal sign (==) evaluates whether the left-hand side of the sign is exactly the same as the right-hand side.\nIn the code above, the condition is vote_choice_intended == \"Lib\". This condition evaluates whether each observation of vote_choice_intended is \"Lib\" or not. Since the second argument of the ifelse() function is \"TRUE\", vote_lib will be \"TRUE\" for the observations for which vote_choice_intended is \"Lib\". On the other hand, the third argument of the ifelse() function is \"FALSE\", so vote_lib will be \"FALSE\" for the observations for which vote_choice_intended is not \"Lib\".\nBy the way, there are many other logical operators which can be used in R. You can find them online, for example, here.\nLet’s check if vote_lib is constructed as intended by drawing a crosstab of vote_lib and vote_choice_intended using the table() function.\n\n  table(ces2019$vote_lib, ces2019$vote_choice_intended, useNA=\"always\")\n\n       \n          BQ  Con Greens  Lib  NDP None of these Other  PPC Will not vote\n  FALSE   98  980    287    0  405            17    24   49             1\n  TRUE     0    0      0  909    0             0     0    0             0\n  &lt;NA&gt;     0    0      0    0    0             0     0    0             0\n       \n        Will spoil ballot &lt;NA&gt;\n  FALSE                 9    0\n  TRUE                  0    0\n  &lt;NA&gt;                  0 1242\n\n\nAs you see in the output above, vote_lib is TRUE for all observations for which vote_choice_intended is Lib but FALSE for all other observations.\n\n\n\n\n\nLet’s use vote_lib as the dependent variable in the lm() function. The independent variable is percep_economy_cps_n\n\n  lm(formula = vote_lib ~ percep_economy_cps_n, data = ces2019)\n\n\nCall:\nlm(formula = vote_lib ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n             -0.1196                0.2380  \n\n\nThe coefficient on percep_economy_cps_n is \\(0.24\\), which suggests that the probability of respondents voting for Liberals is higher by 0.24 points or 24 percentage points for those who perceived the state of national economy Better than those who perceived it Same or for those who perceived it Same than those who perceived it Worse. We can also say that the probability of voting for the Liberals is approximately 50 percentage points higher for those who perceived the state of economy Better than those who perceived it Worse, because \\(0.24 \\times 2 = 0.48\\).\nAs in an ordinal categorical variable, there are also advanced statistical models for a dummy dependent variable.3 As such models are beyond the scope of this class, we will use a linear regression model for a dummy dependent variable, or LPM, in this class.\n\n\n6.3.5 Visualization\nAn appropriate visualization for vote_lib and percep_economy_cps may be a mosaic plot.\n\nlibrary(ggmosaic) # Don't forget to load the ggmosaic package.\n\nggplot(drop_na(ces2019, percep_economy_cps, vote_lib)) +\n  geom_mosaic(aes(x = product(percep_economy_cps), fill = vote_lib), \n              show.legend = FALSE) +\n  scale_fill_manual(values = c(\"lightsteelblue2\", \"steelblue4\")) +\n  ylab(\"Vote Intention for Liberals\") +   \n  xlab(\"Perception of Economy\")         \n\n\n\n\n\n\n\n\nIt is also possible to draw a line chart with a linear regression line for these variables. However, we would need to create a numeric version of vote_lib for this, because the ggplot() functions to draw a line chart do not accept a logical variable as the dependent variable. Below I create a numeric version of vote_lib named vote_lib_n.\n\n  ces2019 &lt;- mutate(ces2019, # Create a numeric version of vote_lib.\n                    vote_lib_n = as.numeric(vote_lib) )\n\n  # Check how the variable is constructed.\n  table(ces2019$vote_lib_n, ces2019$vote_lib, useNA = \"always\")\n\n      \n       FALSE TRUE &lt;NA&gt;\n  0     1870    0    0\n  1        0  909    0\n  &lt;NA&gt;     0    0 1242\n\n\nThen, vote_lib_n is used to draw a line chart with a linear regression line.\n\nggplot( drop_na(ces2019, percep_economy_cps),\n        aes( x = percep_economy_cps, y = vote_lib_n,\n             group = 1 ) ) +\n  geom_point( stat = \"summary\", fun = mean, shape = 17, size = 3.5, color = \"blue\" ) +\n  geom_line( stat = \"summary\", fun = mean, color = \"blue\") +\n  geom_smooth( method = \"lm\", se = FALSE, col=\"red\", linetype = 2) +\n  xlab( \"Perception of Economy\" ) +\n  ylab( \"Probability of Voting for Liberals\" ) +\n  coord_cartesian( ylim = c(0, 1) ) +\n  scale_y_continuous(breaks = seq(0, 1, 0.2))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "simp_linreg.html#conditional-means-medians",
    "href": "simp_linreg.html#conditional-means-medians",
    "title": "6  Simple Linear Regression",
    "section": "6.4 Conditional Means & Medians",
    "text": "6.4 Conditional Means & Medians\nIf you want to compute the conditional means for an ordinal categorical dependent variable, you should use a numeric version of this variable, because the mean() function does not work for a factor.\n\nces2019 %&gt;% \n    group_by(percep_economy_cps) %&gt;%    \n            # Use a numerc version of an ordinal categorical dependent variable.\n    summarize( cond_mean = mean(satisfied_fedgovt_n, na.rm = TRUE) )\n\n# A tibble: 4 × 2\n  percep_economy_cps cond_mean\n  &lt;fct&gt;                  &lt;dbl&gt;\n1 Worse                   1.67\n2 Same                    2.40\n3 Better                  2.79\n4 &lt;NA&gt;                    2.37\n\n\nIf you want to compute the conditional means for a dummy variable, however, you may still use the logical version of a dummy variable, because the mean() function also works for a logical variable. Recall that R interprets TRUE of a logical variable as 1 and FALSE as 0.\n\nces2019 %&gt;% \n    group_by(percep_economy_cps) %&gt;%      # You may use a logical variable.\n    summarize( cond_mean = mean(vote_lib, na.rm = TRUE) )\n\n# A tibble: 4 × 2\n  percep_economy_cps cond_mean\n  &lt;fct&gt;                  &lt;dbl&gt;\n1 Worse                  0.109\n2 Same                   0.371\n3 Better                 0.580\n4 &lt;NA&gt;                   0.267",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "bivariate.html#sec-scatter",
    "href": "bivariate.html#sec-scatter",
    "title": "5  Bivariate Analysis",
    "section": "5.3 Scatterplot",
    "text": "5.3 Scatterplot\nWhen two variables are both quantitative variables taking many values, we may use a scatterplot to visualize the relationship.\n\n5.3.1 Basic Scatterplot: ggplot() + geom_point()\nBelow we will draw a scatterplot for democrat and ranney3_gub_prop from the usstates2020 data frame. As you can see in the codebook for usstates2020, democrat is the percent of Democratic identifiers — individuals who identify themselves as Democrats — in each state, and ranney3_gub_prop is the proportion of two-party vote for a democratic gubernatorial candidate. We would expect a positive relationship between these two variables. Let’s see whether there is indeed a positive relationship by drawing a scatterplot.\nWe can draw a scatterplot by adding the geom_point() function to the ggplot() function. Note that the aes() function is the argument of the ggplot() function this time. Within the aes() function, we need to specify the independent variable (x = ) and the dependent variable (y = ).\n\n      # aes() is specified in the ggplot() function. It should indicate the independent \nggplot(usstates2010,           # variable (x = ) and the dependent variable (y = ).\n       aes(x = democrat, y = ranney3_gub_prop)) + \n  geom_point()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe scatterplot above suggests that there seems to be a positive relationship, but there are some outliers in the upper left quadrant — some states recorded a very high two party vote share for a Democratic gubernatorial candidate even with a relatively low proportion of Democratic identifiers. The warning message above indicates that there are two observations removed from the visualization because they have missing values for either ranney3_gub_prop or democrat.\nWe can change the shape, size, and color of the points by specifying the shape, col, and size arguments in the geom_point() function as follows.\n\nggplot( usstates2010, \n        aes(x = democrat, y = ranney3_gub_prop) ) +\n  geom_point( shape = 21, col = \"blue\", size = 3 ) # shape, col, and size arguments added.\n\n\n\n\n\n\n\n\nR uses numbers and a few symbols to specify the shape of points. You can look up the shape of points used in R online, for example here (see Figure 5.6, and ignore the rest). As we have already seen, you can find the colors used in R online as well, for example, here and here. You may specify a different number for size to see how the points will change.\nWe may want to display both variables in percentage by multiplying ranney3_gub_prop by 100.\n\nggplot( usstates2010,       # ranney3_gub_prop is multiplied by 100.\n        aes(x = democrat, y = ranney3_gub_prop * 100) ) + \n  geom_point( shape = 21, col = \"blue\", size = 3 )\n\n\n\n\n\n\n\n\nYou can further edit this scatterplot using the functions you have learned. See an example below.\n\nggplot( usstates2010,       \n        aes(x = democrat, y = ranney3_gub_prop * 100) ) + \n  geom_point( shape = 21, col = \"blue\", size = 3 ) +\n  xlab(\"Democratic Identifiers (%)\") +\n  ylab(\"Two-Party Vote Share (%) \\nDemocratic Gubernatorial Candidate\") +\n  coord_cartesian(ylim = c(0, 100), xlim=c(15,75)) +\n  scale_x_continuous(breaks = seq(0, 100, 10)) +\n  scale_y_continuous(breaks = seq(0, 100, 10))\n\n\n\n\n\n\n\n\n\n\n5.3.2 Scatterplot by Name of Observations: ggplot() + geom_text()\nSo far we have seen scatterplots by points. We can also use texts instead of points to draw scatterplots. For this purpose, we replace the geom_point() function with the geom_text() function and specify the texts used in a scatterplot in the label argument in the aes() function inside the ggplot() function.\nSee the example below.\n\nggplot(usstates2010, \n       aes(x = democrat, y = ranney3_gub_prop, \n           label = \"test\") ) +  # Specify texts in the label argument in the aes() function.\n  geom_text()                   # Then, use the geom_text() function.\n\n\n\n\n\n\n\n\nIf we specify a single text for the label argument as in the above example, that text is used for all data points. In the above example, I specified label = \"test\", then as you can see, test was used for all data points.\nOr we can specify a variable in the data frame for the label argument. Then, the values of this variable are used for each observation. For the present example, it is useful if we have the name of states for each data point. In the usstates2010 data frame, state is a variable on the name of states, and st is state postal codes. Look up these variables in the usstates2010 data frame by the View() function (alternatively, you can click the name of the data frame in the Environment tab in the upper right pane).\n\n  View(usstates2010)\n\n\nBelow I used st in the label argument.\n\nggplot(usstates2010, \n       aes(x = democrat, y = ranney3_gub_prop, \n           label = st) ) +     # Specify a variable in the label argument in the aes() function.\n  geom_text()                  # Then, use the geom_text() function.\n\n\n\n\n\n\n\n\nWe can change the size and color of texts by specifying the size and col arguments in the geom_text() function as follows.\n\nggplot( usstates2010, \n        aes( x = democrat, y = ranney3_gub_prop, \n             label = st ) ) +\n              # Try other numbers for the size argument to see \n  geom_text( size=2.5, col=\"blue\" )  # how the size of texts changes.\n\n\n\n\n\n\n\n\nNow we can see that the outliers in the upper left quadrant are Colorado (CO), West Virginia (WV), Montana (MT), and Arkansas (AR).\nWe can of course further edit this scatterplot using the functions we have learned.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Bivariate Analysis</span>"
    ]
  },
  {
    "objectID": "simp_linreg.html#footnotes",
    "href": "simp_linreg.html#footnotes",
    "title": "6  Simple Linear Regression",
    "section": "",
    "text": "These models belong to the family of models called Generalized Linear Models (GLMs). For an ordinal categorical dependent variable, an ordered logit model or an ordered probit model, which belongs to GLMs, may be used.↩︎\nAs we saw in the lecture, it may alternatively be called a binary or indicator variable.↩︎\nThese models also belong to the family of models called Generalized Linear Models (GLMs). The models called logit and probit may be used for a dummy dependent variable.↩︎",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html",
    "href": "multi_linreg.html",
    "title": "7  Multiple Linear Regression",
    "section": "",
    "text": "7.1 Overview\nWhile we have started learning statistical inference in lectures, in this chapter, we will still consider a linear regression model as the method for descriptive statistics only. We will cover statistical inference for linear regression in later chapters.\nThis chapter will introduce i) how to fit a multiple linear regression model with two or more independent variables on the right-hand side of the linear regression equation, and ii) dummification of a categorical independent variable in a linear regression model.\nNote that we did not cover the second topic — dummification of a categorical independent variable — in lectures. I want you to learn this topic from this chapter. If you need an additional reference for this topic, you may read Kellstedt and Whitten’s Chapter 11.2.2 (3rd Edition, pp.251-254) or Chapter 10.2.2 (2nd Edition, pp.225-227). Recall that the 2nd edition of this book is available online from the UofT library.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#linear-regression-for-multivariate-analysis",
    "href": "multi_linreg.html#linear-regression-for-multivariate-analysis",
    "title": "7  Multiple Linear Regression",
    "section": "7.2 Linear Regression for Multivariate Analysis",
    "text": "7.2 Linear Regression for Multivariate Analysis\n\n7.2.1 Prepare Variables\nAs in Chapter 6, let’s create percep_economy_cps_n, which is a numeric version of percep_economy_cps, and union_d, a logical version of union.\n\n  ces2019 &lt;- ces2019 |&gt; \n      mutate(percep_economy_cps = fct_relevel(percep_economy_cps, \n              \"(2) Worse\", \"(3) About the same\", \"(1) Better\") ) |&gt; \n      mutate(percep_economy_cps = fct_recode(percep_economy_cps, \n                                \"Worse\" = \"(2) Worse\", \n                                \"Same\" = \"(3) About the same\", \n                                \"Better\" = \"(1) Better\") ) |&gt; \n      mutate(percep_economy_cps_n = as.numeric(percep_economy_cps))\n\n\n  ces2019 &lt;-  ces2019 |&gt; # Change the name of categories of union to TRUE and FALSE.\n      mutate( union_d = fct_recode(union, \"TRUE\" = \"(1) Yes\", \"FALSE\" = \"(2) No\") ) |&gt; \n      mutate( union_d = as.logical(union_d) )  # Then, apply the as.logical() function.\n\n\n\n7.2.2 Multiple Linear Regression\nRecall that we used the lm() function to fit a simple linear regression model. For example, the code below fits a simple linear regression model of trudeau_therm_cps on percep_economy_cps_n.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\nTo fit a multiple linear regression model, we continue to use the lm() function, but now we need to specify multiple independent variables on the right hand side of the equation in the formula argument. More specifically, suppose that the model we try to fit is given by the following formula in which we have three independent variables, \\(X_1\\), \\(X_2\\), and \\(X_3\\).\n\\[\n  Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + u\n\\tag{7.1}\\]\nFor this model, we specify the formula argument in the lm function as formula = Y ~ X1 + X2 + X3. That is, ignoring the coefficients, we connect all the independent variables with a + sign on the right-hand side of tilde, ~.\nLet’s fit a multiple linear regression model of trudeau_therm_cps on three independent variables, percep_economy_cps_n, ideology, and union_d, where percep_economy_cps_n corresponds to \\(X_1\\), ideology corresponds to \\(X_2\\), and union_d corresponds to \\(X_3\\) in Equation 7.1.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + union_d, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + \n    union_d, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n              ideology  \n             24.7569               17.1926               -2.7193  \n         union_dTRUE  \n              0.8752  \n\n\nAs before, we can see the list of coefficients computed at the bottom of the output. The number below (Intercept) is the intercept of the linear regression model. This is an estimate of \\(\\beta_0\\) in the linear regression model in Equation 7.1. The number below percep_economy_cps_n is the coefficient of the percep_economy_cps_n variable, which corresponds to \\(\\beta_1\\) in the linear regression model in Equation 7.1. The number below ideology is the coefficient of the ideology variable, which is an estimate of \\(\\beta_2\\) in Equation 7.1. Finally, the number below union_dTRUE is the coefficient of the union_d variable, which is an estimate of \\(\\beta_3\\) in Equation 7.1.\nIf we have more independent variables than what is shown in this example, we can simply add them on the right hand side of the tilde ~ in the formula argument connecting each of them by the + sign.\nIn the above example, the coefficient on percep_economy_cps_n is different between simple and multiple linear regression models. This is because the coefficient on percep_economy_cps_n in the multiple linear regression model reflects the relationship between trudeau_therm_cps and percep_economy_cps_n controlling for the other two variables included in the model, ideology and union_d. That is, this coefficient indicates how much truedeau_therm_cps changes, on average, as percep_economy_cps_n increases by one unit, holding ideology and union_d constant.\nIn general, the coefficient of the same variable may be different between simple and multiple linear regression models, if one or some of the control variables included in the multiple linear regression model are confounding variables for the relationship between the dependent and the main independent variable of our interest. In the present example, either ideology or union_d or both of them are confounding variables to the relationship between trudeau_therm_cps and percep_economy_cps_n. However, the change in the coefficient of percep_economy_cps_n between the simple linear regression model (18.98) and the multiple linear regression model (17.19) seems to be small, indicating that the confounding effect of these variables is relatively small in this sample.1",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#dummifying-ordinal-categorical-independent-variable",
    "href": "multi_linreg.html#dummifying-ordinal-categorical-independent-variable",
    "title": "7  Multiple Linear Regression",
    "section": "7.3 Dummifying Ordinal Categorical Independent Variable",
    "text": "7.3 Dummifying Ordinal Categorical Independent Variable\nIn the analysis above, we transformed percep_economy_cps to a numeric variable before we used it as an independent variable in the lm() function. Even without this transformation, R allows the use of a factor as an independent variable in the lm() function, but the result is different from the one we saw before for percep_economy_cps_n in Section 6.2.1 and Section 7.2.\nIn the code below, I used percep_economy_cps instead of percep_economy_cps_n as the only independent variable for a linear regression of trudeau_therm_cps.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                   25.13                     23.93                     36.76  \n\n\nIn the output above, you see that percep_economy_cps is divided into two variables percep_economy_cpsSame and percep_economy_cpsBetter, and the coefficients are available for each one of them. What R did here is dummifying this categorical variable.\nDummifying a categorical variable means that each category of the categorical variable (except for one, which is called a reference category) is transformed into a dummy variable for this category. In the current example, R created two dummy variables percep_economy_cpsSame and percep_economy_cpsBetter, which are dummy variables for percep_economy_cps = Same and percep_economy_cps = Better, respectively, from percep_economy_cps which has three categories (Worse is used as a reference category).\nTable 7.1 below shows how the values and categories of these three variables correspond to each other.\n\n\n\nTable 7.1: Dummifying percep_economy_cps\n\n\n\n\n\npercep_economy_cps\nWorse\nSame\nBetter\n\n\n\n\npercep_economy_cpsSame\n0\n1\n0\n\n\npercep_economy_cpsBetter\n0\n0\n1\n\n\n\n\n\n\nAs shown in this table, percep_economy_cpsSame is a dummy variable whose value equals 1 if the value of percep_economy_cps is Same and 0 if the value of percep_economy_cps is Worse or Better.\nSimilarly, percep_economy_cpsBetter is a dummy variable whose value equals 1 if the value of percep_economy_cps is Better and 0 if the value of percep_economy_cps is Worse or Same.\nIn the process of dummifying a categorical variable, a dummy variable is not created for one of the categories, which is used as a reference category — you will see why this is necessary later. In the example here, Worse is used as a reference category, and therefore, a dummy variable is not created for this category.\nWhen dummifying a categorical variable, which is stored as a factor, R uses the first level (category) of the variable as a reference category. Recall that we can check the levels of a factor by the levels() function.\n\n  levels(ces2019$percep_economy_cps)\n\n[1] \"Worse\"  \"Same\"   \"Better\"\n\n\nAs the first level of percep_economy_cps is Worse, this level is used as a reference category, and dummy variables are created only for Same and Better, each of which is named percep_economy_cpsSame and percep_economy_cpsBetter using the name of the variable and the name of each level. Because one category is used as a reference category, if a categorical variable has L categories (L here is an arbitrary number), then dummy variables are created for L-1 categories. In the present example, there are three categories (L = 3) for percep_economy_cps, therefore, only two dummy variables (L-1 = 3-1 = 2) are created for this variable.\n\n7.3.1 Fitted Values from the Linear Regression with Dummified Variables from Categorical Independent Variable\nTo understand a linear regression model with the dummified variables created from a categorical independent variable further, let’s derive the fitted values of trudeau_therm_cps for each category of percep_economy_cps. Recall that a fitted value (or a predicted value) is the value of \\(\\widehat{Y}\\) derived from a linear regression equation (e.g., \\(\\widehat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2\\)) by substituting specific values of independent variables (e.g., specifying \\(X_1\\) and \\(X_2\\) at certain values).\nBelow I reprodued the outcome of the linear regression of trudeau_therm_cps on percep_economy_cps.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                   25.13                     23.93                     36.76  \n\n\nBased on this result, the fitted values of trudeau_therm_cps can be computed by the following formula.\n\n\\[\n\\begin{aligned}\n{\\color{blue}25.13}~+~{\\color{red}23.93}~\\times &percep\\_economy\\_cpsSame\\\\ &+~{\\color{violet}36.76}~\\times percep\\_economy\\_cpsBetter\n\\end{aligned}\n\\tag{7.2}\\]\nIf percep_economy_cps = Worse, then both percep_economy_cpsSame and percep_economy_cpsBetter must be zero (see Table 7.1). Therefore, substituting \\(0\\) for both variables in Equation 7.2, the fitted value of trudeau_therm_cps if percep_economy_cps = Worse is given by \\({\\color{blue}25.13}~+~{\\color{red}23.93}\\times0+{\\color{violet}36.76}\\times0 = {\\color{blue}25.13}\\). Because both independent variables are zero, the fitted value for trudeau_therm_cps when percep_economy_cps = Worse is equivalent to the intercept of the linear regression model in Equation 7.2. This is the reason why no dummy variable is created for a reference category. This category doesn’t need its own dummy variable, since the intercept of a linear regression model represents the fitted value for this reference category.\nIf percep_economy_cps = Same, then percep_economy_cpsSame = 1 and percep_economy_cpsBetter = 0 (see Table 7.1). Therefore, substituting these values in Equation 7.2, the fitted value of trudeau_therm_cps is given by \\({\\color{blue}25.13}~+~{\\color{red}23.93}\\times1+{\\color{violet}36.76}\\times0 = {\\color{blue}25.13}~+~{\\color{red}23.93} = {\\color{red}49.06}\\). This result implies that the coefficient on percep_economy_cpsSame, \\({\\color{red}23.93}\\), indicates the difference in the fitted values of trudeau_therm_cps when percep_economy_cps is Same and when percep_economy_cps is its reference category, Worse (i.e., \\({\\color{red}49.06} - {\\color{blue}25.13} = {\\color{red}23.93}\\)).\nSimilarly, if percep_economy_cps = Better, then percep_economy_cpsSame = 0 and percep_economy_cpsBetter = 1 (see Table 7.1). Therefore, substituting these values in Equation 7.2, the fitted value of trudeau_therm_cps is given by \\({\\color{blue}25.13}~+~{\\color{red}23.93}\\times0+{\\color{violet}36.76}\\times1 = {\\color{blue}25.13}~+~{\\color{violet}36.76} = {\\color{violet}61.89}\\). Again, the coefficient on percep_economy_cpsBetter, \\({\\color{violet}36.76}\\), indicates the difference in the fitted values between when percep_economy_cps is Better and when percep_economy_cps is its reference category, Worse (i.e., \\({\\color{violet}61.89} - {\\color{blue}25.13} = {\\color{violet}36.76}\\)).\n\n\n\n\n\n\n\n\n\n\n7.3.2 How to Interpret the Linear Regression Coefficients on Dummified Variables from Categorical Independent Variable\nMore generally, we can say that the coefficient on a dummy variable created for a certain category of a categorical independent variable (say, \\(X = a\\)) indicates the difference in the fitted values (\\(\\widehat{Y}\\)) for this category (\\(X = a\\)) and the reference category (\\(X =\\) reference category).\nIn other words, the coefficient on a dummy variable for a certain category of a categorical independent variable (\\(X = a\\)) tells us how the value of \\(Y\\) for the observations with \\(X = a\\) differs, on average, from the value of \\(Y\\) for those with \\(X =\\) reference category.\nFor example, in Section 7.3.1, we saw that the coefficient on percep_economy_cpsSame (\\({\\color{red}23.93}\\)) indicates the difference in the fitted values of trudeau_therm_cps when percep_economy_cps is Sameand percep_economy_cps is the reference category, Worse (\\({\\color{red}49.06} - {\\color{blue}25.13} = {\\color{red}23.93}\\)). This coefficient, \\({\\color{red}23.93}\\), can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Same is greater, on average, by \\({\\color{red}23.93}\\) points from those whose perception of economy is the reference category, Worse.\nWe also saw that the coefficient on percep_economy_cpsBetter (\\({\\color{violet}36.76}\\)) indicates the difference in the fitted values between when percep_economy_cps is Better and when percep_economy_cps is the reference category, Worse (\\({\\color{violet}61.89} - {\\color{blue}25.13} = {\\color{violet}36.76}\\)). This coefficient, \\({\\color{violet}36.76}\\), can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Better is greater, on average, by \\({\\color{violet}36.76}\\) points from those whose perception of economy is the reference category, Worse.\nAs we saw in these examples, the coefficient on the dummy variable for a certain category of a categorical independent variable (\\(X = a\\)) should be understood as the difference in the average value of \\(Y\\) for this category (\\(X = a\\)) and the average value of \\(Y\\) for the reference category (\\(X =\\) reference category). This is the reason why a reference category is named that way.\nAs the above discussion has made it clear, the coefficient on the dummy variable for a certain category of a categorical independent variable (\\(X = a\\)) tells us the comparison between the chosen category (\\(X = a\\)) and the reference category (\\(X =\\) reference category).\nIf we want to compare the chosen category (\\(X = a\\)) with another category which is not the reference category (say, \\(X = b\\)), then we need to compute the difference from their coefficients.\nFor example, suppose that we want to compare the average Trudeau thermometer between the respondents whose perception of economy is Better and those whose is Same. The comparison is made by taking the difference of the fitted values of trudeau_therm_cps when percep_economy_cps is Better and when percep_economy_cps is Same. As we have seen, the fitted value of trudeau_therm_cps when percep_economy_cps is Better is \\({\\color{blue}25.13}~+~ {\\color{violet}36.76} = {\\color{violet}61.89}\\) , and the fitted value of trudeau_therm_cps when percep_economy_cps is Same is \\({\\color{blue}25.13}~+~{\\color{red}23.93} = {\\color{red}49.06}\\). Therefore, the difference of these fitted values is \\({\\color{violet}61.89} - {\\color{red}49.06} = {\\color{brown}12.83}\\).\nHowever, this is equivalent to the difference between the coefficient of percep_economy_cpsBetter, \\({\\color{violet}36.76}\\), and the coefficient of percep_economy_cpsSame, \\({\\color{red}23.93}\\), (\\({\\color{violet}36.76} - {\\color{red}23.93} = {\\color{brown}12.83}\\)). Therefore, we just needed to compute the difference between the coefficient of percep_economy_cpsBetter and the coefficient of percep_economy_cpsSame in the first place.\nThis resut can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Better is greater, on average, by \\({\\color{brown}12.83}\\) points from those whose perception of economy is Same.\n\n\n7.3.3 With Additional Independent Variables\nIn Section 7.3.2, we included only the dummy variables for a categorical independent variable on the right-hand side of the linear regression model. We can also include the additional independent variables on the right hand side. For example, below I added ideology and union_d on the right-hand side of the linear regression model of trudeau_therm_cps on percep_economy_cps.\n\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps + ideology + union_d, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps + ideology + \n    union_d, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                 39.3833                   22.0875                   33.8127  \n                ideology               union_dTRUE  \n                 -2.6315                    0.7463  \n\n\n\n\n\n\n\n\nAs before, in this linear regression analysis, percep_economy_cps is dummified into two dummy variables, percep_economy_cpsSame and percep_economy_cpsBetter. The interpretation of the coefficients of these dummy variables is the same as before except that the other variables ideology and union_d are now controlled for.\nThe coefficient of percep_economy_cpsSame is \\({\\color{red}22.09}\\). This can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Same is greater, on average, by \\({\\color{red}22.09}\\) points from those whose perception of economy is the reference category, Worse, controlling for the respondents’ political ideology and union membership.\nThe coefficient of percep_economy_cpsBetter is \\({\\color{violet}33.81}\\). This coefficient, \\({\\color{violet}33.81}\\), can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Better is greater, on average, by \\({\\color{violet}33.81}\\) points from those whose perception of economy is the reference category, Worse, holding their political ideology and union membership constant.\nIf we want to compare the respondents whose perception of economy is Better and those whose is Same, we need to compute the difference between the coefficient of percep_economy_cpsBetter and the coefficient of percep_economy_cpsSame (\\({\\color{violet}33.81} - {\\color{red}22.09} = {\\color{brown}11.72}\\)). As the difference is \\({\\color{brown}11.72}\\), it can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Better is greater, on average, by \\({\\color{brown}11.72}\\) points from those whose perception of economy is Same, with the respondents’ political ideology and union status held constant.\n\n\n7.3.4 Difference from Numerical Version\nComparing the linear regression results of the numeric version and the dummified version of percep_economy_cps, we can see the difference in these two specifications.\nFor your quick reference, I have reproduced the output of the lm() function for both cases below.\n\nWith the numeric version of percep_economy_cps\n\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\n\nWith the dummified version of percep_economy_cps\n\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                   25.13                     23.93                     36.76  \n\n\nIn the result of a simple linear regression model with the numeric version, percep_economy_cps_n, the average difference in the Trudeau thermometer is \\(18.98\\) points both between Better and Same and between Same and Worse. On the other hand, in the linear regression model with the dummified version, the average difference in the Trudeau thermometer is \\({\\color{brown}12.83}\\) points between Better and Same, while it is \\({\\color{red}23.93}\\) points between Same and Worse.\nSimilarly, in the result of a multiple linear regression model with the numeric version, percep_economy_cps_n, the average difference in the Trudeau thermometer is \\(17.19\\) points both between Better and Same and between Same and Worse. On the other hand, in the linear regression model with the dummified version, the average difference in the Trudeau thermometer is \\({\\color{brown}11.72}\\) points between Better and Same, while it is \\({\\color{red}22.09}\\) points between Same and Worse.\nWhen we used percep_economy_cps_n, the difference in Trudeau thermometer is the same whether we consider the difference between Better and Same or that between Same and Worse. On the other hand, when we used the dummified verson, the difference in Trudeau thermometer is different when we consider the difference between Better and Same and when we examine the difference between Same and Worse. \nIn general, the average difference in the dependent variable between one category of ordinal categorical variable and its adjacent category is the same for all categories, if we use a numeric version of an ordinal categorical variable, but it is different for all categories of this variable, if we use the dummified version of this variable. The dummification may be considered as a more flexible modeling strategy for an ordinal categorical variable than the use of a numeric version of this variable. This is a modeling choice we need to make when we include an ordinal categorical variable as an independent variable in our linear regression model.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#dummifying-nominal-categorical-independent-variable",
    "href": "multi_linreg.html#dummifying-nominal-categorical-independent-variable",
    "title": "7  Multiple Linear Regression",
    "section": "7.4 Dummifying Nominal Categorical Independent Variable",
    "text": "7.4 Dummifying Nominal Categorical Independent Variable\nDummification of nominal categorical independent variables will be covered in the next week’s tutorial exercise.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#footnotes",
    "href": "multi_linreg.html#footnotes",
    "title": "7  Multiple Linear Regression",
    "section": "",
    "text": "A caveat here is that while it is not clear in the analyses presented, the number of observations included is different between these simple and multiple linear regressions. We will come back to this issue later.↩︎",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#sec-lr-multi",
    "href": "multi_linreg.html#sec-lr-multi",
    "title": "7  Multiple Linear Regression",
    "section": "7.2 Linear Regression for Multivariate Analysis",
    "text": "7.2 Linear Regression for Multivariate Analysis\n\n7.2.1 Prepare Variables\nAs in Chapter 6, let’s create percep_economy_cps_n, which is a numeric version of percep_economy_cps, and union_d, a logical version of union.\n\n  ces2019 &lt;- ces2019 |&gt; \n      mutate(percep_economy_cps = fct_relevel(percep_economy_cps, \n              \"(2) Worse\", \"(3) About the same\", \"(1) Better\") ) |&gt; \n      mutate(percep_economy_cps = fct_recode(percep_economy_cps, \n                                \"Worse\" = \"(2) Worse\", \n                                \"Same\" = \"(3) About the same\", \n                                \"Better\" = \"(1) Better\") ) |&gt; \n      mutate(percep_economy_cps_n = as.numeric(percep_economy_cps))\n\n\n  ces2019 &lt;-  ces2019 |&gt; # Change the name of categories of union to TRUE and FALSE.\n      mutate( union_d = fct_recode(union, \"TRUE\" = \"(1) Yes\", \"FALSE\" = \"(2) No\") ) |&gt; \n      mutate( union_d = as.logical(union_d) )  # Then, apply the as.logical() function.\n\n\n\n7.2.2 Multiple Linear Regression\nRecall that we used the lm() function to fit a simple linear regression model. For example, the code below fits a simple linear regression model of trudeau_therm_cps on percep_economy_cps_n.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\nTo fit a multiple linear regression model, we continue to use the lm() function, but now we need to specify multiple independent variables on the right hand side of the equation in the formula argument. More specifically, suppose that the model we try to fit is given by the following formula in which we have three independent variables, \\(X_1\\), \\(X_2\\), and \\(X_3\\).\n\\[\n  Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + u\n\\tag{7.1}\\]\nFor this model, we specify the formula argument in the lm function as formula = Y ~ X1 + X2 + X3. That is, ignoring the coefficients, we connect all the independent variables with a + sign on the right-hand side of tilde, ~.\nLet’s fit a multiple linear regression model of trudeau_therm_cps on three independent variables, percep_economy_cps_n, ideology, and union_d, where percep_economy_cps_n corresponds to \\(X_1\\), ideology corresponds to \\(X_2\\), and union_d corresponds to \\(X_3\\) in Equation 7.1.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + union_d, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + \n    union_d, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n              ideology  \n             24.7569               17.1926               -2.7193  \n         union_dTRUE  \n              0.8752  \n\n\nAs before, we can see the list of coefficients computed at the bottom of the output. The number below (Intercept) is the intercept of the linear regression model. This is an estimate of \\(\\beta_0\\) in the linear regression model in Equation 7.1. The number below percep_economy_cps_n is the coefficient of the percep_economy_cps_n variable, which corresponds to \\(\\beta_1\\) in the linear regression model in Equation 7.1. The number below ideology is the coefficient of the ideology variable, which is an estimate of \\(\\beta_2\\) in Equation 7.1. Finally, the number below union_dTRUE is the coefficient of the union_d variable, which is an estimate of \\(\\beta_3\\) in Equation 7.1.\nIf we have more independent variables than what is shown in this example, we can simply add them on the right hand side of the tilde ~ in the formula argument connecting each of them by the + sign.\nIn the above example, the coefficient on percep_economy_cps_n is different between simple and multiple linear regression models. This is because the coefficient on percep_economy_cps_n in the multiple linear regression model reflects the relationship between trudeau_therm_cps and percep_economy_cps_n controlling for the other two variables included in the model, ideology and union_d. That is, this coefficient indicates how much truedeau_therm_cps changes, on average, as percep_economy_cps_n increases by one unit, holding ideology and union_d constant.\nIn general, the coefficient of the same variable may be different between simple and multiple linear regression models, if one or some of the control variables included in the multiple linear regression model are confounding variables for the relationship between the dependent and the main independent variable of our interest. In the present example, either ideology or union_d or both of them are confounding variables to the relationship between trudeau_therm_cps and percep_economy_cps_n. However, the change in the coefficient of percep_economy_cps_n between the simple linear regression model, 18.98, and the multiple linear regression model, 17.19, seems to be small, indicating that the confounding effect of these variables is relatively small in this sample.1",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#sec-dum-ocat-ind",
    "href": "multi_linreg.html#sec-dum-ocat-ind",
    "title": "7  Multiple Linear Regression",
    "section": "7.3 Dummifying Ordinal Categorical Independent Variable",
    "text": "7.3 Dummifying Ordinal Categorical Independent Variable\nIn the analysis above, we transformed percep_economy_cps to a numeric variable before we used it as an independent variable in the lm() function. Even without this transformation, R allows the use of a factor as an independent variable in the lm() function, but the result is different from the one we saw before for percep_economy_cps_n in Section 6.2.1 and Section 7.2.\nIn the code below, I use percep_economy_cps instead of percep_economy_cps_n as the only independent variable for a linear regression of trudeau_therm_cps.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                   25.13                     23.93                     36.76  \n\n\nIn the output above, you see that percep_economy_cps is divided into two variables percep_economy_cpsSame and percep_economy_cpsBetter, and the coefficients are available for each one of them. What R did here is dummifying this categorical variable.\nDummifying a categorical variable means that each category of the categorical variable (except for one, which is called a reference category) is transformed into a dummy variable for this category. In the current example, R created two dummy variables percep_economy_cpsSame and percep_economy_cpsBetter, which are dummy variables for percep_economy_cps = Same and percep_economy_cps = Better, created from percep_economy_cps which has three categories (Worse is used as a reference category).\nTable 7.1 below shows how the values and categories of these three variables correspond to each other.\n\n\n\nTable 7.1: Dummifying percep_economy_cps\n\n\n\n\n\npercep_economy_cps\nWorse\nSame\nBetter\n\n\n\n\npercep_economy_cpsSame\n0\n1\n0\n\n\npercep_economy_cpsBetter\n0\n0\n1\n\n\n\n\n\n\nAs shown in this table, percep_economy_cpsSame is a dummy variable whose value equals 1 if the value of percep_economy_cps is Same and 0 if the value of percep_economy_cps is Worse or Better.\nSimilarly, percep_economy_cpsBetter is a dummy variable whose value equals 1 if the value of percep_economy_cps is Better and 0 if the value of percep_economy_cps is Worse or Same.\nIn the process of dummifying a categorical variable, a dummy variable is not created for one of the categories, which is used as a reference category — you will see why this is necessary later. In the example here, Worse is used as a reference category, and therefore, a dummy variable is not created for this category.\nWhen dummifying a categorical variable, which is stored as a factor, R uses the first level (category) of the variable as a reference category. Recall that we can check the levels of a factor by the levels() function.\n\n  levels(ces2019$percep_economy_cps)\n\n[1] \"Worse\"  \"Same\"   \"Better\"\n\n\nAs the first level of percep_economy_cps is Worse, this level is used as a reference category, and dummy variables are created only for Same and Better, each of which is named percep_economy_cpsSame and percep_economy_cpsBetter using the name of the variable and the name of each level. Because one category is used as a reference category, if a categorical variable has L categories (L here is an arbitrary number), then dummy variables are created for L-1 categories. In the present example, there are three categories (L = 3) for percep_economy_cps, therefore, only two dummy variables (L-1 = 3-1 = 2) are created for this variable.\n\n7.3.1 Fitted Values from the Linear Regression with Dummified Variables from Categorical Independent Variable\nTo understand a linear regression model with the dummified variables created from a categorical independent variable further, let’s derive the fitted values of trudeau_therm_cps for each category of percep_economy_cps. Recall that a fitted value (or a predicted value) is the value of \\(\\widehat{Y}\\) derived from a linear regression equation (e.g., \\(\\widehat{Y} = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2\\)) by substituting specific values of independent variables (e.g., specifying \\(X_1\\) and \\(X_2\\) at certain values).\nBelow I reproduced the outcome of the linear regression of trudeau_therm_cps on percep_economy_cps.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                   25.13                     23.93                     36.76  \n\n\nBased on this result, the fitted values of trudeau_therm_cps can be computed by the following formula.\n\n\\[\n\\begin{aligned}\n{\\color{blue}25.13}~+~{\\color{red}23.93}~\\times &percep\\_economy\\_cpsSame\\\\ &+~{\\color{violet}36.76}~\\times percep\\_economy\\_cpsBetter\n\\end{aligned}\n\\tag{7.2}\\]\nIf percep_economy_cps = Worse, then both percep_economy_cpsSame and percep_economy_cpsBetter must be zero (see Table 7.1). Therefore, substituting \\(0\\) for both variables in Equation 7.2, the fitted value of trudeau_therm_cps if percep_economy_cps = Worse is given by \\({\\color{blue}25.13}~+~{\\color{red}23.93}\\times0+{\\color{violet}36.76}\\times0 = {\\color{blue}25.13}\\). Because both independent variables are zero, the fitted value for trudeau_therm_cps when percep_economy_cps = Worse is equivalent to the intercept of the linear regression model in Equation 7.2. This is the reason why no dummy variable is created for a reference category. This category doesn’t need its own dummy variable, since the intercept of a linear regression model represents the fitted value for this reference category.\nIf percep_economy_cps = Same, then percep_economy_cpsSame = 1 and percep_economy_cpsBetter = 0 (see Table 7.1). Therefore, substituting these values in Equation 7.2, the fitted value of trudeau_therm_cps is given by \\({\\color{blue}25.13}~+~{\\color{red}23.93}\\times1+{\\color{violet}36.76}\\times0 = {\\color{blue}25.13}~+~{\\color{red}23.93} = {\\color{red}49.06}\\). This result implies that the coefficient on percep_economy_cpsSame, \\({\\color{red}23.93}\\), indicates the difference in the fitted values of trudeau_therm_cps when percep_economy_cps is Same and when percep_economy_cps is its reference category, Worse (i.e., \\({\\color{red}49.06} - {\\color{blue}25.13} = {\\color{red}23.93}\\)).\nSimilarly, if percep_economy_cps = Better, then percep_economy_cpsSame = 0 and percep_economy_cpsBetter = 1 (see Table 7.1). Therefore, substituting these values in Equation 7.2, the fitted value of trudeau_therm_cps is given by \\({\\color{blue}25.13}~+~{\\color{red}23.93}\\times0+{\\color{violet}36.76}\\times1 = {\\color{blue}25.13}~+~{\\color{violet}36.76} = {\\color{violet}61.89}\\). Again, the coefficient on percep_economy_cpsBetter, \\({\\color{violet}36.76}\\), indicates the difference in the fitted values between when percep_economy_cps is Better and when percep_economy_cps is its reference category, Worse (i.e., \\({\\color{violet}61.89} - {\\color{blue}25.13} = {\\color{violet}36.76}\\)).\n\n\n\n\n\n\n\n\n\n\n7.3.2 How to Interpret the Linear Regression Coefficients on Dummified Variables from Categorical Independent Variable\nMore generally, we can say that the coefficient on a dummy variable created for a certain category of a categorical independent variable (say, \\(X = a\\)) indicates the difference in the fitted values (\\(\\widehat{Y}\\)) for this category (\\(X = a\\)) and the reference category (\\(X =\\) reference category).\nIn other words, the coefficient on a dummy variable for a certain category of a categorical independent variable (\\(X = a\\)) tells us how the value of \\(Y\\) for the observations with \\(X = a\\) differs, on average, from the value of \\(Y\\) for those with \\(X =\\) reference category.\nFor example, in Section 7.3.1, we saw that the coefficient on percep_economy_cpsSame (\\({\\color{red}23.93}\\)) indicates the difference in the fitted values of trudeau_therm_cps when percep_economy_cps is Sameand percep_economy_cps is the reference category, Worse (\\({\\color{red}49.06} - {\\color{blue}25.13} = {\\color{red}23.93}\\)). This coefficient, \\({\\color{red}23.93}\\), can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Same is greater, on average, by \\({\\color{red}23.93}\\) points from those whose perception of economy is the reference category, Worse.\nWe also saw that the coefficient on percep_economy_cpsBetter (\\({\\color{violet}36.76}\\)) indicates the difference in the fitted values between when percep_economy_cps is Better and when percep_economy_cps is the reference category, Worse (\\({\\color{violet}61.89} - {\\color{blue}25.13} = {\\color{violet}36.76}\\)). This coefficient, \\({\\color{violet}36.76}\\), can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Better is greater, on average, by \\({\\color{violet}36.76}\\) points from those whose perception of economy is the reference category, Worse.\nAs we saw in these examples, the coefficient on the dummy variable for a certain category of a categorical independent variable (\\(X = a\\)) should be understood as the difference in the average value of \\(Y\\) for this category (\\(X = a\\)) and the average value of \\(Y\\) for the reference category (\\(X =\\) reference category). This is the reason why a reference category is named that way.\nAs the above discussion has made it clear, the coefficient on the dummy variable for a certain category of a categorical independent variable (\\(X = a\\)) tells us the comparison between the chosen category (\\(X = a\\)) and the reference category (\\(X =\\) reference category).\nIf we want to compare the chosen category (\\(X = a\\)) with another category which is not the reference category (say, \\(X = b\\)), then we need to compute the difference from their coefficients.\nFor example, suppose that we want to compare the average Trudeau thermometer between the respondents whose perception of economy is Better and those whose is Same. The comparison is made by taking the difference of the fitted values of trudeau_therm_cps when percep_economy_cps is Better and when percep_economy_cps is Same. As we have seen, the fitted value of trudeau_therm_cps when percep_economy_cps is Better is \\({\\color{blue}25.13}~+~ {\\color{violet}36.76} = {\\color{violet}61.89}\\) , and the fitted value of trudeau_therm_cps when percep_economy_cps is Same is \\({\\color{blue}25.13}~+~{\\color{red}23.93} = {\\color{red}49.06}\\). Therefore, the difference of these fitted values is \\({\\color{violet}61.89} - {\\color{red}49.06} = {\\color{brown}12.83}\\).\nHowever, this is equivalent to the difference between the coefficient of percep_economy_cpsBetter, \\({\\color{violet}36.76}\\), and the coefficient of percep_economy_cpsSame, \\({\\color{red}23.93}\\), (\\({\\color{violet}36.76} - {\\color{red}23.93} = {\\color{brown}12.83}\\)). Therefore, we just needed to compute the difference between the coefficient of percep_economy_cpsBetter and the coefficient of percep_economy_cpsSame in the first place.\nThis resut can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Better is greater, on average, by \\({\\color{brown}12.83}\\) points from those whose perception of economy is Same.\n\n\n7.3.3 With Additional Independent Variables\nIn Section 7.3.2, we included only the dummy variables for a categorical independent variable on the right-hand side of the linear regression model. We can also include the additional independent variables on the right hand side. For example, below I added ideology and union_d on the right-hand side of the linear regression model of trudeau_therm_cps on percep_economy_cps.\n\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps + ideology + union_d, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps + ideology + \n    union_d, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                 39.3833                   22.0875                   33.8127  \n                ideology               union_dTRUE  \n                 -2.6315                    0.7463  \n\n\n\n\n\n\n\n\nAs before, in this linear regression analysis, percep_economy_cps is dummified into two dummy variables, percep_economy_cpsSame and percep_economy_cpsBetter. The interpretation of the coefficients of these dummy variables is the same as before except that the other variables ideology and union_d are now controlled for.\nThe coefficient of percep_economy_cpsSame is \\({\\color{red}22.09}\\). This can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Same is greater, on average, by \\({\\color{red}22.09}\\) points from those whose perception of economy is the reference category, Worse, controlling for the respondents’ political ideology and union membership.\nThe coefficient of percep_economy_cpsBetter is \\({\\color{violet}33.81}\\). This coefficient, \\({\\color{violet}33.81}\\), can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Better is greater, on average, by \\({\\color{violet}33.81}\\) points from those whose perception of economy is the reference category, Worse, holding their political ideology and union membership constant.\nIf we want to compare the respondents whose perception of economy is Better and those whose is Same, we need to compute the difference between the coefficient of percep_economy_cpsBetter and the coefficient of percep_economy_cpsSame (\\({\\color{violet}33.81} - {\\color{red}22.09} = {\\color{brown}11.72}\\)). As the difference is \\({\\color{brown}11.72}\\), it can be interpreted that the Trudeau thermometer for the respondents whose perception of economy is Better is greater, on average, by \\({\\color{brown}11.72}\\) points from those whose perception of economy is Same, with the respondents’ political ideology and union status held constant.\n\n\n7.3.4 Difference from Numerical Version\nComparing the linear regression results of the numeric version and the dummified version of percep_economy_cps, we can see the difference in these two specifications.\nFor your quick reference, I have reproduced the outputs of the lm() function for a simple linear regression of trudeau_therm_cps with both versions of percep_economy_cps below.\n(1) With the numeric version of percep_economy_cps\n\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\n(2) With the dummified version of percep_economy_cps\n\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                   25.13                     23.93                     36.76  \n\n\nIn the result of a simple linear regression model with the numeric version, percep_economy_cps_n, the average difference in the Trudeau thermometer is \\(18.98\\) points both between Better and Same and between Same and Worse. On the other hand, in the linear regression model with the dummified version, the average difference in the Trudeau thermometer is \\({\\color{violet}36.76} - {\\color{red}23.93} = {\\color{brown}12.83}\\) points between Better and Same, while it is \\({\\color{red}23.93}\\) points between Same and Worse.\nSimilarly, I have reproduced the outputs of the lm() function for a multiple linear regression of trudeau_therm_cps with both versions of percep_economy_cps below.\n(1) With the numeric version of percep_economy_cps\n\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + \n    union_d, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n              ideology  \n             24.7569               17.1926               -2.7193  \n         union_dTRUE  \n              0.8752  \n\n\n(2) With the dummified version of percep_economy_cps\n\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps + ideology + \n    union_d, data = ces2019)\n\nCoefficients:\n             (Intercept)    percep_economy_cpsSame  percep_economy_cpsBetter  \n                 39.3833                   22.0875                   33.8127  \n                ideology               union_dTRUE  \n                 -2.6315                    0.7463  \n\n\nIn the result of a multiple linear regression model with the numeric version, percep_economy_cps_n, the average difference in the Trudeau thermometer is \\(17.19\\) points both between Better and Same and between Same and Worse. On the other hand, in the result with the dummified version, the average difference in the Trudeau thermometer is \\({\\color{violet}33.81} - {\\color{red}22.09} = {\\color{brown}11.72}\\) points between Better and Same, while it is \\({\\color{red}22.09}\\) points between Same and Worse.\nWhen we used the numeric version, percep_economy_cps_n, the difference in Trudeau thermometer is the same whether we consider the difference between Better and Same or that between Same and Worse. On the other hand, when we used the dummified version, the difference in Trudeau thermometer is different when we consider the difference between Better and Same and when we examine the difference between Same and Worse. \nIn general, the average difference in the dependent variable between one category of ordinal categorical variable and its adjacent category is the same for all categories, if we use a numeric version of an ordinal categorical variable, but it is different for all categories of this variable, if we use the dummified version of this variable. Hence, dummification may be considered as a more flexible modeling strategy for an ordinal categorical variable than the use of a numeric version of this variable. This is a modeling choice we need to make when we include an ordinal categorical variable as an independent variable in our linear regression model.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#dummifying-nominal-categorical-independent-variable-questions",
    "href": "multi_linreg.html#dummifying-nominal-categorical-independent-variable-questions",
    "title": "7  Multiple Linear Regression",
    "section": "7.4 Dummifying Nominal Categorical Independent Variable: Questions",
    "text": "7.4 Dummifying Nominal Categorical Independent Variable: Questions\n{#sec-dum-ncat-ind-q}\nFor an ordinal categorical variable, we can consider dummifying it and transforming it into a numeric variable as alternatives, but for a nominal categorical variable, dummifying may be the only appropriate option. The interpretation of the results when we use independent variables dummified from a nominal categorical variable in a linear regression model is the same as the interpretation for dummified independent variables from an ordinal categorical variable in Section 7.3. Therefore, instead of repeating the explanation on how to interpret a model, I want you to work on the following questions on dummifying a nominal categorical independent variable. Answers to these questions will be made available in ?sec-dum-ncat-ind-a after all tutorial sections have covered this chapter.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#dummifying-nominal-categorical-independent-variable-answers",
    "href": "multi_linreg.html#dummifying-nominal-categorical-independent-variable-answers",
    "title": "7  Multiple Linear Regression",
    "section": "7.5 Dummifying Nominal Categorical Independent Variable: Answers",
    "text": "7.5 Dummifying Nominal Categorical Independent Variable: Answers\n{#sec-dum-ncat-ind-a}",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#sec-dum-ncat-ind-q",
    "href": "multi_linreg.html#sec-dum-ncat-ind-q",
    "title": "7  Multiple Linear Regression",
    "section": "7.4 Dummifying Nominal Categorical Independent Variable: Questions",
    "text": "7.4 Dummifying Nominal Categorical Independent Variable: Questions\nFor an ordinal categorical variable, we can consider dummifying it and transforming it into a numeric variable as alternatives, but for a nominal categorical variable, dummifying may be the only appropriate option. As the interpretation of the results remain the same as in Section 7.3, instead of repeating the explanation on how to interpret a model, I want you to work on the following questions on dummifying a nominal categorical independent variable. Answers to these questions will be made available in Section 7.5 after all tutorial sections have covered this chapter.\n\n \nLet’s use the province of residence of the respondents (province) in the ces2019 data frame as an example.\n \nQuestion 1\nWhat will be a reference category when we dummify province on the right hand side of a linear regression model using the lm() function? Use the levels() function to find out.\n \nQuestion 2\nFit a linear regression model of trudeau_therm_cps on province using the lm() function. Interpret the intercept and the coefficient on provinceON.\n \nQuestion 3\nFit a linear regression model of trudeau_therm_cps on province, percep_economy_cps_n, ideology, and union_d using the lm() function. Interpret the coefficients on provinceON, provinceSK, and percep_economy_cps_n, respectively.\n \nQuestion 4\nDummifying all categories except one is not the only way to create a dummy variable from a nominal categorical variable. An alternative is to create a dummy variable only for a single category or a subset of categories of a nominal categorical variable. In this question, we consider a single dummy variable for a subset of categories of province.\nSuppose we theorized that the respondents’ feelings about the incumbent Liberal prime minister are different between the Prairies (Alberta, Manitoba, and Saskatchewan) and the rest of the provinces. In this case, we want to dummify province such that prairies = 1 if the respondents lived in these provinces and prairies = 0 otherwise. We can create such a variable by the ifelse() function introduced in Section 6.3.4. Read that section again to review the basics of the ifelse() function. For the current purpose, you may specify the condition in the ifelse() function as follows.\n\n  ces2019 &lt;- mutate(ces2019,\n      # Create a new variable \"prairies\" using the ifelse() function.\n                    prairies = ifelse(province %in% c(\"AB\",\"MB\",\"SK\"), \"TRUE\", \"FALSE\") )\n                        # This ifelse() function assigns \"TRUE\" to observations if\n                        # \"province\" is \"AB\", \"MB\" or \"SK\" but assigns \"FALSE\" otherwise.\n      # Then, we transform prairies into a logical variable.\n  ces2019 &lt;- mutate(ces2019, prairies = as.logical(prairies) )\n\nIn the above code, the condition for the ifelse() function is specified as province %in% c(\"AB\",\"MB\",\"SK\"), which means that “province is either AB or MB or SK.” If you want to specify a condition that a certain variable, say var, equals either A or B or C or D, you can use %in% to specify the condition as var %in% c(\"A\",\"B\",\"C\",\"D\").\nLet’s check if prairies was created as we wanted.\n\n  table(ces2019$prairies, ces2019$province, useNA = \"always\")\n\n       \n         AB  BC  MB  NB  NL  NS  ON  PE  QC  SK &lt;NA&gt;\n  FALSE   0 804   0 201 201 200 807 201 802   0    0\n  TRUE  282   0 261   0   0   0   0   0   0 262    0\n  &lt;NA&gt;    0   0   0   0   0   0   0   0   0   0    0\n\n\nFit a linear regression model of trudeau_therm_cps on prairies, percep_economy_cps_n, ideology, and union_d using the lm() function.\nInterpret the coefficient on prairiesTRUE.\n \nQuestion 5\nWe may also use multiple dummy variables corresponding to different subsets of a nominal categorical variable. Suppose we theorized that, in addition to the Prairies, the respondents’ feelings about the incumbent Liberal prime minister may also be different in the Maritimes (New Brunswick, Nova Scotia, and Prince Edward Island) from the rest of the provinces.\nCreate a dummy variable for the Maritimes, named maritimes, using the ifelse() function. Then, fit a linear regression model of trudeau_therm_cps on prairies, maritimes, percep_economy_cps_n, ideology, and union_d using the lm() function.\nInterpret the coefficients on prairiesTRUE and maritimesTRUE, respectively.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "multi_linreg.html#sec-dum-ncat-ind-a",
    "href": "multi_linreg.html#sec-dum-ncat-ind-a",
    "title": "7  Multiple Linear Regression",
    "section": "7.5 Dummifying Nominal Categorical Independent Variable: Answers",
    "text": "7.5 Dummifying Nominal Categorical Independent Variable: Answers\nAnswers to the questions posed in Section 7.4 will be made available here after all tutorial sections have covered this chapter. Schedule to come back to review these answers.\n \nLet’s use the province of residence of the respondents (province) in the ces2019 data frame as an example.\n \nQuestion 1\nWhat will be a reference category when we dummify province on the right hand side of a linear regression model using the lm() function? Use the levels() function to find out.\nBelow is a list of levels of this variable.\n\n  levels(ces2019$province)\n\n [1] \"AB\" \"BC\" \"MB\" \"NB\" \"NL\" \"NS\" \"ON\" \"PE\" \"QC\" \"SK\"\n\n\nBecause the first level is AB, Alberta will be used as a reference category.\n \nQuestion 2\nFit a linear regression model of trudeau_therm_cps on province using the lm() function. Interpret the intercept and the coefficient on provinceON.\nWe fit a linear regression model of trudeau_therm_cps on province as below.\n\n  lm(formula = trudeau_therm_cps ~ province, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ province, data = ces2019)\n\nCoefficients:\n(Intercept)   provinceBC   provinceMB   provinceNB   provinceNL   provinceNS  \n     24.910       17.566       12.487       21.535       22.019       23.955  \n provinceON   provincePE   provinceQC   provinceSK  \n     24.083       24.600       24.225        3.426  \n\n\n\nThe intercept is the fitted value for the reference category of this variable (province). Since the reference category is Alberta, the intercept is the fitted value for Alberta. The intercept in the above linear regression result is \\(24.91\\). This may be interpreted as follows.\n“Feeling thermometer about Trudeau is, on average, 24.91 points for those respondents who lived in Alberta.”\nThe coefficient on a dummy variable for one categocy of a nominal categorical variable represents the difference in the average value of the dependent variable between the observations for which the variable is this category and those for which the variable is the reference category. Because the coefficient of provinceON is \\(24.08\\), and the reference category is Alberta, this coefficient may be interpreted as follows.\n“Feeling thermometer about Trudeau is, on average, 24.08 points higher for those respondents who lived in Ontario than those who lived in Alberta.”\n \nQuestion 3\nFit a linear regression model of trudeau_therm_cps on province, percep_economy_cps_n, ideology, and union_d using the lm() function. Interpret the coefficients on provinceON, provinceSK, and percep_economy_cps_n, respectively.\nWe fit a linear regression model of trudeau_therm_cps on province, percep_economy_cps_n, ideology, and union_d as below.\n\n  lm(formula = trudeau_therm_cps ~ province + percep_economy_cps_n\n                                    + ideology + union_d, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ province + percep_economy_cps_n + \n    ideology + union_d, data = ces2019)\n\nCoefficients:\n         (Intercept)            provinceBC            provinceMB  \n             15.2848               11.7557               10.8040  \n          provinceNB            provinceNL            provinceNS  \n             16.9362               18.4670               12.1679  \n          provinceON            provincePE            provinceQC  \n             15.3387               15.8607               12.3670  \n          provinceSK  percep_economy_cps_n              ideology  \n              3.4424               15.8163               -2.6628  \n         union_dTRUE  \n              0.5959  \n\n\nBecause there are additional control variables, the coefficient on a dummy variable for one category of a nominal categorical variable represents the difference in the average value of the dependent variable between the observations for which the variable is this category and those for which the variable is the reference category, controlling for other control variables.\nThe coefficient of provinceON can be interpreted as follows.\n“Feeling thermometer about Trudeau is, on average, 15.34 points higher for those respondents who lived in Ontario than those who lived in Alberta, controlling for the perception of economy, political ideology, and union membership.”\nThe coefficients on provinceSK can be interpreted as follows.\n“Feeling thermometer about Trudeau is, on average, 3.44 points higher for those respondents who lived in Saskatchewan than those who lived in Alberta, holding the perception of economy, political ideology, and union membership constant.”\nThe coefficients on percep_economy_cps_n can be interpreted as below.\n“Feeling thermometer about Trudeau is, on average, 15.82 points higher for those respondents whose perception of economy is better (the same) than those whose perception of economy is the same (worse), controlling for the provinces of residence, political ideology, and union membership.”\n \nQuestion 4\nDummifying all categories except one is not the only way to create a dummy variable from a nominal categorical variable. An alternative is to create a dummy variable only for a single category or a subset of categories of a nominal categorical variable. In this question, we consider a single dummy variable for a subset of categories of province.\nSuppose we theorized that the respondents’ feelings about the incumbent Liberal prime minister are different between the Prairies (Alberta, Manitoba, and Saskatchewan) and the rest of the provinces. In this case, we want to dummify province such that prairies = 1 if the respondents lived in these provinces and prairies = 0 otherwise. We can create such a variable by the ifelse() function introduced in Section 6.3.4. Read that section again to review the basics of the ifelse() function. For the current purpose, you may specify the condition in the ifelse() function as follows.\n\n  ces2019 &lt;- mutate(ces2019,\n      # Create a new variable \"prairies\" using the ifelse() function.\n                    prairies = ifelse(province %in% c(\"AB\",\"MB\",\"SK\"), \"TRUE\", \"FALSE\") )\n                        # This ifelse() function assigns \"TRUE\" to observations if\n                        # \"province\" is \"AB\", \"MB\" or \"SK\" but assigns \"FALSE\" otherwise.\n      # Then, we transform prairies into a logical variable.\n  ces2019 &lt;- mutate(ces2019, prairies = as.logical(prairies) )\n\nIn the above code, the condition for the ifelse() function is specified as province %in% c(\"AB\",\"MB\",\"SK\"), which means that “province is either AB or MB or SK.” If you want to specify a condition that a certain variable, say var, equals either A or B or C or D, you can use %in% to specify the condition as var %in% c(\"A\",\"B\",\"C\",\"D\").\nLet’s check if prairies was created as we wanted.\n\n  table(ces2019$prairies, ces2019$province, useNA = \"always\")\n\n       \n         AB  BC  MB  NB  NL  NS  ON  PE  QC  SK &lt;NA&gt;\n  FALSE   0 804   0 201 201 200 807 201 802   0    0\n  TRUE  282   0 261   0   0   0   0   0   0 262    0\n  &lt;NA&gt;    0   0   0   0   0   0   0   0   0   0    0\n\n\nFit a linear regression model of trudeau_therm_cps on prairies, percep_economy_cps_n, ideology, and union_d using the lm() function.\nInterpret the coefficient on prairiesTRUE.\nWe fit a linear regression model of trudeau_therm_cps on prairies, percep_economy_cps_n, ideology, and union_d as below.\n\n  lm(formula = trudeau_therm_cps ~ prairies + percep_economy_cps_n\n                                    + ideology + union_d, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ prairies + percep_economy_cps_n + \n    ideology + union_d, data = ces2019)\n\nCoefficients:\n         (Intercept)          prairiesTRUE  percep_economy_cps_n  \n             28.6463               -9.0945               16.0341  \n            ideology           union_dTRUE  \n             -2.6583                0.6047  \n\n\nGiven this dummy variable for the Prairies, the reference category is all provinces other than the Prairies. Therefore, the coefficient on prairiesTRUE indicates the average difference in trudeau_therm_cps between the respondents who lived in the Prairies and those who lived in other provinces, controlling for other variables.\nThe coefficient on prairiesTRUE may be interpreted as follows.\n“Feeling thermometer about Trudeau is, on average, 9.09 points lower for those respondents who lived in the Prairies than those who lived in other provinces, controlling for the perception of economy, political ideology, and union membership.”\n \nQuestion 5\nWe may also use multiple dummy variables corresponding to different subsets of a nominal categorical variable. Suppose we theorized that, in addition to the Prairies, the respondents’ feelings about the incumbent Liberal prime minister may also be different in the Maritimes (New Brunswick, Nova Scotia, and Prince Edward Island) from the rest of the provinces.\nCreate a dummy variable for the Maritimes, named maritimes, using the ifelse() function. Then, fit a linear regression model of trudeau_therm_cps on prairies, maritimes, percep_economy_cps_n, ideology, and union_d using the lm() function.\nInterpret the coefficients on prairiesTRUE and maritimesTRUE, respectively.\nWe create a new dummy variable maritimes as below.\n\n  ces2019 &lt;- mutate(ces2019,\n      # Create a new variable \"maritimes\" using the ifelse() function.\n                    maritimes = ifelse(province %in% c(\"NB\",\"NS\",\"PE\"), \"TRUE\", \"FALSE\") )\n      # This ifelse() function assigns \"TRUE\" to observations if\n      # \"province\" is \"NB\", \"NS\" or \"PE\" but assigns \"FALSE\" otherwise.\n  ces2019 &lt;- mutate(ces2019, # Then, we transform prairies into a logical variable.\n                  prairies = as.logical(prairies) )\n\nLet’s check if maritimes was created as we wanted.\n\n  table(ces2019$maritimes, ces2019$province, useNA = \"always\")\n\n       \n         AB  BC  MB  NB  NL  NS  ON  PE  QC  SK &lt;NA&gt;\n  FALSE 282 804 261   0 201   0 807   0 802 262    0\n  TRUE    0   0   0 201   0 200   0 201   0   0    0\n  &lt;NA&gt;    0   0   0   0   0   0   0   0   0   0    0\n\n\n\n  lm(formula = trudeau_therm_cps ~ prairies + maritimes + percep_economy_cps_n\n                                    + ideology + union_d, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ prairies + maritimes + percep_economy_cps_n + \n    ideology + union_d, data = ces2019)\n\nCoefficients:\n         (Intercept)          prairiesTRUE         maritimesTRUE  \n             28.3114               -8.8188                1.4265  \npercep_economy_cps_n              ideology           union_dTRUE  \n             16.0503               -2.6527                0.6189  \n\n\nBecause the above model includes dummy variables for the Prairies and the Maritimes, the reference category is the provinces other than those in the Prairies and the Maritimes. Therefore, the coefficients on prairiesTRUE and maritimesTRUE indicate, respectively, the average difference in trudeau_therm_cps between the respondents who lived in the Prairies and Maritimes and those who lived in the provinces other than the Prairies and the Maritimes, controlling for other variables.\nThe coefficients on prairiesTRUE and maritimesTRUE may be interpreted as follows.\n“Feeling thermometer about Trudeau is, on average, 8.82 points lower for those respondents who lived in the Prairies than those who lived in the provinces other than the Prairies and the Maritimes, controlling for the perception of economy, political ideology, and union membership.”\n“Feeling thermometer about Trudeau is, on average, 1.43 points higher for those respondents who lived in the Maritimes than those who lived in the provinces other than the Prairies and the Maritimes, holding the perception of economy, political ideology, and union membership constant.”",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Multiple Linear Regression</span>"
    ]
  },
  {
    "objectID": "linreg_inf.html",
    "href": "linreg_inf.html",
    "title": "8  Statistical Inference for Linear Regression",
    "section": "",
    "text": "8.1 Prepare Variables\nAs in the previous chapters, create percep_economy_cps_n, which is a numeric version of percep_economy_cps, and union_d, a logical version of union.\nces2019 &lt;- ces2019 |&gt; \n      mutate(percep_economy_cps = fct_relevel(percep_economy_cps, \n              \"(2) Worse\", \"(3) About the same\", \"(1) Better\") ) |&gt; \n      mutate(percep_economy_cps = fct_recode(percep_economy_cps, \n                                \"Worse\" = \"(2) Worse\", \n                                \"Same\" = \"(3) About the same\", \n                                \"Better\" = \"(1) Better\") ) |&gt; \n      mutate(percep_economy_cps_n = as.numeric(percep_economy_cps))\nces2019 &lt;-  ces2019 |&gt; # Change the name of categories of union to TRUE and FALSE.\n      mutate( union_d = fct_recode(union, \"TRUE\" = \"(1) Yes\", \"FALSE\" = \"(2) No\") ) |&gt; \n      mutate( union_d = as.logical(union_d) )  # Then, apply the as.logical() function.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistical Inference for Linear Regression</span>"
    ]
  },
  {
    "objectID": "linreg_inf.html#summarize-linear-regression-results-summ",
    "href": "linreg_inf.html#summarize-linear-regression-results-summ",
    "title": "8  Statistical Inference for Linear Regression",
    "section": "8.3 Summarize Linear Regression Results: summ()",
    "text": "8.3 Summarize Linear Regression Results: summ()\nInstall the jtools package. Refer to Section 1.4.2 if you want to recall more details on how to install a new package.\n\n  install.packages(\"jtools\")\n\nThen, load jtools.\n\n  library(jtools)\n\nHere we use the summ() function from the jtools package to derive the detailed results of the lm() function. This function gives us similar information on the result of the lm() function to the one derived by the summary() function. Arguably, the output from the summ() function is more readable than the ouput from the summary() function.\nThe basic syntax of the summ() function is the same as the summary()function — i.e., to include the output of the lm() function in the summ() function as its argument. Let’s show the detailed information of the linear regression result stored in model2 using the summ() function.\n\n  summ(model2)\n\nMODEL INFO:\nObservations: 2346 (1675 missing obs. deleted)\nDependent Variable: trudeau_therm_cps\nType: OLS linear regression \n\nMODEL FIT:\nF(3,2342) = 248.76, p = 0.00\nR² = 0.24\nAdj. R² = 0.24 \n\nStandard errors:OLS\n---------------------------------------------------------\n                              Est.   S.E.   t val.      p\n-------------------------- ------- ------ -------- ------\n(Intercept)                  24.76   2.26    10.94   0.00\npercep_economy_cps_n         17.19   0.77    22.25   0.00\nideology                     -2.72   0.25   -10.67   0.00\nunion_dTRUE                   0.88   1.35     0.65   0.52\n---------------------------------------------------------\n\n\nThere are three sets of information in the above output of the summ() function. The first set of information at the top of the output is MODEL INFO. The most useful piece of information here is the number of observations included in the model and the number of missing observations (those with missing values for at least one of the variables included in the model) excluded from the estimation.\nThe second set of information at the middle of the output is MODEL FIT. I will not cover these statistics for a model fit in this class, except for R-squared (\\(R^2\\)), which I will briefly cover in my lecture later in the semester.\nThe third set of information at the bottom is a linear regression table. The first column of the table is a list of the linear regression coefficients. Est. in the second column is the point estimates of the linear regression coefficients for the intercept and the variables listed in the first column. S.E. in the third column is the standard errors of those linear regression coefficients. Many academic articles on empirical research in political science report these statistics.\nThe information in the fourth and fifth columns concern hypothesis testing. t val. in the fourth column is called a t-statistic or t-value, which is the point estimate of a coefficient divided by its standard error. Note that t-statistic is optional in my lecture as it may be too technical for this class.\np in the fifth column is a p-value, from which we can interpret the statistical significance of each linear regression coefficient.\nWe can also change the number of decimal places that appear in the table by specifying the digits argument. For example, if we specify digits = 4, it will display numbers up to the fourth decimal place, as below.\n\n  summ(model2, digits = 4)\n\nMODEL INFO:\nObservations: 2346 (1675 missing obs. deleted)\nDependent Variable: trudeau_therm_cps\nType: OLS linear regression \n\nMODEL FIT:\nF(3,2342) = 248.7557, p = 0.0000\nR² = 0.2416\nAdj. R² = 0.2407 \n\nStandard errors:OLS\n-----------------------------------------------------------------\n                                Est.     S.E.     t val.        p\n-------------------------- --------- -------- ---------- --------\n(Intercept)                  24.7569   2.2629    10.9405   0.0000\npercep_economy_cps_n         17.1926   0.7728    22.2481   0.0000\nideology                     -2.7193   0.2549   -10.6683   0.0000\nunion_dTRUE                   0.8752   1.3498     0.6483   0.5168\n-----------------------------------------------------------------\n\n\nWe can also display the confidence intervals for linear regression coefficients by setting the confint = TRUE.\n\n  summ(model2, confint = TRUE)\n\nMODEL INFO:\nObservations: 2346 (1675 missing obs. deleted)\nDependent Variable: trudeau_therm_cps\nType: OLS linear regression \n\nMODEL FIT:\nF(3,2342) = 248.76, p = 0.00\nR² = 0.24\nAdj. R² = 0.24 \n\nStandard errors:OLS\n------------------------------------------------------------------\n                              Est.    2.5%   97.5%   t val.      p\n-------------------------- ------- ------- ------- -------- ------\n(Intercept)                  24.76   20.32   29.19    10.94   0.00\npercep_economy_cps_n         17.19   15.68   18.71    22.25   0.00\nideology                     -2.72   -3.22   -2.22   -10.67   0.00\nunion_dTRUE                   0.88   -1.77    3.52     0.65   0.52\n------------------------------------------------------------------\n\n\nIn the above output, 2.5% in the third column is the lower bound of a 95% confidence interval, and 97.5% in the fourth column is the upper bound. Note that the percentage between 2.5% and 97.5% is 95%. Together, they form a 95% confidence interval.\nWe can change the confidence level by the ci.width argument. We need to specify the confidence level as a number between 0 and 1, rather than a percentage. Below, I specified ci.width = 0.99 to derive the 99% confidence intervals.\n\n  summ(model2, confint = TRUE, ci.width = 0.99)\n\nMODEL INFO:\nObservations: 2346 (1675 missing obs. deleted)\nDependent Variable: trudeau_therm_cps\nType: OLS linear regression \n\nMODEL FIT:\nF(3,2342) = 248.76, p = 0.00\nR² = 0.24\nAdj. R² = 0.24 \n\nStandard errors:OLS\n------------------------------------------------------------------\n                              Est.    0.5%   99.5%   t val.      p\n-------------------------- ------- ------- ------- -------- ------\n(Intercept)                  24.76   18.92   30.59    10.94   0.00\npercep_economy_cps_n         17.19   15.20   19.18    22.25   0.00\nideology                     -2.72   -3.38   -2.06   -10.67   0.00\nunion_dTRUE                   0.88   -2.60    4.35     0.65   0.52\n------------------------------------------------------------------\n\n\nAs before, we can also change the number of decimal places to appear by specifying the digits argument.\n\n  summ(model2, confint = TRUE, ci.width = 0.99, digits = 4)\n\nMODEL INFO:\nObservations: 2346 (1675 missing obs. deleted)\nDependent Variable: trudeau_therm_cps\nType: OLS linear regression \n\nMODEL FIT:\nF(3,2342) = 248.7557, p = 0.0000\nR² = 0.2416\nAdj. R² = 0.2407 \n\nStandard errors:OLS\n----------------------------------------------------------------------------\n                                Est.      0.5%     99.5%     t val.        p\n-------------------------- --------- --------- --------- ---------- --------\n(Intercept)                  24.7569   18.9234   30.5905    10.9405   0.0000\npercep_economy_cps_n         17.1926   15.2004   19.1847    22.2481   0.0000\nideology                     -2.7193   -3.3764   -2.0622   -10.6683   0.0000\nunion_dTRUE                   0.8752   -2.6046    4.3549     0.6483   0.5168\n----------------------------------------------------------------------------\n\n\nAs I covered in my lecture, when a (\\(100 - \\alpha\\)) % confidence interval for a linear regression coefficient does not include zero, we say that this coefficient is statistically significant (or statistically distinguishable from zero) at the \\(\\alpha\\) % significance level. In the above example, since the 99% confidence intervals for all linear regression coefficients except for union_d don’t include zero, all these coefficients except union_d are statistically significant at the 1% significance level.\nWe can also interpret statistical significance from the p-values presented in the last column indicated by p.\nIf the p-value is smaller than a (a is a number between 0 and 1), this suggests that the coefficient is statistically significant (or statistically distinguishable from zero) at the (a \\(\\times\\) 100)% significance level. For example, if the p-value is smaller than 0.05, the coefficient is statistically significant at the 5% significance level. In the above table, the p-values for all except union_d are indicated as 0.0000, which means that the p-values are smaller than 0.0000, and therefore, rounded up to 0.0000. Since these p-values are smaller than 0.05, these coefficients are statistically significant at the 5% significance level.\nMoreover, these coefficients are also statistically significant at the 1% significance level as their p-values are smaller than 0.01. They are also statistically significant at the 0.1% significance level because they are smaller than 0.001. They are statistically significant even at the 0.01% significance level as the p-values are smaller than 0.0001.\nOn the other hand, the p-value for union_d is 0.52, indicating that this coefficient is statistically insignificant (or not statistically distinguishable from zero) even at the 10% significance level.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistical Inference for Linear Regression</span>"
    ]
  },
  {
    "objectID": "linreg_inf.html#linear-regression-table-export_summs",
    "href": "linreg_inf.html#linear-regression-table-export_summs",
    "title": "8  Statistical Inference for Linear Regression",
    "section": "8.4 Linear Regression Table: export_summs()",
    "text": "8.4 Linear Regression Table: export_summs()\nWe can also format the result of a linear regression into a nice table using the export_summs() function of the jtools package. To use this function, we also need the huxtable package.\nFirst, install the huxtable package.\n\n  install.packages(\"huxtable\")\n\nThen, load huxtable.\n\n  library(huxtable)\n\nNow we can use the export_summs() function from the jtools package. The basic syntax is the same as the summ() function.\n\n  export_summs(model2)\n\n\n\nModel 1\n\n(Intercept)24.76 ***\n\n(2.26)   \n\npercep_economy_cps_n17.19 ***\n\n(0.77)   \n\nideology-2.72 ***\n\n(0.25)   \n\nunion_dTRUE0.88    \n\n(1.35)   \n\nN2346       \n\nR20.24    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nThis is similar to the popular format of a linear regression table we see in many political science research articles. As you can see in the table, the first column is a list of linear regression coefficients including an intercept. In the next column, we can see the point estimates of these coefficients. The numbers in parentheses are the standard errors for each coefficient. N is the number of observations included in the linear regression analysis, and R2 is the R-squared for this linear regression model (as I mentioned before, I will cover R-squared in a lecture later in the semester).\nThe star signs (asterisks) right next to each coefficient estimate indicate statistical significance of each coefficient. You can find the legend for these star signs at the bottom of the table, which states that\n     *** p &lt; 0.001, ** p &lt; 0.01, and * p &lt; 0.05.\n\np in this legend refers to the p-value.\nThis legend can be read as:\n    *** indicates that the p-value is smaller than 0.001;\n     ** indicates that the p-value is smaller than 0.01; and\n      * indicates that the p-value is smaller than 0.05.\n\nTherefore, if the coefficient is given the *** sign, this means that this coefficient is statistically significant at the 0.1% significance level;\nif it is given **, this coefficient is statistically significant at the 1% significance level (but not statistically significant at the 0.1% significance level);\nif it is given *, this coefficient is statistically significant at the 5% significance level (but not at the 1% significance level); and\nif it is not given any stars, the coefficient is not statistically significant at the 5% or lower significance levels.\nIn the example above, all coefficients except for union_dTRUE are given ***, indicating that these coefficients are statistically significant at the 0.1% significance level. There is no star sign given to union_dTRUE, suggesting that this coefficient is not statistically significant even at the 5% significance level, the highest significance level reported in this table.\nBelow is another example, which is a linear regression of the democratic candidate’s vote share in the U.S. gubernatorial elections (ranney3_gub_prop) on the proportion of Democratic identifiers (democrat) in each state.\n\n  lm(formula = ranney3_gub_prop*100 ~ democrat, data = usstates2010) |&gt; \n    export_summs()\n\n\n\nModel 1\n\n(Intercept)26.76 ***\n\n(7.09)   \n\ndemocrat0.66 ** \n\n(0.22)   \n\nN49       \n\nR20.16    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nIn this table, the coefficient on democrat is given two stars (**), indicating that the coefficient on this variable is statistically significant at the 1% significance level (but not at the 0.1% significance level).\nThe export_summs() function can also create a table which juxtaposes a simple and multiple linear regression models. For example, the following code creates a table with both simple and multiple linear regression models for trudeau_therm_cps (recall that model1 is the simple linear regression model and model2 is the multiple linear regression model created earlier in Section 8.2).\n\n  export_summs(model1, model2)\n\n\n\nModel 1Model 2\n\n(Intercept)8.13 ***24.76 ***\n\n(1.22)   (2.26)   \n\npercep_economy_cps_n18.98 ***17.19 ***\n\n(0.61)   (0.77)   \n\nideology       -2.72 ***\n\n       (0.25)   \n\nunion_dTRUE       0.88    \n\n       (1.35)   \n\nN3859       2346       \n\nR20.20    0.24    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nA table like this is convenient for comparing the coefficient estimates for a certain variable of our interest across different models. In the present example, we may be interested in how the coefficient estimate for percep_economy_cps_n changes between simple and multiple linear regression models.\nWe can replace the standard errors in the table with confidence intervals by specifying the following argument in the export_summs() function.\n\n  export_summs(model1, model2,\n               error_format = \"[{conf.low}, {conf.high}]\")\n\n\n\nModel 1Model 2\n\n(Intercept)8.13 ***24.76 ***\n\n[5.74, 10.52]   [20.32, 29.19]   \n\npercep_economy_cps_n18.98 ***17.19 ***\n\n[17.79, 20.17]   [15.68, 18.71]   \n\nideology       -2.72 ***\n\n       [-3.22, -2.22]   \n\nunion_dTRUE       0.88    \n\n       [-1.77, 3.52]   \n\nN3859       2346       \n\nR20.20    0.24    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nIn this table, a pair of numbers in the squared brackets below each coefficient estimate indicates the confidence interval for that coefficient. For example, [17.79, 20.17] below the coefficient estimate for percep_economy_cps_n in Model 1 is the 95% confidence interval for the coefficient on percep_economy_cps_n.\nAs before, we can change the confidence level using the ci.width argument and the number of decimal places to appear using the digits argument. In the code below, I set the confidence level at 99% and decimal places to appear at four.\n\n  export_summs(model1, model2,\n               error_format = \"[{conf.low}, {conf.high}]\", \n               ci.width = 0.99, digits = 4)\n\n\n\nModel 1Model 2\n\n(Intercept)8.1281 ***24.7569 ***\n\n[5.7399, 10.5162]   [20.3195, 29.1944]   \n\npercep_economy_cps_n18.9823 ***17.1926 ***\n\n[17.7940, 20.1705]   [15.6772, 18.7080]   \n\nideology         -2.7193 ***\n\n         [-3.2191, -2.2194]   \n\nunion_dTRUE         0.8752    \n\n         [-1.7718, 3.5222]   \n\nN3859         2346         \n\nR20.2028    0.2416    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistical Inference for Linear Regression</span>"
    ]
  },
  {
    "objectID": "linreg_inf.html#use-same-subset-of-data-across-different-models-drop_na",
    "href": "linreg_inf.html#use-same-subset-of-data-across-different-models-drop_na",
    "title": "8  Statistical Inference for Linear Regression",
    "section": "8.5 Use Same Subset of Data Across Different Models: drop_na()",
    "text": "8.5 Use Same Subset of Data Across Different Models: drop_na()\nIn the linear regression table presented above, which juxtaposed the result of simple and multiple linear regression models of trudeau_therm_cps, you might have noticed that the number of observations included in the models is different between these models. In particular, there are 3,859 observations included in the simple linear regression model (Model 1 in the table), while the number of observations is dropped to 2,346 in the multiple linear regression model (Model 2). The reason for this relatively large difference in the number of observations is that these two variables are based on the questions asked in different portions of the Canadian Election Study in 2019. More precisely, percep_economy_cps_n is based on the question asked in the Campaign Period Survey (CPS) and ideology is based on the question asked in the Post Election Survey (PES). PES was administered for a subset of the respondents included in CPS.\nGiven that the difference in the number of observations is relatively large, we may want to restrict the observations included in the simple linear regression model to those included in the multiple linear regression model. We can restrict our sample by the drop_na() function. The following code creates a new data frame, named ev_data which includes only the respondents who answered all the questions related to trudeau_therm_cps, percep_economy_cps_n, ideolgoy, and union_d.\n\n  ev_data &lt;- ces2019 |&gt; \n              drop_na(trudeau_therm_cps, percep_economy_cps_n, ideology, union_d)\n\nLet’s reestimate the simple and multiple linear regression models of trudeau_therm_cps on percep_economy_cps_n, using this new data frame.\n\n  model1b &lt;- lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ev_data)\n\n\n  model2b &lt;- lm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + union_d, \n                data = ev_data)\n\nLet’s create a table for the results of both linear regression models using the export_summs() function.\n\n  export_summs(model1b, model2b,\n               error_format = \"[{conf.low}, {conf.high}]\")\n\n\n\nModel 1Model 2\n\n(Intercept)7.79 ***24.76 ***\n\n[4.67, 10.91]   [20.32, 29.19]   \n\npercep_economy_cps_n18.96 ***17.19 ***\n\n[17.44, 20.47]   [15.68, 18.71]   \n\nideology       -2.72 ***\n\n       [-3.22, -2.22]   \n\nunion_dTRUE       0.88    \n\n       [-1.77, 3.52]   \n\nN2346       2346       \n\nR20.20    0.24    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nNow we have the same number of observations in both models. That is, the number of observations for the simple linear regression model is now much smaller (2,346) than before (3,859). However, the reestimation result of the simple linear regression is not much different from the previous result when the sample was not restricted to those without missing values for ideology and union_d.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistical Inference for Linear Regression</span>"
    ]
  },
  {
    "objectID": "linreg_inf.html#export-linear-regression-table-to-ms-word-document",
    "href": "linreg_inf.html#export-linear-regression-table-to-ms-word-document",
    "title": "8  Statistical Inference for Linear Regression",
    "section": "8.6 Export Linear Regression Table to MS-Word Document",
    "text": "8.6 Export Linear Regression Table to MS-Word Document\nWe can also produce an MS-Word document of the table produced above using the export_summs() function. But for this purpose, we also need the officer and flextable packages.\nFirst, install both the officer and flextable packages.\n\n  install.packages( c(\"officer\", \"flextable\") )\n\nThen, load officer and flextable.\n\n  library(officer)\n  library(flextable)\n\nWe can export the table to an MS-Word document by specifying the to.file and file.name arguments in the explort_summs() function. The to.file argument should be \"docx\", as we want to produce an MS-Word document. You can specify any file name for the MS-Word file in the file.name argument. Here I used \"table.docx\".\n\n  export_summs(model1b, model2b,\n               error_format = \"[{conf.low}, {conf.high}]\",\n               to.file = \"docx\", file.name = \"table.docx\")\n\nAn MS-Word document named “table.docx” should be created in your working directory. Open this Word document to check its content. The same table produced above should be given in this Word document. As you can see in this Word document, the variable names in R are used in the table produced this way. You should change these names to those you use in your paper, which should also be more easily interpreted by readers. For example, you may replace percep_ceonomy_cps_n with “Perception of Economy” or “PecepEcon” and union_dTRUE with “Union Membership” or “UNION.” If you use something like “PercepEcon” and “UNION,” you should first define what these symbols mean in your paper.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistical Inference for Linear Regression</span>"
    ]
  },
  {
    "objectID": "linreg_inf.html#estimate-linear-regression-models",
    "href": "linreg_inf.html#estimate-linear-regression-models",
    "title": "8  Statistical Inference for Linear Regression",
    "section": "8.2 Estimate Linear Regression Models",
    "text": "8.2 Estimate Linear Regression Models\nFirst, let’s estimate a simple linear regression model of trudeau_therm_cps on percep_economy_cps_n.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\nWe can assign the result of the lm() function to a new object. For example, I assigned the above result to an object called model1 below.\n\n  model1 &lt;- lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nThen, we can see the linear regression result stored in model1 by typing the name of this new object in the Console.\n\n  model1\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\nLet’s assign the result of a multiple linear regression of trudeau_therm_cps on percep_economy_cps_n and ideology and union_d to a new object, named model2.\n\n  model2 &lt;- lm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + union_d, \n                      data = ces2019)\n\nAgain, we can access this result by typing model2 in the Console.\n\n  model2\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + \n    union_d, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n              ideology  \n             24.7569               17.1926               -2.7193  \n         union_dTRUE  \n              0.8752  \n\n\nThere is more information in the result of the lm() function than what appears in the R console this way. We can access them, for example, by the summary() function. A basic syntax of the summary() function is to include the output of the lm() function as its argument (i.e., inside the parentheses).\n\n  summary(model2)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + \n    union_d, data = ces2019)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-71.77 -20.63   0.86  19.87  85.24 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           24.7569     2.2629  10.940   &lt;2e-16 ***\npercep_economy_cps_n  17.1926     0.7728  22.248   &lt;2e-16 ***\nideology              -2.7193     0.2549 -10.668   &lt;2e-16 ***\nunion_dTRUE            0.8752     1.3498   0.648    0.517    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 26.59 on 2342 degrees of freedom\n  (1675 observations deleted due to missingness)\nMultiple R-squared:  0.2416,    Adjusted R-squared:  0.2407 \nF-statistic: 248.8 on 3 and 2342 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nMost of the outputs here concern statistical inference. We can interpret the result of statistical inference for a linear regression model from this output of the summary() function, which may be considered as a default option to examine the linear regression result in R. I covered how we may interpret the result from this table in my lecture. Here I will introduce another function, summ(), from a package called jtools.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistical Inference for Linear Regression</span>"
    ]
  },
  {
    "objectID": "linreg_inf.html#sec-estimate-lm",
    "href": "linreg_inf.html#sec-estimate-lm",
    "title": "8  Statistical Inference for Linear Regression",
    "section": "8.2 Estimate Linear Regression Models",
    "text": "8.2 Estimate Linear Regression Models\nFirst, let’s estimate a simple linear regression model of trudeau_therm_cps on percep_economy_cps_n.\n\n  lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\nWe can assign the result of the lm() function to a new object. For example, I assigned the above result to an object called model1 below.\n\n  model1 &lt;- lm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nThen, we can see the linear regression result stored in model1 by typing the name of this new object in the Console.\n\n  model1\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n  \n               8.128                18.982  \n\n\nLet’s assign the result of a multiple linear regression of trudeau_therm_cps on percep_economy_cps_n and ideology and union_d to a new object, named model2.\n\n  model2 &lt;- lm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + union_d, \n                      data = ces2019)\n\nAgain, we can access this result by typing model2 in the Console.\n\n  model2\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + \n    union_d, data = ces2019)\n\nCoefficients:\n         (Intercept)  percep_economy_cps_n              ideology  \n             24.7569               17.1926               -2.7193  \n         union_dTRUE  \n              0.8752  \n\n\nThere is more information in the result of the lm() function than what appears in the R console this way. We can access them, for example, by the summary() function. A basic syntax of the summary() function is to include the output of the lm() function as its argument (i.e., inside the parentheses).\n\n  summary(model2)\n\n\nCall:\nlm(formula = trudeau_therm_cps ~ percep_economy_cps_n + ideology + \n    union_d, data = ces2019)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-71.77 -20.63   0.86  19.87  85.24 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           24.7569     2.2629  10.940   &lt;2e-16 ***\npercep_economy_cps_n  17.1926     0.7728  22.248   &lt;2e-16 ***\nideology              -2.7193     0.2549 -10.668   &lt;2e-16 ***\nunion_dTRUE            0.8752     1.3498   0.648    0.517    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 26.59 on 2342 degrees of freedom\n  (1675 observations deleted due to missingness)\nMultiple R-squared:  0.2416,    Adjusted R-squared:  0.2407 \nF-statistic: 248.8 on 3 and 2342 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\nMost of the outputs here concern statistical inference. We can interpret the result of statistical inference for a linear regression model from this output of the summary() function, which may be considered as a default option to examine the linear regression result in R. I covered how we may interpret the result from this table in my lecture. Here I will introduce another function, summ(), from a package called jtools.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistical Inference for Linear Regression</span>"
    ]
  },
  {
    "objectID": "subsig.html",
    "href": "subsig.html",
    "title": "9  Substantive Significance",
    "section": "",
    "text": "9.1 Preparation",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#basic-idea",
    "href": "subsig.html#basic-idea",
    "title": "9  Substantive Significance",
    "section": "10.1 Basic Idea",
    "text": "10.1 Basic Idea\nWhen we have a certain substantive/theoretical expectation for the relationship of two variables (controlling for other variables) in the population, the first step to examine this expectation is to see whether we have a point estimate of the coefficient of a variable of our interest in the expected direction (i.e., positive or negative) and what range of values its confidence interval encompasses. If the confidence interval does not include zero, we may say that the coefficient of our interest is statistically distinguishable from zero, or more simply, statistically significant. We have seen how to produce the results for these analyses in R in the previous Week 10 R Lab Session.\nThe second step is to examine whether the relationship found is . The relationship may be substantively important/significant if the magnitude of the estimated relationship is meaningfully large in a particular context.. There is . In general, you need to make an argument based on the particular nature of the relationship of your interest and the findings in your empirical research.\nThere may be many different ways to make such an argument, but for the final paper in this class, I’d suggest you estimate the change in the expected value of the dependent variable (= compute the difference in the fitted/predicted values \\(\\widehat{E(Y|X)}\\) or \\(\\widehat{Y}\\)) given a meaningful change in the independent variable of your interest based on the results of your linear regression analysis. For example, suppose we want to evaluate the substantive magnitude of the relationship between trudeau_therm_cps and percep_econ_cps_n controlling for other variables based on the multiple linear regression estimated above. In this case, we may estimate the difference in the conditional expectations (\\(E(Y|X)\\)) of trudeau_therm_cps between the individuals who perceived that the state of national economy had gotten better and those who perceived that it had gotten worse, holding all other variables constant. Then, we may offer an argument about whether this difference is meaningfully large in the particular context of this question.\nWhen we do this computation, we should also derive a confidence interval for the change in \\(E(Y|X)\\) according to a meaningful change in the independent variable. In the above example, we would derive the confidence interval for the difference in the conditional expectations of trudeau_therm_cps between the individuals who perceived that the state of economy had gotten better and those who perceived that it had gotten worse. Then, we will reflect the result of the confidence interval in our argument about whether the relationship found is substantively significant.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#estimation-by-the-emmeans-package",
    "href": "subsig.html#estimation-by-the-emmeans-package",
    "title": "9  Substantive Significance",
    "section": "10.2 Estimation by the emmeans() Package",
    "text": "10.2 Estimation by the emmeans() Package\nTo recap, what we are going to estimate is the difference in the conditional expectations/means of the dependent variable , which I describe here as “the difference (or change) in \\(E(Y|X)\\).” This is the difference in the values of the dependent variable along a linear regression line . Also, this “difference (or change) in \\(E(Y|X)\\)” is the population parameter of our interest in the present context.\nThen, we estimate the difference in \\(E(Y|X)\\) in the population using the difference in \\(\\widehat{E(Y|X)}\\) or \\(\\widehat{Y}\\), which is the difference in the predicted/fitted values computed from our sample linear regression model or the difference in the values of the dependent variable along a linear regression line . In other words, the difference in the predicted/fitted values, \\(\\widehat{E(Y|X)}\\) or \\(\\widehat{Y}\\), is our estimator or estimate for the difference in \\(E(Y|X)\\) in the population.\nThroughout this Lab Session document, I will use “the difference (or change) in \\(E(Y|X)\\) (or the conditional expectation/mean)” to refer to our population parameter and “the difference (or change) in \\(\\widehat{E(Y|X)}\\)” to refer to our estimator or estimate. For example, I may say that “we estimate the difference in \\(E(Y|X)\\),” “we estimate the change in the conditional expectation/mean of Y in the population,” and “we compute the difference in \\(\\widehat{E(Y|X)}\\) from our sample.”\nTo estimate the difference in \\(E(Y|X)\\) and derive its confidence interval, we will use the emmeans() function and the contrast() function from the emmeans package.\nFirst, install the emmeans package.\n\n  install.packages(\"emmeans\")\n\nThen, load this package.\n\n  library(emmeans)\n\n\nOur analysis is in two steps. In the first step, we will use the emmeans() function to estimate \\(E(Y|X)\\) for different values of the independent variable of our interest, controlling for other variables. In the second step, we will supply the result of the emmeans() function to the contrast() function to conduct statistical inference for the difference in \\(E(Y|X)\\) between different values of the independent variable.\nI will explain each step in turn in the following two sections.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#statistical-inference-for-eyx-emmeans",
    "href": "subsig.html#statistical-inference-for-eyx-emmeans",
    "title": "9  Substantive Significance",
    "section": "10.3 Statistical Inference for \\(E(Y|X)\\): emmeans()",
    "text": "10.3 Statistical Inference for \\(E(Y|X)\\): emmeans()\nFor the first step to estimate \\(E(Y|X)\\) for different values of the independent variable of our interest, we use the emmeans() function. For our purpose here, we use at least three arguments for the emmeans() function. The first argument (object) is the outcome of the lm() function, the second argument (spec) is an independent variable for which we want to specify multiple values and compare \\(E(Y|X)\\) across them, and the third argument (at) is the values at which we want to specify the independent variable of our interest.\nThe following code will estimate \\(E(Y|X)\\) when percep_economy_cps_n = 1, ideology = 5, union_d = FALSE, and province = AB.\n\n  emmeans( object = model, # The first argument is the output from the lm() function.\n           \n           specs = \"percep_economy_cps_n\",  # The second argument is the independent \n                                            # variable of our interest.\n           \n              # In the third argument, we specify the values at which we want to hold \n              # the independent variables. We may nclude the equations for all independent  \n              # variables within the list() function on the right-hand side of this argument.\n           at = list(percep_economy_cps_n = 1, \n                     ideology = 5, union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n\nConfidence level used: 0.95 \n\n\nIn the output above, you can see the point estimate of \\(E(Y|X)\\) under emmean, its standard error under SE, the lower end of the 95% confidence interval for \\(E(Y|X)\\) under lower.CL, and the upper end under upper.CL. According to this result, the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1, ideology = 5, union_d = FALSE, and province = AB is estimated as 17.8, and its 95% confidence interval is [13.8, 21.8].\nIn the second argument (specs), we specified percep_economy_cps_n as the variable for which we want to estimate \\(E(Y|X)\\) at different values. If we specify multiple values for percep_economy_cps_n in the third argument (at), then the emmeans() function will estimate multiple \\(E(Y|X)\\) corresponding to each of the values specified for percep_economy_cps_n.\nBelow I specified three values — 1, 2 and 3 — for percep_economy_cps_n.\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # In the third argument, we specify three values --- 1, 2 and 3 --- for \n              # percep_economy_cps_n.\n           at = list(percep_economy_cps_n = c(1,2,3), \n                     ideology = 5, union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n                    2   33.6 2.05 2333     29.6     37.6\n                    3   49.4 2.33 2333     44.8     54.0\n\nConfidence level used: 0.95 \n\n\nThen, the emmeans() function estimated three conditional expectations of trudeau_therm_cps for each value specified for percep_economy_cps_n holding other variables at ideology = 5, union_d = FALSE, and province = AB. Specifically, the conditional expectation of trudeau_therm_cps is 17.8 when percep_economy_cps_n = 1, 33.6 when percep_economy_cps_n = 2, and 49.4 when percep_economy_cps_n = 3, holding other variables at the specified values.\nNote that the emmeans() function estimates \\(E(Y|X)\\) for each of the specified values only for the variable specified in the specs argument. For example, the code below lists multiple values for ideology in the at argument while percep_economy_cps_n is still suggested in the specs argument. This code does not produce multiple \\(E(Y|X)\\) for each of the specified values for ideology.\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # Now we specify the values from 0 to 10 for \"ideology,\"\n              # but the specs argument is still \"percep_economy_cps_n.\"\n           at = list(percep_economy_cps_n = 1, \n                     ideology = c(0:10), union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n\nResults are averaged over the levels of: ideology \nConfidence level used: 0.95 \n\n\nThe above command estimated only one \\(E(Y|X)\\). There is also the message that “Results are averaged over the levels of: ideology”. What this means is that the emmeans() function first estimated multiple \\(E(Y|X)\\) for each of the specified values from 0 to 10 of ideology with other variables fixed at the specified values and then took the average of \\(E(Y|X)\\) across all the values of ideology from 0 to 10. If we want to estimate \\(E(Y|X)\\) for each of these values of ideology separately, we should specify ideology in the specs function as in the code below.\n\n  emmeans( object = model, \n           specs = \"ideology\",  \n              # The specs argument is now changed to \"ideology.\"\n           \n           at = list(percep_economy_cps_n = 1, \n                     ideology = c(0:10), union_d = FALSE, province = \"AB\") )\n\n ideology emmean   SE   df lower.CL upper.CL\n        0  31.10 2.54 2333   26.113    36.09\n        1  28.44 2.40 2333   23.733    33.14\n        2  25.78 2.27 2333   21.316    30.23\n        3  23.11 2.17 2333   18.856    27.37\n        4  20.45 2.09 2333   16.346    24.55\n        5  17.79 2.04 2333   13.779    21.80\n        6  15.12 2.03 2333   11.153    19.10\n        7  12.46 2.04 2333    8.466    16.46\n        8   9.80 2.08 2333    5.718    13.88\n        9   7.14 2.15 2333    2.914    11.36\n       10   4.47 2.25 2333    0.058     8.89\n\nConfidence level used: 0.95 \n\n\nNow the emmeans() function returned the estimation of \\(E(Y|X)\\) for all the specified values of ideology, respectively, from 31.10 when ideology = 0 to 4.47 when ideology = 10 holding the other values constant at the specified values.\nSo far, we have specified the values for all variables included in our linear regression model. For our purposes, however, it suffices to specify the values just for the independent variable of our interest. This is because what we are interested in is in \\(E(Y|X)\\) across different values of our independent variable holding other control variables constant. For this purpose, which values we hold control variables at do not matter. If the values of control variables are not specified, the emmeans() function will use default values (= means) for these variables. In the code below, I specified the values for percep_economy_cps_n only.\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # Now we specify the values for percep_economy_cps_n only.\n           at = list( percep_economy_cps_n = c(1,2,3) )  )\n\n percep_economy_cps_n emmean    SE   df lower.CL upper.CL\n                    1   29.6 1.020 2333     27.6     31.6\n                    2   45.5 0.755 2333     44.0     46.9\n                    3   61.3 1.160 2333     59.0     63.6\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated conditional expectations of trudeau_therm_cps for each value of percep_economy_cps_n in this output are different from those reported before. This is because the values of other control variables are held at different values. More specifically, without the values specified in the at argument, the values of the other variables are held at their means, if the variables are numeric. In the current example, as ideology is a numeric variable, its value is held at its mean. For factor or logical variables, \\(E(Y|X)\\) is first computed for each category of these variables and the average of \\(E(Y|X)\\) is computed across all these categories. Therefore, there is a message in the above output that says “Results are averaged over the levels of: union_d, province.”\nBecause what values we hold control variables constant at do not matter when we take in \\(E(Y|X)\\) by the contrast() function introduced in the next section, we will specify the values only for the independent variable of our interest in the at argument of the emmeans() function for the rest of the current Lab Session.\nUsing the emmeans() function as suggested above, we can estimate \\(E(Y|X)\\) for different values of the independent variable of our interest, holding other variables constant.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#statistical-inference-for-difference-in-eyx-contrast",
    "href": "subsig.html#statistical-inference-for-difference-in-eyx-contrast",
    "title": "9  Substantive Significance",
    "section": "10.4 Statistical Inference for Difference in E(Y|X): contrast()",
    "text": "10.4 Statistical Inference for Difference in E(Y|X): contrast()\nIn the second step, we will supply the result of the emmeans() function to the contrast() function to estimate the difference in \\(E(Y|X)\\) between different values of the independent variable of interest.\nLet’s estimate the difference in the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1 (the respondent’s perception of economy is “Worse”) and when percep_economy_cps_n = 3 (the respondent’s perception of economy is “Better”).\nRecall that we can estimate \\(E(Y|X)\\) for each of these two values of percep_economy_cps_n as below. Note that now I use the pipe operator (|&gt;) in the code below.\n\n  model |&gt;  \n        # \"model\" will be piped to the emmeans() function as its first argument.\n  \n      emmeans( specs = \"percep_economy_cps_n\",  \n               \n               # We now specify two values --- 1 and 3 --- only for percep_economy_cps_n \n               # in the at argument.\n               at = list( percep_economy_cps_n = c(1,3) ) )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   29.6 1.02 2333     27.6     31.6\n                    3   61.3 1.16 2333     59.0     63.6\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nWe supply this output to the contrast() function to take the difference. We set the method argument of the contrast() function to “pairwise”, so that the contrast() function will estimate a pairwise difference in \\(E(Y|X)\\) between the values of the independent variable specified in the emmeans() function.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n        # The output from the emmeans() function is piped to the contrast() function.\n\n        # The method argument is set to \"pairwise\".\n      contrast( method = \"pairwise\")\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n1 - percep_economy_cps_n3    -31.6 1.58 2333 -19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nIn the above output, contrast lists a pairwise comparison of the values of the independent variable we specified (= percep_economy_cps_n in the current example). Under contrast, we can see 1 - 3, which means that what was estimated here was the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1 minus the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 3. This is the expected change in trudeau_therm_cps when the percep_economy_cps variable changes from “Better” to “Worse”. Because the change in percep_economy_cps considered here corresponds to a two-unit of the value of percep_economy_cps_n and the coefficient estimate on percep_economy_cps_n is positive (15.8163), the expected difference in trudeau_therm_cps here is negative (\\((-2) \\times 15.8 = -31.6\\)). This is perhaps counter intuitive, because the estimated relationship between trudeu_therm_cps and percep_economy_cps_n is positive.\nThe problem here is that the pairwise difference computed was 1 - 3 in terms of the values of percep_economy_cps_n. What we want instead is a pairwise difference of 3 - 1. That is, we want to reverse the order of these values. We can correct this in two ways. First, we may reverse the order of the values specified for percep_economy_cps_n in the at argument in the emmeans() function as in the following code.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(3,1) ) ) |&gt; \n                         # Now the values are specified as c(3,1) instead of c(1,3).               \n  \n      contrast( method = \"pairwise\")\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333  19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nSecond, we may keep the original order of the values for percep_economy_cps_n in the emmeans() function, but change the method argument to \"revpairwise\" in the conrast() function. revpairwise stands for a reversed pairwise comparison. As its name suggests, if we use revpairwise, the contrast() function reverses the order of a pairwise comparison.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list(percep_economy_cps_n = c(1,3) ) ) |&gt; \n                         # Now the original order of the values --- c(1,3) --- is kept.               \n  \n        # The method argument is changed to \"revpairwise\".  \n      contrast( method = \"revpairwise\")\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333  19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nEither way, now we can get the difference we want — the change in the conditional expectation of trudeau_therm_cps when percep_economy_cps_n changes from 1 to 3 (\\(2 \\times 15.8 = 31.6\\)).\nIn the above outputs, what follows after contrast and estimate are a few statistics for statistical inference about the estimated difference in \\(E(Y|X)\\), such as its standard error (SE) and p-value (p.value). We can also derive the confidence interval for the difference in the conditional expectation of trudeau_therm_cps by specifying the infer argument to TRUE in the contrast() function as in the code below.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n  \n        # Now we add \"infer = TRUE\" in the contrast() function.\n      contrast( method = \"revpairwise\", infer = TRUE )\n\n contrast                                      estimate   SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333     28.5\n upper.CL t.ratio p.value\n     34.7  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nIn the output above, lower.CL indicates the lower end of the 95% confidence interval for the difference and upper.CL the upper end. According to this result, the 95% confidence interval for the difference in the conditional expectation of trudeau_therm_cps between those who perceived that the national economy had gotten better and those who perceived that it had gotten worse, controlling for the other variables included in the model, is [28.5, 34.7].\nWe can also change the confidence level by specifying the number between 0 and 1 in the level argument in the contrast() function. For example, if we specify level = 0.99 as in the code below, the contrast() function produces the 99% confidence interval for the difference in \\(E(Y|X)\\).\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n  \n        # Now we add the level argument in the contrast() function.  \n      contrast( method = \"revpairwise\", infer = TRUE, level = 0.99 )\n\n contrast                                      estimate   SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333     27.5\n upper.CL t.ratio p.value\n     35.7  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.99 \n\n\nIn addition, we can also change the number of digits to appear. For this purpose, as in the code below, we need to use the summary() function and the print() function, consecutively, and we specify the number of digits we want in the print() function.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n      contrast( method = \"revpairwise\", infer = TRUE, level = 0.99 ) |&gt; \n  \n            # The output from the contrast() function is piped to the summary() function.\n      summary() |&gt; \n  \n            # Then, the output from the summary() function is piped further to the print() \n            # function, in which we can specify the number of digits to appear \n            # in the output on the R Console.\n      print( digits = 6 )\n\n contrast                                      estimate      SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1  31.6327 1.58427 2333  27.5485\n upper.CL t.ratio p.value\n  35.7168  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.99",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#making-argument-for-substantive-significance",
    "href": "subsig.html#making-argument-for-substantive-significance",
    "title": "9  Substantive Significance",
    "section": "10.5 Making Argument for Substantive Significance",
    "text": "10.5 Making Argument for Substantive Significance\nI suggested before that you should estimate the difference in \\(E(Y|X)\\) corresponding to a meaningful amount of change in the independent variable of your interest. You should carefully consider what would be a meaningful change in your independent variable. Note that there are to determine what a meaningful amount of change would be. Instead, this is something you need to carefully consider and make a reasonable argument. To think about what a meaningful amount of change would be for your independent variable, it is advisable to explore the distribution of this variable carefully by using visualization and/or its summary statistics.\nAs an example, I draw a bar chart for percep_economy_cps below. As you can see, although about a half of the responses are concentrated on “Same,” the responses are reasonably spread across all three categories from “Worse” to “Better.” More specifically, there are about 2,300 observations, of which approximately one third of the responses are “Worse” and a quarter are “Better”. This distribution of the responses may justify that the change from “Worse” to “Better” would be a meaningful change in percep_economy_cps in this sample, because there are reasonable fractions of observations in all these categories.\n\n\n\n\n\n\n\n\n\nIf most of the observations were concentrated on two consecutive categories, say “Worse” and “Same”, and only a tiny fraction of responses were in the last category, “Better”, as in a hypothetical bar chart below, then the change from “Worse” to “Better” might not have been justified as a meaningful change in percep_economy_cps in this hypothetical sample. In this case, a meaningful change may be from “Worse” to “Same” because this change encompasses most of the observations. The estimated change in the conditional expectations of trudeau_therm_cps corresponding to this change in percep_economy_cps is available immediately from the coefficient of percep_economy_cps_n as this is only a one-unit increase in percep_economy_cps_n.\n\n\n\n\n\n\n\n\n\nOnce you have determined the meaningful amount of change in the independent variable of your interest, you can estimate the difference in \\(E(Y|X)\\) by the emmeans() and contrast() functions, as discussed in the previous section. After that, you need to offer your argument about whether this estimated amount of change in \\(E(Y|X)\\) is of substantively meaningful magnitude. The example above is relatively simple for this purpose because the estimated change in trudeau_therm_cps corresponding to the change in percep_economy from “Worse” to “Better” is \\(31.6\\), which is one-third — a large proportion — of the entire range of trudeau_therm_cps.\nWhen you evaluate the estimated difference in \\(E(Y|X)\\) with respect to a meaningful change in your independent variable, make sure you consider the entire range of its confidence interval. In the example above, the 99% confidence interval is [28.5, 34.7]. Even when we consider the lower end or the upper end of this interval, our conclusion will not change because either one is still about one-third of the entire range of trudeau_therm_cps. If the range of interval is so large that the conclusion may be different depending on whether we consider the point estimate, the lower end of the interval, or the upper end, then we should reflect this difference in our discussion. For example, if the confidence interval for the estimated change in trudeau_therm_cps corresponding to the change in percep_economy from “Worse” to “Better” were hypothetically [5.5, 57.7], then this expected change in trudeau_therm_cps may be as large as more than a half of the entire range (57.5) or as small as one twentieth of the entire range (5.5). Our discussion should reflect this inconclusiveness of the estimated magnitude.\nIn the above example, I compared the estimated difference in \\(E(Y|X)\\) with the entire range of the dependent variable, trudeau_therm_cps. Alternatively, you may compare the estimated difference in \\(E(Y|X)\\) with the IQR or the standard deviation of the dependent variable. If you use the IQR, then you compare the estimated difference in \\(E(Y|X)\\) with the amount of variation in \\(Y\\) in the middle half of your sample. If you use the standard deviation, then you compare it with a typical amount of deviation in the value of Y from the mean in your sample. You may also draw a histogram of your dependent variable and identify a meaningful range of values from the distribution. It is of course fine if you can offer a reasonable discussion on the substantive magnitude of the difference in \\(E(Y|X)\\) without reference to a certain empirical range of the dependent variable. Again, there are to determine whether the estimated change in \\(E(Y|X)\\) is of substantive magnitude. Your creativity, logical and sensible reasoning, and convincing argumentation are called for.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#ordinal-categorical-variable",
    "href": "subsig.html#ordinal-categorical-variable",
    "title": "9  Substantive Significance",
    "section": "11.1 Ordinal Categorical Variable",
    "text": "11.1 Ordinal Categorical Variable\n\n11.1.1 Numeric Version\nAn independent variable in the example in the previous section (percep_economy_cps_n) was a numeric version of an ordinal categorical variable. Therefore, if the independent variable of your interest is a numeric version of an ordinal categorical variable, then you may consider a meaningful change of this type of variable as we did in the previous section.\n\n\n11.1.2 Dummified Version\nIf the independent variable of your interest is dummified for all categories except for one (i.e., a factor version of an ordinal categorical variable is included in the right-hand side of the linear regression model in R), you may consider it in a similar way to the example given below in the section on a nominal categorical variable (Section 3.4).",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#quantitative-variable-numeric",
    "href": "subsig.html#quantitative-variable-numeric",
    "title": "9  Substantive Significance",
    "section": "11.2 Quantitative Variable (numeric)",
    "text": "11.2 Quantitative Variable (numeric)\nNow consider the difference in the conditional expectation of trudeau_therm_cps for a meaningful change in ideology controlling for other variables in the model estimated above. ideology is a quantitative variable.\n\n11.2.1 Entire Range\nOne idea is to estimate the difference in \\(E(Y|X)\\) between the minimum and maximum values of ideology as we did for percep_economy_cps_n. As the minimum value of ideology is 0 (most leftist/liberal position), and the maximum is 10 (most rightist/conservative position), let’s specify these values for ideology in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(10, 0) ) ) |&gt;\n                # We specified the maximum and minimum values of ideology.\n  \n  contrast( method = \"pairwise\", infer = TRUE )\n\n contrast               estimate   SE   df lower.CL upper.CL t.ratio p.value\n ideology10 - ideology0    -26.6 2.52 2333    -31.6    -21.7 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional mean of trudeau_therm_cps between the most conservative respondents (ideology = 10) and the most liberal respondents (ideology = 0), controlling for all other variables included in the model, is \\(-26.6\\) and its 95% confidence interval is [-31.6, -21.7].\nAs discussed before, we should carefully consider what a meaningful amount of change of ideology would be. For this purpose, let’s draw a bar chart of ideology below .\n\n\n\n\n\n\n\n\n\nAccording to this bar chart, the respondents are spread across the entire range of ideology from the most leftist position (ideology = 0) to the most rightist position (ideology = 10). This observation may be used to justify the comparison of the conditional expectation of trudeau_therm_cps between the maximum and minimum values of ideology.\n\n\n11.2.2 IQR\nHowever, the bar chart also indicates that there are only a very small number of respondents in the extreme ideological positions, such as 0, 1, 9 and 10. We may want to use an alternative amount of change in ideology, which do not include these extreme ideological positions. For example, we may want to use the IQR of ideology, which represents the extent of variation in the values of ideology in the middle half of the sample. IQR of ideology may be computed by the IQR() function.\n\n  IQR(my_data$ideology, na.rm = TRUE)\n\n[1] 3\n\n\nFor our purpose, however, we need the values of both lower and upper quartiles because we need to specify these values for ideology in the at function of the emmeans() function. We can find the lower and upper quartiles of a variable by applying the summary() function to the variable.\n\n  summary(my_data$ideology)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   4.000   5.000   5.061   7.000  10.000 \n\n\nAccording to the above result, the lower quartile of ideology is 4 and the upper quartile is 7. Let’s specify these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7, 4) ) ) |&gt; \n                # We specified the upper and lower quartiles of ideology.  \n  \n  contrast( method = \"pairwise\", infer = TRUE )\n\n contrast              estimate    SE   df lower.CL upper.CL t.ratio p.value\n ideology7 - ideology4    -7.99 0.757 2333    -9.47     -6.5 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional expectation of trudeau_therm_cps between the respondents with the upper quartile in ideology and those with the lower quartile is \\(-7.99\\) and its 95% confidence interval is [ -9.47, -6.5].\n\n\n11.2.3 One Standard Deviation Above and Below the Mean\nAlternatively, we may want to use the standard deviation of ideology as a meaningful amount of change in this variable. We may use the sd() function to compute the standard deviation of a variable.\n\n  sd(my_data$ideology)\n\n[1] 2.21214\n\n\nAs the standard deviation represents a typical amount of deviation from the mean of a variable, we may consider the variation in ideology from one standard deviation below its mean to one standard deviation above its mean. The mean of ideology was reported above as \\(5.06\\) when we applied the summary() function to ideology. Given that the standard deviation of ideology reported above is \\(2.21\\), the range between one standard deviation below its mean (\\(5.06 - 2.21 = 2.85\\)) and one standard deviation above its mean (\\(5.06 + 2.21 = 7.27\\)) is \\(2.85\\) and \\(7.27\\). Let’s specify these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7.27, 2.85) ) ) |&gt; \n                # We specified one standard deviation above the mean \n                # and one standard deviation below the mean of ideology.  \n\n  contrast( method = \"pairwise\", infer = TRUE ) |&gt;       \n  summary() |&gt; \n  print( digits = 4 )\n\n contrast                    estimate    SE   df lower.CL upper.CL t.ratio\n ideology7.27 - ideology2.85   -11.77 1.116 2333   -13.96   -9.581 -10.549\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional mean of trudeau_therm_cps between the respondents with one standard deviation above the mean in ideology and those with one standard deviation below the mean is \\(-11.77\\) and its 95% confidence interval is [-13.96, -9.58].\nNote that ideology is a variable which takes only integer values. It may not make sense to consider the values such as \\(7.27\\) and \\(2.85\\) as ideology never takes these values. In this case, it may be more appropriate to use other types of range discussed in the sections above and below.\nIf the independent variable of interest is , then the use of standard deviation makes more sense, as decimals naturally appear in such a variable.\nHere we considered of the independent variable, because we use the variation from one standard deviation below the mean to one standard deviation above the mean. Instead, we may also consider — e.g., the variation from the mean to one standard deviation above the mean. This amount of change is considered in my lecture when the substantive significance of economic voting in the U.S. presidential elections is discussed based on the national-level aggregate data.\n\n\n11.2.4 From Visual Inspection\nAnother alternative may be the range chosen from a visual inspection of the distribution of a variable. In the bar chart drawn above, we can see that the values of ideology in the medium range from 3 to 7, except for the middle point of 5, have a relatively similar number of respondents, which is almost twice the number of the scores right next to this range, 2 and 8. In other words, this medium range of 3 to 7 seems to stand out from the rest as the most popular range of left-right ideology. This observation may be used to justify the use of the difference in conditional expectation of trudeau_therm_cps in this range of ideology. In the code below, I used these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7, 3) ) ) |&gt; \n                # I derived these values from a visual inspection of\n                # the bar chart of \"ideology\" drawn above.\n\n  contrast( method = \"pairwise\", infer = TRUE ) |&gt;       \n  summary() |&gt; \n  print( digits = 4 )\n\n contrast              estimate   SE   df lower.CL upper.CL t.ratio p.value\n ideology7 - ideology3   -10.65 1.01 2333   -12.63   -8.671 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional expectation of trudeau_therm_cps in this visually identified middle range of ideology is \\(-10.65\\) and its 95% confidence interval is [-12.63, -8.67].\nAgain, there are to determine which one of the above ranges is most appropriate for ideology. You need to offer a reasonable and convincing justification on why you use a particular range. I would perhaps not use the mean plus/minus one standard deviation for ideology because ideology is discrete and never takes decimals. While the entire range of ideology is informative and legitimate in its own right, I would not rely solely on this range because the respondents with extreme values of ideology are very small in number. I would perhaps supplement the result with the entire range of ideology by the result with either the IQR of ideology or the range identified from a visual inspection.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#dummy-variable-logical",
    "href": "subsig.html#dummy-variable-logical",
    "title": "9  Substantive Significance",
    "section": "11.3 Dummy Variable (logical)",
    "text": "11.3 Dummy Variable (logical)\nFor a dummy independent variable, the difference in \\(E(Y|X)\\) when it is 1 and when it is 0 is an appropriate meaningful range of change because it doesn’t take any other values. Its estimate and confidence interval can be found immediately from the coefficient on the dummy independent variable reported in the output from the summ() function.\nIn the output of the multiple linear regression model estimated above, the coefficient estimate of union_d is 0.60 and its 95% confidence interval is [-2.03, 3.21]. Therefore, the point estimate of the difference in the conditional expectations of trudeau_therm_cps between those who belong to the unions and those who don’t, holding other variables in the model constant, is 0.60 and its 95% confidence interval is [-2.03, 3.21].\nSince this interval includes zero, this is an inconclusive evidence about whether there is any relationship between trudeau_therm_cps and union_d controlling for other variables. While it is inconclusive whether there is any positive or negative relationship, we can still say from this estimation result that if there is either a positive or negative relationship between them, it is likely to be small, because the lowest end of the 95% confidence interval is only \\(-2.03\\) and the highest end is only \\(3.21\\). Given that the range of trudeau_therm_cps is between 0 and 100 and the responses are spread over the entire range of this variable, these numbers (\\(-2.03\\) and \\(3.21\\)) seem to indicate a very small magnitude of the difference between uion members and non-members.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#nominal-categorical-variable-factor",
    "href": "subsig.html#nominal-categorical-variable-factor",
    "title": "9  Substantive Significance",
    "section": "11.4 Nominal Categorical Variable (factor)",
    "text": "11.4 Nominal Categorical Variable (factor)\nIf the independent variable of interest is a nominal categorical variable, the variable should be dummified on the right-hand side of a linear regression model. Review the Week 9 R Lab Session and Tutorial 8 Exercise for detail. For a nominal independent variable, a meaningful amount of change in the independent variable is some substantively/theoretically meaningful comparison of the categories in this independent variable.\nConsider province included in the multiple linear regression estimated above. As we saw in the previous Lab Sessions, the coefficient on each dummified variable represents the difference in \\(E(Y|X)\\) of the dummified category from \\(E(Y|X)\\) of the reference category, controlling for other variables included in the model. If a meaningful comparison of the categories is between a certain category with the reference category, the coefficient on the dummy variable for this category is the difference in \\(E(Y|X)\\) that we need. If a meaningful comparison of the categories is between certain categories other than the reference category, we need to estimate the difference in \\(E(Y|X)\\) between these categories.\nSuppose we posit that a meaningful comparison is between Ontario and Saskatchewan. Then, we should specify these categories in the at argument in the emmeans() function as below.\n\n  model |&gt;   \n      emmeans( specs = \"province\",  \n               at = list( province = c(\"ON\",\"SK\") ) ) |&gt; \n              # Comparison is between \"ON\" and \"SK.\"\n  \n      contrast( method = \"pairwise\", infer = TRUE ) |&gt; \n      summary() |&gt; \n      print( digits = 4 )\n\n contrast estimate   SE   df lower.CL upper.CL t.ratio p.value\n ON - SK      11.9 2.45 2333    7.092     16.7   4.855  &lt;.0001\n\nResults are averaged over the levels of: union_d \nConfidence level used: 0.95 \n\n\nAccording to this result, the estimated difference in the conditional expectation of trudeau_therm_cps between Ontario and Saskatchewan is \\(11.90\\) and its 95% confidence interval is [7.09, 16.70].\nAlternatively, suppose we posit that a meaningful comparison is between Ontario and Alberta. We can specify these categories in the at argument in the emmeans() function as below; however, because Alberta is the reference category of province, the result should be the same as the coefficient estimate on provinceON in the multiple linear regression output reported above.\n\n  model |&gt;   \n      emmeans( specs = \"province\",  \n               at = list( province = c(\"ON\",\"AB\") ) ) |&gt; \n      contrast( method = \"pairwise\", infer = TRUE ) |&gt; \n      summary() |&gt; \n      print( digits = 4 )\n\n contrast estimate    SE   df lower.CL upper.CL t.ratio p.value\n ON - AB     15.34 2.366 2333     10.7    19.98   6.483  &lt;.0001\n\nResults are averaged over the levels of: union_d \nConfidence level used: 0.95 \n\n\nAccording to this result, the estimated difference in the conditional expectation of trudeau_therm_cps between Ontario and Alberta is \\(15.34\\) and its 95% confidence interval is [10.70, 19.98], which is the same as the coefficient estimate on provinceON reported before.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#preparation",
    "href": "subsig.html#preparation",
    "title": "9  Substantive Significance",
    "section": "",
    "text": "9.1.1 Prepare Variables\nAs in the previous chapters, create percep_economy_cps_n, which is a numeric version of percep_economy_cps, and union_d, a logical version of union.\n\n  ces2019 &lt;- ces2019 |&gt; \n      mutate(percep_economy_cps = fct_relevel(percep_economy_cps, \n              \"(2) Worse\", \"(3) About the same\", \"(1) Better\") ) |&gt; \n      mutate(percep_economy_cps = fct_recode(percep_economy_cps, \n                                \"Worse\" = \"(2) Worse\", \n                                \"Same\" = \"(3) About the same\", \n                                \"Better\" = \"(1) Better\") ) |&gt; \n      mutate(percep_economy_cps_n = as.numeric(percep_economy_cps))\n\n\n  ces2019 &lt;-  ces2019 |&gt; # Change the name of categories of union to TRUE and FALSE.\n      mutate( union_d = fct_recode(union, \"TRUE\" = \"(1) Yes\", \"FALSE\" = \"(2) No\") ) |&gt; \n      mutate( union_d = as.logical(union_d) )  # Then, apply the as.logical() function.\n\n\n\n9.1.2 Prepare New Data Frame\nAlso construct a new data frame which includes non-missing observations for the variables used in the example linear regression model in this chapter. These variables are trudeau_therm_cps, percep_economy_cps_n, percep_economy_cps, ideology, union_d, and province. The new data frame is named my_data in the code below.\n\n  my_data &lt;- ces2019 |&gt; \n      drop_na( trudeau_therm_cps, percep_economy_cps_n, percep_economy_cps, \n               ideology, union_d, province )\n\n\n\n9.1.3 Estimate Example Model\nAs a primary example, I will use a multiple linear regression of trudeau_therm_cps on percep_economy_cps_n, ideology, union_d and province. Let’s estimate this model and assign it to a new object, named model.\n\n  model &lt;- lm(formula = trudeau_therm_cps ~ percep_economy_cps_n\n                                              + ideology + union_d + province, \n                      data = my_data)\n\nNote that the model includes four different types of independent variables:\n\na numeric version of an ordinal categorical variable (percep_economy_cps_n),\na quantitative variable (ideology),\na dummy variable stored as a logical (union_d), and\na nominal categorical variable stored as a factor (province).\n\nI will discuss how we can evaluate the substantive significance for each type of variable.\nLet’s take a look at the estimation result by the summ() function from the jtools package.\n\n  summ(model, confint = TRUE, digits = 4)\n\nMODEL INFO:\nObservations: 2346\nDependent Variable: trudeau_therm_cps\nType: OLS linear regression \n\nMODEL FIT:\nF(12,2333) = 69.7279, p = 0.0000\nR² = 0.2640\nAdj. R² = 0.2602 \n\nStandard errors:OLS\n----------------------------------------------------------------------------\n                                Est.      2.5%     97.5%     t val.        p\n-------------------------- --------- --------- --------- ---------- --------\n(Intercept)                  15.2848    9.7034   20.8662     5.3702   0.0000\npercep_economy_cps_n         15.8163   14.2630   17.3697    19.9667   0.0000\nideology                     -2.6628   -3.1577   -2.1678   -10.5489   0.0000\nunion_dTRUE                   0.5959   -2.0253    3.2171     0.4458   0.6558\nprovinceBC                   11.7557    7.1483   16.3631     5.0034   0.0000\nprovinceMB                   10.8040    5.1630   16.4450     3.7558   0.0002\nprovinceNB                   16.9362   10.7094   23.1630     5.3336   0.0000\nprovinceNL                   18.4670   12.1214   24.8126     5.7068   0.0000\nprovinceNS                   12.1679    5.9590   18.3769     3.8430   0.0001\nprovinceON                   15.3387   10.6994   19.9780     6.4835   0.0000\nprovincePE                   15.8607    9.6777   22.0437     5.0303   0.0000\nprovinceQC                   12.3670    7.6228   17.1111     5.1118   0.0000\nprovinceSK                    3.4424   -2.2297    9.1144     1.1901   0.2341\n----------------------------------------------------------------------------\n\n\nThe linear regression table above shows the 95% confidence intervals for all coefficients. You can also read the statistical significance from the p-values at the right most column (p). If this number times 100 percent — (p \\(\\times\\) 100)% — is smaller than a certain significance level (e.g., 5%, 1%, 0.1%), then the coefficient with this p-value is statistically significant at this significance level.\nIf you want R to tell you which coefficient is statistically significant at the 5%, 1% or 0.1% significance level, you may use the summary() function. Or if you use the export_summs() function from the huxtable package, then you can see both confidence intervals and the signs for statistical significance together in a single table. Review Section 8.4 for detail.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#substantive-significance",
    "href": "subsig.html#substantive-significance",
    "title": "9  Substantive Significance",
    "section": "9.2 Substantive Significance",
    "text": "9.2 Substantive Significance\n\n9.2.1 Basic Idea\nWhen we have a certain substantive/theoretical expectation for the relationship of two variables in the population, the first step to examine this expectation is to see whether we have a point estimate of the coefficient of a variable of our interest in the expected direction (i.e., positive or negative) and what range of values its confidence interval encompasses. If the confidence interval does not include zero, we may say that the coefficient of our interest is statistically distinguishable from zero, or more simply, statistically significant.1 We have seen how to conduct these analyses in R in Chapter 8.\nThe second step is to examine whether the relationship found is substantively important or significant. The relationship may be substantively important/significant if the magnitude of the estimated relationship is meaningfully large in its specific context.2 There is no unique way to assess the substantive significance of the relationship. In general, you need to make an argument based on the specific nature of the relationship of your interest and the findings in your empirical research.\nThere may be many different ways to make such an argument, but for the final paper in this class, I suggest you estimate the change in the expected value of the dependent variable (\\(E(Y|X)\\)) corresponding to a meaningful change in the independent variable of your interest (\\(X\\)) based on the results of your linear regression analysis.\nThis is what I have suggested in my lecture. To recap, let me restate my suggestion below.\n\nIdentify a substantively meaningful amount of change in \\(X\\). Let’s say this is identified as the change from \\(X^*\\) to \\(X^{**}\\). Then, it may be denoted as (\\(\\Delta X = X^{**} - X^*\\)).\nEstimate the change in \\(E(Y|X)\\), the change in the conditional expectation/mean of Y, corresponding to this substantively meaningful change in \\(X\\). This change can be denoted by \\(E(Y|X^{**}) - E(Y|X^{*}) = \\beta \\times \\Delta X\\), where \\(\\beta\\) is the coefficient of \\(X\\).\nEstimate the confidence interval for this change in \\(E(Y|X)\\).\nDiscuss the substantive magnitude of the relationship between \\(Y\\) and \\(X\\) based on both the point estimate and confidence interval for this change in \\(E(Y|X)\\).\n\n\nAs you can see in the above figure, this change in \\(E(Y|X) = E(Y|X^{**}) - E(Y|X^{*})\\) is the difference in the values of the dependent variable along a linear regression line in the population. This “difference (or change) in \\(E(Y|X)\\)” is the population parameter of our interest in the present context.\nThen, we estimate the change in \\(E(Y|X)\\) in the population using the difference in \\(\\widehat{Y}\\) or the difference in \\(\\widehat{E(Y|X)} = \\widehat{E(Y|X^{**})} - \\widehat{E(Y|X^{*})}\\), which is the difference in the predicted/fitted values computed from our sample linear regression model or the difference in the values of the dependent variable along a linear regression line in our sample. In other words, the difference in the predicted/fitted values, \\(\\widehat{E(Y|X)}\\) or \\(\\widehat{Y}\\), is our estimator or estimate for the difference in \\(E(Y|X)\\) in the population.\nThroughout this chapter, I will use “the difference (or change) in \\(E(Y|X)\\) (or the conditional expectation/mean)” and “\\(E(Y|X^{**}) - E(Y|X^{*})\\)” to refer to our population parameter\nSimilarly, I will use “the difference (or change) in \\(\\widehat{E(Y|X)}\\)” and “\\(\\widehat{E(Y|X^{**})} - \\widehat{E(Y|X^{*})}\\)” to refer to our estimator or estimate for the change in \\(E(Y|X)\\) in the population.\nNote that the discussion so far implicitly assumes that we have only one independent variable, \\(X\\), on the right hand side of a linear regression equation. However, we normally control for some other variables, which are collectively denoted by \\(Z\\) here. Therefore, the change in the conditional expectation of \\(Y\\) corresponding to the meaningful change in \\(X\\) is estimated holding all other variables \\(Z\\) constant at certain values, say \\(Z^+\\). Incorporating \\(Z^+\\), our population parameter can be denoted as “the difference (or change) in \\(E(Y|X,Z^+) = E(Y|X^{**},Z^+) - E(Y|X^{*},Z^+)\\)”.\nFor example, suppose we want to evaluate the substantive magnitude of the relationship between trudeau_therm_cps (\\(Y\\)) and percep_econ_cps_n (\\(X\\)) controlling for other variables (\\(Z\\)) based on the multiple linear regression estimated in Section 9.1.3. In this case, we first estimate the difference in the conditional expectations of trudeau_therm_cps (\\(E(Y|X,Z)\\)) between the individuals who perceived that the state of national economy had gotten better (\\(X = 3\\)) and those who perceived that it had gotten worse (\\(X = 1\\)), holding all other variables constant (\\(Z = Z^+\\)). In equation, the difference we estimate may be written as \\(E(Y | X = 3, Z^+) - E(Y | X = 1, Z^+)\\)\nWe should also derive the confidence interval for the difference in the conditional expectations of trudeau_therm_cps between the individuals who perceived that the state of economy had gotten better and those who perceived that it had gotten worse, holding other variables constant. Then, we will offer an argument about whether this difference in \\(E(Y|X,Z^+)\\) is meaningfully large in the particular context of this relationship based on its point estimate and confidence interval.\n\n\n9.2.2 Estimation by the emmeans() Package\nTo estimate the difference in \\(E(Y|X,Z^+)\\) and derive its confidence interval, we will use the emmeans() function and the contrast() function from the emmeans package.\nFirst, install the emmeans package (Section 1.4).\n\n  install.packages(\"emmeans\")\n\nThen, load this package.\n\n  library(emmeans)\n\n\nOur analysis is in two steps.\n\nIn the first step, we will use the emmeans() function to estimate \\(E(Y|X,Z^+)\\) for different values of \\(X\\), such as \\(X^*\\) and \\(X^{**}\\), holding other variables \\(Z\\) constant at \\(Z^+\\).\nIn the second step, we will supply the result of the emmeans() function to the contrast() function to conduct statistical inference for the difference in \\(E(Y|X,Z^+) = E(Y|X^{**},Z^+) - E(Y|X^{*},Z^+)\\).\n\nI will explain each step in turn in the following two sections.\n\n\n9.2.3 Estimate \\(E(Y|X,Z^+)\\): emmeans()\nFor the first step to estimate \\(E(Y|X,Z^+)\\), we use the emmeans() function. For our purpose, we specify the following three arguments in the emmeans() function.\n\nThe first argument (object) is the outcome of the lm() function, which is used to estimate the difference in \\(E(Y|X,Z^+)\\)\nThe second argument (spec) is the name of the independent variable of our interest, \\(X\\).\nThe third argument (at) is the values taken by the main independent variable of our interest, \\(X\\), and control variables, \\(Z\\). For \\(X\\), we will specify both \\(X = X^*\\) and \\(X = X^{**}\\). For all other control variables, \\(Z\\), we can specify \\(Z = Z^+\\), but we will see that the specification of the values for \\(Z\\) can be omitted for our purpose to compute the difference in \\(E(Y|X,Z^+)\\).\n\n\n\nAs we use the multiple linear regression model estimated in Section 9.1.3, \\(Y\\) is trudeau_therm_cps, \\(X\\) is percep_economy_cps_n, and \\(Z\\) includes ideology, union_d, and province.\nLet’s estimate the conditional expectation of trudeau_therm_cps between the respondents who perceived the state of economy had gotten better (percep_economy_cps_n = 3) and those who perceived it had gotten worse (percep_economy_cps_n = 1), holding the other control variables constant this way: ideology= 5,union_d=FALSE, andprovince=AB` (i.e., non-union member, Alberta resident with neutral ideology).\nHere,\n\n\\(X = X^{**}\\) corresponds to “percep_economy_cps_n = 3,”\n\\(X = X^*\\) corresponds to “percep_economy_cps_n = 1,” and\n\\(Z = Z^+\\) corresponds to “ideology = 5, union_d = FALSE, and province = AB”.\n\nFor simplicity, let’s estimate \\(E(Y|X^*,Z^+)\\) first. This is the conditional expectation of \\(Y\\) when the value of \\(X\\) is held at \\(X^*\\) and the values of \\(Z\\) at \\(Z^+\\).\n\n  emmeans( object = model, # The first argument is the output from the lm() function.\n           \n           specs = \"percep_economy_cps_n\",  # The second argument is the independent \n                                            # variable of our interest.\n           \n              # In the third argument, we specify the values at which we want to hold \n              # both the main independent variable of our interest and the other \n              # control variables. We may include the equations for all independent  \n              # variables within the list() function on the right-hand side of this \n              # argument.\n           at = list(percep_economy_cps_n = 1, \n                     ideology = 5, union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n\nConfidence level used: 0.95 \n\n\nIn the output above, you can see the point estimate of \\(E(Y|X^*,Z^+)\\) under emmean, its standard error under SE, the lower end of the 95% confidence interval for \\(E(Y|X^*,Z^+)\\) under lower.CL, and the upper end under upper.CL. I skip the “df” column as we don’t cover the degrees of freedom (“df”) in this class. According to this result, the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1, ideology = 5, union_d = FALSE, and province = AB is estimated as 17.8, and its 95% confidence interval is [13.8, 21.8].\nIn the second argument (specs), we specified percep_economy_cps_n as the main independent variable, X, for which we want to estimate \\(E(Y|X,Z^+)\\) at different values.\nIf we specify multiple values for percep_economy_cps_n in the third argument (at), then the emmeans() function will estimate multiple \\(E(Y|X,Z^+)\\) corresponding to each of the values specified for percep_economy_cps_n.\nBelow I specified three values — 1, 2 and 3 — for percep_economy_cps_n using c() to list all these values.\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # In the third argument, we specify three values --- 1, 2 and 3 --- for \n              # percep_economy_cps_n.\n           at = list(percep_economy_cps_n = c(1,2,3), \n                     ideology = 5, union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n                    2   33.6 2.05 2333     29.6     37.6\n                    3   49.4 2.33 2333     44.8     54.0\n\nConfidence level used: 0.95 \n\n\nThen, the emmeans() function estimated three conditional expectations of trudeau_therm_cps for each value specified for percep_economy_cps_n holding other variables at ideology = 5, union_d = FALSE, and province = AB. Specifically, the conditional expectation of trudeau_therm_cps is 17.8 when percep_economy_cps_n = 1, 33.6 when percep_economy_cps_n = 2, and 49.4 when percep_economy_cps_n = 3, holding other variables at the specified values.\nNote that the emmeans() function estimates \\(E(Y|X,Z^+)\\) for each of the specified values only for the variable specified in the specs argument (\\(X\\)). For example, the code below lists multiple values for ideology in the at argument3 while percep_economy_cps_n is still suggested in the specs argument. This code does not produce multiple \\(E(Y|X,Z)\\) for each of the specified values for ideology.\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # Now we specify the values from 0 to 10 for \"ideology,\"\n              # but the specs argument is still \"percep_economy_cps_n.\"\n           at = list(percep_economy_cps_n = 1, \n                     ideology = c(0:10), union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n\nResults are averaged over the levels of: ideology \nConfidence level used: 0.95 \n\n\nThe above command estimated only one \\(E(Y|X,Z)\\). There is also the message that “Results are averaged over the levels of: ideology”. What this means is that the emmeans() function first estimated multiple \\(E(Y|X,Z)\\) for each of the specified values from 0 to 10 of ideology with other variables fixed at the specified values and then took the average of \\(E(Y|X)\\) across all the values of ideology from 0 to 10. If we want to estimate \\(E(Y|X,Z)\\) for each of these values of ideology separately, we should specify ideology in the specs function as in the code below. Note that ideology is the main independent variable of our interest (\\(X\\)), and percep_economy_cps_n is one of the control variables (\\(Z\\)) in this case.\n\n  emmeans( object = model, \n           specs = \"ideology\",  \n              # The specs argument is now changed to \"ideology.\"\n           \n           at = list(percep_economy_cps_n = 1, \n                     ideology = c(0:10), union_d = FALSE, province = \"AB\") )\n\n ideology emmean   SE   df lower.CL upper.CL\n        0  31.10 2.54 2333   26.113    36.09\n        1  28.44 2.40 2333   23.733    33.14\n        2  25.78 2.27 2333   21.316    30.23\n        3  23.11 2.17 2333   18.856    27.37\n        4  20.45 2.09 2333   16.346    24.55\n        5  17.79 2.04 2333   13.779    21.80\n        6  15.12 2.03 2333   11.153    19.10\n        7  12.46 2.04 2333    8.466    16.46\n        8   9.80 2.08 2333    5.718    13.88\n        9   7.14 2.15 2333    2.914    11.36\n       10   4.47 2.25 2333    0.058     8.89\n\nConfidence level used: 0.95 \n\n\nNow the emmeans() function returned the estimation of \\(E(Y|X,Z^+)\\) for all the specified values of ideology (\\(X\\)), respectively, from 31.10 when ideology = 0 to 4.47 when ideology = 10 holding the other variables constant at the specified values (\\(Z^+\\)).\nSo far, we have specified the values for all variables included in our linear regression model (\\(X\\) and \\(Z\\)). For our purpose, however, it suffices to specify the values just for the independent variable of our interest (\\(X\\)). This is because what we are interested in is the difference in \\(E(Y|X,Z)\\) across different values of \\(X\\) holding other control variables \\(Z\\) constant. For this purpose, which values we hold control variables at do not matter. If the values of control variables are not specified, the emmeans() function will use means of these variables. In the code below, I specified the values for percep_economy_cps_n only in the third argument (at).\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # Now we specify the values for percep_economy_cps_n only.\n           at = list( percep_economy_cps_n = c(1,2,3) )  )\n\n percep_economy_cps_n emmean    SE   df lower.CL upper.CL\n                    1   29.6 1.020 2333     27.6     31.6\n                    2   45.5 0.755 2333     44.0     46.9\n                    3   61.3 1.160 2333     59.0     63.6\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated conditional expectations of trudeau_therm_cps for each value of percep_economy_cps_n in this output are different from those reported before. This is because the values of other control variables \\(Z\\) are held at different values. More specifically, without the values specified in the at argument, the values of the other variables \\(Z\\) are held at their means, if the variables are numeric. In the current example, as ideology is a numeric variable, its value is held at its mean. If \\(Z\\) are factor or logical variables, \\(E(Y|X,Z)\\) is first computed for each category of these variables in \\(Z\\), and the average of \\(E(Y|X,Z)\\) is computed across all these categories of \\(Z\\). Therefore, there is a message in the above output indicating “Results are averaged over the levels of: union_d, province.”\nBecause what values we hold control variables constant at do not matter when we take the difference in \\(E(Y|X)\\) by the contrast() function introduced in the next section, we will specify the values only for the independent variable of our interest \\(X\\) in the at argument of the emmeans() function in the rest of this chapter.\n\n\n\n9.2.4 Statistical Inference for Difference in \\(E(Y|X,Z^+)\\): contrast()\nIn the second step, we will supply the result of the emmeans() function to the contrast() function to estimate the difference in \\(E(Y|X)\\) between different values of the independent variable of interest. In other ward, we estimate \\(E(Y|X^{**},Z^+) - E(Y|X^{*},Z^+)\\) by this method.\nLet’s estimate the difference in the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1 (the respondent’s perception of economy is “Worse”) and when percep_economy_cps_n = 3 (the respondent’s perception of economy is “Better”), controlling for other variables.\nRecall that we can estimate \\(E(Y|X,Z^+)\\) for each of these two values of percep_economy_cps_n as below. Note that I use the pipe operator (|&gt;) in this code.\n\n  model |&gt;  \n        # \"model\" will be piped to the emmeans() function as its first argument.\n  \n      emmeans( specs = \"percep_economy_cps_n\",  \n               \n               # We now specify two values --- 1 and 3 --- only for percep_economy_cps_n \n               # in the at argument.\n               at = list( percep_economy_cps_n = c(1,3) ) )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   29.6 1.02 2333     27.6     31.6\n                    3   61.3 1.16 2333     59.0     63.6\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nWe supply this output to the contrast() function to take the difference. We set the method argument of the contrast() function to “pairwise”, so that the contrast() function will estimate a pairwise difference in \\(E(Y|X,Z^+)\\) between the values of \\(X\\) specified in the emmeans() function.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n        # The output from the emmeans() function is piped to the contrast() function.\n\n        # The method argument is set to \"pairwise\".\n      contrast( method = \"pairwise\" )\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n1 - percep_economy_cps_n3    -31.6 1.58 2333 -19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nIn the above output, the first column, named contrast, lists a pairwise comparison of the values of the independent variable \\(X\\) that we specified. In this column, we can see percep_economy_cps_n1 - percep_economy_cps_n3, which means that the contrast here is 1 - 3 in the value of percep_economy_cps_n. This indicates that what was estimated here was the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1 (“Worse”) minus the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 3 (“Better”), controlling for other variables. This is the expected change in trudeau_therm_cps when the percep_economy_cps variable changes from “Better” to “Worse”. Because the change in percep_economy_cps considered here corresponds to a two-unit decline of the value of percep_economy_cps_n, and the coefficient estimate on percep_economy_cps_n is positive (15.8163), the expected difference in trudeau_therm_cps in the current scenario is negative, \\((-2) \\times 15.8 = -31.6\\). This is perhaps counter intuitive, because the estimated relationship between trudeu_therm_cps and percep_economy_cps_n is positive.\nThe problem here is that the pairwise difference computed was 1 - 3 in terms of the values of percep_economy_cps_n, or “Worse - Better” in terms of percep_economy_cps. However, what we want instead is a pairwise difference of 3 - 1 or “Better - Worse”. That is, we want to reverse the order of these values.\nWe can correct this in two ways. First, we may reverse the order of the values specified for percep_economy_cps_n in the at argument in the emmeans() function as in the following code.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(3,1) ) ) |&gt; \n               # Now the values are specified as c(3,1) instead of c(1,3).               \n  \n      contrast( method = \"pairwise\")\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333  19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nSecond, we may keep the original order of the values for percep_economy_cps_n in the emmeans() function, but change the method argument to \"revpairwise\" in the conrast() function. “revpairwise” stands for a reversed pairwise comparison. As its name suggests, if we use “revpairwise,” the contrast() function reverses the order of a pairwise comparison.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list(percep_economy_cps_n = c(1,3) ) ) |&gt; \n               # Now the original order of the values --- c(1,3) --- is kept.               \n  \n        # The method argument is changed to \"revpairwise\".  \n      contrast( method = \"revpairwise\")\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333  19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nEither way, now we can get the difference we want — the change in the conditional expectation of trudeau_therm_cps when percep_economy_cps_n changes from 1 to 3 or percep_economy_cps changes from “Worse” to “Better”, which may be computed as \\(2 \\times 15.8 = 31.6\\)).\nIn the above outputs, what follows after contrast and estimate are a few statistics for statistical inference about the estimated difference in \\(E(Y|X,Z^+)\\), such as its standard error (SE) and p-value (p.value). We can also derive the confidence interval for the difference in \\(E(Y|X,Z^+)\\) by specifying the infer argument to TRUE in the contrast() function as in the code below.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n  \n        # Now we add \"infer = TRUE\" in the contrast() function.\n      contrast( method = \"revpairwise\", infer = TRUE )\n\n contrast                                      estimate   SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333     28.5\n upper.CL t.ratio p.value\n     34.7  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nIn this output, lower.CL indicates the lower end of the 95% confidence interval for the difference and upper.CL the upper end. According to this result, the 95% confidence interval for the difference in the conditional expectation of trudeau_therm_cps between those who perceived that the national economy had gotten better and those who perceived that it had gotten worse, controlling for the other variables included in the model, is [28.5, 34.7].\nWe can also change the confidence level by specifying the number between 0 and 1 in the level argument in the contrast() function. For example, if we specify level = 0.99 as in the code below, the contrast() function produces the 99% confidence interval for the difference in \\(E(Y|X,Z^+)\\).\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n  \n        # Now we add the level argument in the contrast() function.  \n      contrast( method = \"revpairwise\", infer = TRUE, level = 0.99 )\n\n contrast                                      estimate   SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333     27.5\n upper.CL t.ratio p.value\n     35.7  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.99 \n\n\nIn addition, we can also change the number of digits to appear. For this purpose, as in the code below, we need to use the summary() function and the print() function, consecutively, and we specify the number of digits we want in the print() function.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n      contrast( method = \"revpairwise\", infer = TRUE, level = 0.99 ) |&gt; \n  \n            # The output from the contrast() function is piped to the summary() function.\n      summary() |&gt; \n  \n            # Then, the output from the summary() function is piped further to the print() \n            # function, in which we can specify the number of digits to appear \n            # in the output on the R Console.\n      print( digits = 6 )\n\n contrast                                      estimate      SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1  31.6327 1.58427 2333  27.5485\n upper.CL t.ratio p.value\n  35.7168  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.99 \n\n\n\n\n9.2.5 Making Argument for Substantive Significance\nI suggested before that you should estimate the difference in \\(E(Y|X,Z^+)\\) corresponding to a meaningful amount of change in the independent variable of your interest, \\(X\\). You should carefully consider what would be a meaningful change in your main independent variable \\(X\\). Note that there are no hard and fast rules to determine what a meaningful amount of change would be. Instead, this is something you need to carefully consider and make a reasonable argument. To think about what a meaningful amount of change would be for your independent variable \\(X\\), it is advisable to explore the distribution of \\(X\\) carefully by using visualization and/or its summary statistics.\nAs an example, I draw a bar chart for percep_economy_cps below. As you can see, although about a half of the responses are concentrated on “Same,” the responses are reasonably spread across all three categories from “Worse” to “Better.” More specifically, of about 2,300 observations, approximately one third of the responses are “Worse” and a quarter are “Better”. This distribution of the responses may justify that the change from “Worse” to “Better” would be a meaningful change in percep_economy_cps in this sample, because there are reasonable fractions of observations in all these categories.\n\n\n\n\n\n\n\n\n\nIf most of the observations were concentrated on two consecutive categories, say “Worse” and “Same”, and only a tiny fraction of responses were in the last category, “Better”, as in the hypothetical bar chart below, then the change from “Worse” to “Better” might not have been justified as a meaningful change in percep_economy_cps in this hypothetical sample. In this case, a meaningful change may be from “Worse” to “Same” because this change encompasses most of the observations. The estimated change in the conditional expectations of trudeau_therm_cps corresponding to this change in percep_economy_cps is available immediately from the coefficient of percep_economy_cps_n as this is only a one-unit increase in percep_economy_cps_n.\n\n\n\n\n\n\n\n\n\nOnce you have determined the meaningful amount of change in \\(X\\), you can estimate the difference in \\(E(Y|X,Z^+)\\) by the emmeans() and contrast() functions, as discussed in Section 9.2.3 and Section 9.2.4. After that, you need to offer your argument about whether this estimated amount of change in \\(E(Y|X,Z^+)\\) is of substantively meaningful magnitude. The example above is relatively simple for this purpose because the estimated change in trudeau_therm_cps corresponding to the change in percep_economy from “Worse” to “Better” is \\(31.6\\), which is one-third — a large proportion — of the entire range of trudeau_therm_cps.\nWhen you evaluate the estimated difference in \\(E(Y|X,Z^+)\\) with respect to a meaningful change in \\(X\\), make sure you consider the entire range of its confidence interval. In the example above, the 99% confidence interval is [28.5, 34.7]. Even when we consider the lower end or the upper end of this interval, our conclusion will not change because either one is still about one-third of the entire range of trudeau_therm_cps. If the range of interval is so large that the conclusion may be different depending on whether we consider the point estimate, the lower end of the interval, or the upper end, then we should reflect this difference in our discussion. For example, if the confidence interval for the estimated change in trudeau_therm_cps corresponding to the change in percep_economy from “Worse” to “Better” were hypothetically [5.5, 57.7], then this expected change in trudeau_therm_cps would be as large as more than a half of the entire range (57.5) or as small as one twentieth of the entire range (5.5). Our discussion should reflect this inconclusiveness of the estimated magnitude in this hypothetical scenario.\nIn the above example, I compared the estimated difference in \\(E(Y|X)\\) with the entire range of the dependent variable, trudeau_therm_cps. Alternatively, you may compare the estimated difference in \\(E(Y|X)\\) with the IQR or the standard deviation of the dependent variable. If you use the IQR, then you compare the estimated difference in \\(E(Y|X)\\) with the amount of variation in \\(Y\\) in the middle half of your sample in terms of the value of \\(Y\\). If you use the standard deviation, then you compare it with a typical amount of deviation in the value of \\(Y\\) from the mean in your sample. You may also draw a histogram of your dependent variable and identify a meaningful range of values from the visual inspection of the distribution. It is of course fine if you can offer a reasonable discussion on the substantive magnitude of the difference in \\(E(Y|X)\\) without reference to a certain empirical range of the dependent variable. Again, there are no hard and fast rules to determine whether the estimated change in \\(E(Y|X)\\) is of substantive magnitude. Your creativity, logical and sensible reasoning, and convincing argumentation are called for.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#with-different-types-of-independent-variable",
    "href": "subsig.html#with-different-types-of-independent-variable",
    "title": "9  Substantive Significance",
    "section": "9.3 With Different Types of Independent Variable",
    "text": "9.3 With Different Types of Independent Variable\nThis section will discuss how we may consider a meaningful amount of change for different types of independent variables.\n\n9.3.1 Ordinal Categorical Variable\n\n9.3.1.1 Numeric Version\nAn independent variable in the example in the previous section (percep_economy_cps_n) was a numeric version of an ordinal categorical variable. Therefore, if the independent variable of your interest is a numeric version of an ordinal categorical variable, then you may consider a meaningful change of this type of variable as we did in the previous section.\n\n\n9.3.1.2 Dummified Version\nIf the independent variable of your interest is dummified for all categories except for one (i.e., a factor version of an ordinal categorical variable is included in the right-hand side of the linear regression model in R), you may consider it in a similar way to the example given below in the section on a nominal categorical variable (Section 3.4).\n\n\n\n9.3.2 Quantitative Variable (numeric)\nNow consider the difference in the conditional expectation of trudeau_therm_cps for a meaningful change in ideology controlling for other variables in the model estimated above. ideology is a quantitative variable.\n\n9.3.2.1 Entire Range\nOne idea is to estimate the difference in \\(E(Y|X)\\) between the minimum and maximum values of ideology as we did for percep_economy_cps_n. As the minimum value of ideology is 0 (most leftist/liberal position), and the maximum is 10 (most rightist/conservative position), let’s specify these values for ideology in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(10, 0) ) ) |&gt;\n                # We specified the maximum and minimum values of ideology.\n  \n  contrast( method = \"pairwise\", infer = TRUE )\n\n contrast               estimate   SE   df lower.CL upper.CL t.ratio p.value\n ideology10 - ideology0    -26.6 2.52 2333    -31.6    -21.7 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional mean of trudeau_therm_cps between the most conservative respondents (ideology = 10) and the most liberal respondents (ideology = 0), controlling for all other variables included in the model, is \\(-26.6\\) and its 95% confidence interval is [-31.6, -21.7].\nAs discussed before, we should carefully consider what a meaningful amount of change of ideology would be. For this purpose, let’s draw a bar chart of ideology below .\n\n\n\n\n\n\n\n\n\nAccording to this bar chart, the respondents are spread across the entire range of ideology from the most leftist position (ideology = 0) to the most rightist position (ideology = 10). This observation may be used to justify the comparison of the conditional expectation of trudeau_therm_cps between the maximum and minimum values of ideology.\n\n\n9.3.2.2 IQR\nHowever, the bar chart also indicates that there are only a very small number of respondents in the extreme ideological positions, such as 0, 1, 9 and 10. We may want to use an alternative amount of change in ideology, which do not include these extreme ideological positions. For example, we may want to use the IQR of ideology, which represents the extent of variation in the values of ideology in the middle half of the sample. IQR of ideology may be computed by the IQR() function.\n\n  IQR(my_data$ideology, na.rm = TRUE)\n\n[1] 3\n\n\nFor our purpose, however, we need the values of both lower and upper quartiles because we need to specify these values for ideology in the at function of the emmeans() function. We can find the lower and upper quartiles of a variable by applying the summary() function to the variable.\n\n  summary(my_data$ideology)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   4.000   5.000   5.061   7.000  10.000 \n\n\nAccording to the above result, the lower quartile of ideology is 4 and the upper quartile is 7. Let’s specify these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7, 4) ) ) |&gt; \n                # We specified the upper and lower quartiles of ideology.  \n  \n  contrast( method = \"pairwise\", infer = TRUE )\n\n contrast              estimate    SE   df lower.CL upper.CL t.ratio p.value\n ideology7 - ideology4    -7.99 0.757 2333    -9.47     -6.5 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional expectation of trudeau_therm_cps between the respondents with the upper quartile in ideology and those with the lower quartile is \\(-7.99\\) and its 95% confidence interval is [ -9.47, -6.5].\n\n\n9.3.2.3 One Standard Deviation Above and Below the Mean\nAlternatively, we may want to use the standard deviation of ideology as a meaningful amount of change in this variable. We may use the sd() function to compute the standard deviation of a variable.\n\n  sd(my_data$ideology)\n\n[1] 2.21214\n\n\nAs the standard deviation represents a typical amount of deviation from the mean of a variable, we may consider the variation in ideology from one standard deviation below its mean to one standard deviation above its mean. The mean of ideology was reported above as \\(5.06\\) when we applied the summary() function to ideology. Given that the standard deviation of ideology reported above is \\(2.21\\), the range between one standard deviation below its mean (\\(5.06 - 2.21 = 2.85\\)) and one standard deviation above its mean (\\(5.06 + 2.21 = 7.27\\)) is \\(2.85\\) and \\(7.27\\). Let’s specify these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7.27, 2.85) ) ) |&gt; \n                # We specified one standard deviation above the mean \n                # and one standard deviation below the mean of ideology.  \n\n  contrast( method = \"pairwise\", infer = TRUE ) |&gt;       \n  summary() |&gt; \n  print( digits = 4 )\n\n contrast                    estimate    SE   df lower.CL upper.CL t.ratio\n ideology7.27 - ideology2.85   -11.77 1.116 2333   -13.96   -9.581 -10.549\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional mean of trudeau_therm_cps between the respondents with one standard deviation above the mean in ideology and those with one standard deviation below the mean is \\(-11.77\\) and its 95% confidence interval is [-13.96, -9.58].\nNote that ideology is a variable which takes only integer values. It may not make sense to consider the values such as \\(7.27\\) and \\(2.85\\) as ideology never takes these values. In this case, it may be more appropriate to use other types of range discussed in the sections above and below.\nIf the independent variable of interest is , then the use of standard deviation makes more sense, as decimals naturally appear in such a variable.\nHere we considered of the independent variable, because we use the variation from one standard deviation below the mean to one standard deviation above the mean. Instead, we may also consider — e.g., the variation from the mean to one standard deviation above the mean. This amount of change is considered in my lecture when the substantive significance of economic voting in the U.S. presidential elections is discussed based on the national-level aggregate data.\n\n\n9.3.2.4 From Visual Inspection\nAnother alternative may be the range chosen from a visual inspection of the distribution of a variable. In the bar chart drawn above, we can see that the values of ideology in the medium range from 3 to 7, except for the middle point of 5, have a relatively similar number of respondents, which is almost twice the number of the scores right next to this range, 2 and 8. In other words, this medium range of 3 to 7 seems to stand out from the rest as the most popular range of left-right ideology. This observation may be used to justify the use of the difference in conditional expectation of trudeau_therm_cps in this range of ideology. In the code below, I used these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7, 3) ) ) |&gt; \n                # I derived these values from a visual inspection of\n                # the bar chart of \"ideology\" drawn above.\n\n  contrast( method = \"pairwise\", infer = TRUE ) |&gt;       \n  summary() |&gt; \n  print( digits = 4 )\n\n contrast              estimate   SE   df lower.CL upper.CL t.ratio p.value\n ideology7 - ideology3   -10.65 1.01 2333   -12.63   -8.671 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional expectation of trudeau_therm_cps in this visually identified middle range of ideology is \\(-10.65\\) and its 95% confidence interval is [-12.63, -8.67].\nAgain, there are to determine which one of the above ranges is most appropriate for ideology. You need to offer a reasonable and convincing justification on why you use a particular range. I would perhaps not use the mean plus/minus one standard deviation for ideology because ideology is discrete and never takes decimals. While the entire range of ideology is informative and legitimate in its own right, I would not rely solely on this range because the respondents with extreme values of ideology are very small in number. I would perhaps supplement the result with the entire range of ideology by the result with either the IQR of ideology or the range identified from a visual inspection.\n\n\n\n9.3.3 Dummy Variable (logical)\nFor a dummy independent variable, the difference in \\(E(Y|X)\\) when it is 1 and when it is 0 is an appropriate meaningful range of change because it doesn’t take any other values. Its estimate and confidence interval can be found immediately from the coefficient on the dummy independent variable reported in the output from the summ() function.\nIn the output of the multiple linear regression model estimated above, the coefficient estimate of union_d is 0.60 and its 95% confidence interval is [-2.03, 3.21]. Therefore, the point estimate of the difference in the conditional expectations of trudeau_therm_cps between those who belong to the unions and those who don’t, holding other variables in the model constant, is 0.60 and its 95% confidence interval is [-2.03, 3.21].\nSince this interval includes zero, this is an inconclusive evidence about whether there is any relationship between trudeau_therm_cps and union_d controlling for other variables. While it is inconclusive whether there is any positive or negative relationship, we can still say from this estimation result that if there is either a positive or negative relationship between them, it is likely to be small, because the lowest end of the 95% confidence interval is only \\(-2.03\\) and the highest end is only \\(3.21\\). Given that the range of trudeau_therm_cps is between 0 and 100 and the responses are spread over the entire range of this variable, these numbers (\\(-2.03\\) and \\(3.21\\)) seem to indicate a very small magnitude of the difference between uion members and non-members.\n\n\n9.3.4 Nominal Categorical Variable (factor)\nIf the independent variable of interest is a nominal categorical variable, the variable should be dummified on the right-hand side of a linear regression model. Review the Week 9 R Lab Session and Tutorial 8 Exercise for detail. For a nominal independent variable, a meaningful amount of change in the independent variable is some substantively/theoretically meaningful comparison of the categories in this independent variable.\nConsider province included in the multiple linear regression estimated above. As we saw in the previous Lab Sessions, the coefficient on each dummified variable represents the difference in \\(E(Y|X)\\) of the dummified category from \\(E(Y|X)\\) of the reference category, controlling for other variables included in the model. If a meaningful comparison of the categories is between a certain category with the reference category, the coefficient on the dummy variable for this category is the difference in \\(E(Y|X)\\) that we need. If a meaningful comparison of the categories is between certain categories other than the reference category, we need to estimate the difference in \\(E(Y|X)\\) between these categories.\nSuppose we posit that a meaningful comparison is between Ontario and Saskatchewan. Then, we should specify these categories in the at argument in the emmeans() function as below.\n\n  model |&gt;   \n      emmeans( specs = \"province\",  \n               at = list( province = c(\"ON\",\"SK\") ) ) |&gt; \n              # Comparison is between \"ON\" and \"SK.\"\n  \n      contrast( method = \"pairwise\", infer = TRUE ) |&gt; \n      summary() |&gt; \n      print( digits = 4 )\n\n contrast estimate   SE   df lower.CL upper.CL t.ratio p.value\n ON - SK      11.9 2.45 2333    7.092     16.7   4.855  &lt;.0001\n\nResults are averaged over the levels of: union_d \nConfidence level used: 0.95 \n\n\nAccording to this result, the estimated difference in the conditional expectation of trudeau_therm_cps between Ontario and Saskatchewan is \\(11.90\\) and its 95% confidence interval is [7.09, 16.70].\nAlternatively, suppose we posit that a meaningful comparison is between Ontario and Alberta. We can specify these categories in the at argument in the emmeans() function as below; however, because Alberta is the reference category of province, the result should be the same as the coefficient estimate on provinceON in the multiple linear regression output reported above.\n\n  model |&gt;   \n      emmeans( specs = \"province\",  \n               at = list( province = c(\"ON\",\"AB\") ) ) |&gt; \n      contrast( method = \"pairwise\", infer = TRUE ) |&gt; \n      summary() |&gt; \n      print( digits = 4 )\n\n contrast estimate    SE   df lower.CL upper.CL t.ratio p.value\n ON - AB     15.34 2.366 2333     10.7    19.98   6.483  &lt;.0001\n\nResults are averaged over the levels of: union_d \nConfidence level used: 0.95 \n\n\nAccording to this result, the estimated difference in the conditional expectation of trudeau_therm_cps between Ontario and Alberta is \\(15.34\\) and its 95% confidence interval is [10.70, 19.98], which is the same as the coefficient estimate on provinceON reported before.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "linreg_inf.html#sec-lr-inf-table",
    "href": "linreg_inf.html#sec-lr-inf-table",
    "title": "8  Statistical Inference for Linear Regression",
    "section": "8.4 Linear Regression Table: export_summs()",
    "text": "8.4 Linear Regression Table: export_summs()\nWe can also format the result of a linear regression into a nice table using the export_summs() function of the jtools package. To use this function, we also need the huxtable package.\nFirst, install the huxtable package.\n\n  install.packages(\"huxtable\")\n\nThen, load huxtable.\n\n  library(huxtable)\n\nNow we can use the export_summs() function from the jtools package. The basic syntax is the same as the summ() function.\n\n  export_summs(model2)\n\n\n\nModel 1\n\n(Intercept)24.76 ***\n\n(2.26)   \n\npercep_economy_cps_n17.19 ***\n\n(0.77)   \n\nideology-2.72 ***\n\n(0.25)   \n\nunion_dTRUE0.88    \n\n(1.35)   \n\nN2346       \n\nR20.24    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nThis is similar to the popular format of a linear regression table we see in many political science research articles. As you can see in the table, the first column is a list of linear regression coefficients including an intercept. In the next column, we can see the point estimates of these coefficients. The numbers in parentheses are the standard errors for each coefficient. N is the number of observations included in the linear regression analysis, and R2 is the R-squared for this linear regression model (as I mentioned before, I will cover R-squared in a lecture later in the semester).\nThe star signs (asterisks) right next to each coefficient estimate indicate statistical significance of each coefficient. You can find the legend for these star signs at the bottom of the table, which states that\n     *** p &lt; 0.001, ** p &lt; 0.01, and * p &lt; 0.05.\n\np in this legend refers to the p-value.\nThis legend can be read as:\n    *** indicates that the p-value is smaller than 0.001;\n     ** indicates that the p-value is smaller than 0.01; and\n      * indicates that the p-value is smaller than 0.05.\n\nTherefore, if the coefficient is given the *** sign, this means that this coefficient is statistically significant at the 0.1% significance level;\nif it is given **, this coefficient is statistically significant at the 1% significance level (but not statistically significant at the 0.1% significance level);\nif it is given *, this coefficient is statistically significant at the 5% significance level (but not at the 1% significance level); and\nif it is not given any stars, the coefficient is not statistically significant at the 5% or lower significance levels.\nIn the example above, all coefficients except for union_dTRUE are given ***, indicating that these coefficients are statistically significant at the 0.1% significance level. There is no star sign given to union_dTRUE, suggesting that this coefficient is not statistically significant even at the 5% significance level, the highest significance level reported in this table.\nBelow is another example, which is a linear regression of the democratic candidate’s vote share in the U.S. gubernatorial elections (ranney3_gub_prop) on the proportion of Democratic identifiers (democrat) in each state.\n\n  lm(formula = ranney3_gub_prop*100 ~ democrat, data = usstates2010) |&gt; \n    export_summs()\n\n\n\nModel 1\n\n(Intercept)26.76 ***\n\n(7.09)   \n\ndemocrat0.66 ** \n\n(0.22)   \n\nN49       \n\nR20.16    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nIn this table, the coefficient on democrat is given two stars (**), indicating that the coefficient on this variable is statistically significant at the 1% significance level (but not at the 0.1% significance level).\nThe export_summs() function can also create a table which juxtaposes a simple and multiple linear regression models. For example, the following code creates a table with both simple and multiple linear regression models for trudeau_therm_cps (recall that model1 is the simple linear regression model and model2 is the multiple linear regression model created earlier in Section 8.2).\n\n  export_summs(model1, model2)\n\n\n\nModel 1Model 2\n\n(Intercept)8.13 ***24.76 ***\n\n(1.22)   (2.26)   \n\npercep_economy_cps_n18.98 ***17.19 ***\n\n(0.61)   (0.77)   \n\nideology       -2.72 ***\n\n       (0.25)   \n\nunion_dTRUE       0.88    \n\n       (1.35)   \n\nN3859       2346       \n\nR20.20    0.24    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nA table like this is convenient for comparing the coefficient estimates for a certain variable of our interest across different models. In the present example, we may be interested in how the coefficient estimate for percep_economy_cps_n changes between simple and multiple linear regression models.\nWe can replace the standard errors in the table with confidence intervals by specifying the following argument in the export_summs() function.\n\n  export_summs(model1, model2,\n               error_format = \"[{conf.low}, {conf.high}]\")\n\n\n\nModel 1Model 2\n\n(Intercept)8.13 ***24.76 ***\n\n[5.74, 10.52]   [20.32, 29.19]   \n\npercep_economy_cps_n18.98 ***17.19 ***\n\n[17.79, 20.17]   [15.68, 18.71]   \n\nideology       -2.72 ***\n\n       [-3.22, -2.22]   \n\nunion_dTRUE       0.88    \n\n       [-1.77, 3.52]   \n\nN3859       2346       \n\nR20.20    0.24    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.\n\n\n\n\nIn this table, a pair of numbers in the squared brackets below each coefficient estimate indicates the confidence interval for that coefficient. For example, [17.79, 20.17] below the coefficient estimate for percep_economy_cps_n in Model 1 is the 95% confidence interval for the coefficient on percep_economy_cps_n.\nAs before, we can change the confidence level using the ci.width argument and the number of decimal places to appear using the digits argument. In the code below, I set the confidence level at 99% and decimal places to appear at four.\n\n  export_summs(model1, model2,\n               error_format = \"[{conf.low}, {conf.high}]\", \n               ci.width = 0.99, digits = 4)\n\n\n\nModel 1Model 2\n\n(Intercept)8.1281 ***24.7569 ***\n\n[5.7399, 10.5162]   [20.3195, 29.1944]   \n\npercep_economy_cps_n18.9823 ***17.1926 ***\n\n[17.7940, 20.1705]   [15.6772, 18.7080]   \n\nideology         -2.7193 ***\n\n         [-3.2191, -2.2194]   \n\nunion_dTRUE         0.8752    \n\n         [-1.7718, 3.5222]   \n\nN3859         2346         \n\nR20.2028    0.2416    \n\n *** p &lt; 0.001;  ** p &lt; 0.01;  * p &lt; 0.05.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Statistical Inference for Linear Regression</span>"
    ]
  },
  {
    "objectID": "subsig.html#footnotes",
    "href": "subsig.html#footnotes",
    "title": "9  Substantive Significance",
    "section": "",
    "text": "Review the lecture materials for more details about “statistical significance.”↩︎\nIt is possible that the estimated relationship seems relatively small in magnitude yet still substantively significant/important depending on its specific context. For example, suppose the magnitude of impact of a certain factor in local elections is found to be only about 10 votes, which seems very small, but if the number of votes needed to win an election is very small and turnout is low, even 10 votes could be decisive about who wins a race. In this case, although the magnitude of the impact seems relatively small, it is still meaningfully large in this particular context.↩︎\nc(0:10) produces a vector of consecutive numbers (integers) from 1 to 10.↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#sec-subsig-section",
    "href": "subsig.html#sec-subsig-section",
    "title": "9  Substantive Significance",
    "section": "9.2 Substantive Significance",
    "text": "9.2 Substantive Significance\n\n9.2.1 Basic Idea\nWhen we have a certain substantive/theoretical expectation for the relationship of two variables in the population, the first step to examine this expectation is to see whether we have a point estimate of the coefficient of a variable of our interest in the expected direction (i.e., positive or negative) and what range of values its confidence interval encompasses. If the confidence interval does not include zero, we may say that the coefficient of our interest is statistically distinguishable from zero, or more simply, statistically significant.1 We have seen how to conduct these analyses in R in Chapter 8.\nThe second step is to examine whether the relationship found is substantively important or significant. The relationship may be substantively important/significant if the magnitude of the estimated relationship is meaningfully large in its specific context.2 There is no unique way to assess the substantive significance of the relationship. In general, you need to make an argument based on the specific nature of the relationship of your interest and the findings in your empirical research.\nThere may be many different ways to make such an argument, but for the final paper in this class, I suggest you estimate the change in the expected value of the dependent variable (\\(E(Y|X)\\)) corresponding to a meaningful change in the independent variable of your interest (\\(X\\)) based on the results of your linear regression analysis.\nThis is what I have suggested in my lecture. To recap, let me restate my suggestion below.\n\nIdentify a substantively meaningful amount of change in \\(X\\). Let’s say this is identified as the change from \\(X^*\\) to \\(X^{**}\\). Then, it may be denoted as (\\(\\Delta X = X^{**} - X^*\\)).\nEstimate the change in \\(E(Y|X)\\), the change in the conditional expectation/mean of Y, corresponding to this substantively meaningful change in \\(X\\). This change can be denoted by \\(E(Y|X^{**}) - E(Y|X^{*}) = \\beta \\times \\Delta X\\), where \\(\\beta\\) is the coefficient of \\(X\\).\nEstimate the confidence interval for this change in \\(E(Y|X)\\).\nDiscuss the substantive magnitude of the relationship between \\(Y\\) and \\(X\\) based on both the point estimate and confidence interval for this change in \\(E(Y|X)\\).\n\n\nAs you can see in the above figure, this change in \\(E(Y|X) = E(Y|X^{**}) - E(Y|X^{*})\\) is the difference in the values of the dependent variable along a linear regression line in the population. This “difference (or change) in \\(E(Y|X)\\)” is the population parameter of our interest in the present context.\nThen, we estimate the change in \\(E(Y|X)\\) in the population using the difference in \\(\\widehat{Y}\\) or the difference in \\(\\widehat{E(Y|X)} = \\widehat{E(Y|X^{**})} - \\widehat{E(Y|X^{*})}\\), which is the difference in the predicted/fitted values computed from our sample linear regression model or the difference in the values of the dependent variable along a linear regression line in our sample. In other words, the difference in the predicted/fitted values, \\(\\widehat{E(Y|X)}\\) or \\(\\widehat{Y}\\), is our estimator or estimate for the difference in \\(E(Y|X)\\) in the population.\nThroughout this chapter, I will use “the difference (or change) in \\(E(Y|X)\\) (or the conditional expectation/mean)” and “\\(E(Y|X^{**}) - E(Y|X^{*})\\)” to refer to our population parameter\nSimilarly, I will use “the difference (or change) in \\(\\widehat{E(Y|X)}\\)” and “\\(\\widehat{E(Y|X^{**})} - \\widehat{E(Y|X^{*})}\\)” to refer to our estimator or estimate for the change in \\(E(Y|X)\\) in the population.\nNote that the discussion so far implicitly assumes that we have only one independent variable, \\(X\\), on the right hand side of a linear regression equation. However, we normally control for some other variables, which are collectively denoted by \\(Z\\) here. Therefore, the change in the conditional expectation of \\(Y\\) corresponding to the meaningful change in \\(X\\) is estimated holding all other variables \\(Z\\) constant at certain values, say \\(Z^+\\). Incorporating \\(Z^+\\), our population parameter can be denoted as “the difference (or change) in \\(E(Y|X,Z^+) = E(Y|X^{**},Z^+) - E(Y|X^{*},Z^+)\\)”.\nFor example, suppose we want to evaluate the substantive magnitude of the relationship between trudeau_therm_cps (\\(Y\\)) and percep_econ_cps_n (\\(X\\)) controlling for other variables (\\(Z\\)) based on the multiple linear regression estimated in Section 9.1.3. In this case, we first estimate the difference in the conditional expectations of trudeau_therm_cps (\\(E(Y|X,Z)\\)) between the individuals who perceived that the state of national economy had gotten better (\\(X = 3\\)) and those who perceived that it had gotten worse (\\(X = 1\\)), holding all other variables constant (\\(Z = Z^+\\)). In equation, the difference we estimate may be written as \\(E(Y | X = 3, Z^+) - E(Y | X = 1, Z^+)\\)\nWe should also derive the confidence interval for the difference in the conditional expectations of trudeau_therm_cps between the individuals who perceived that the state of economy had gotten better and those who perceived that it had gotten worse, holding other variables constant. Then, we will offer an argument about whether this difference in \\(E(Y|X,Z^+)\\) is meaningfully large in the particular context of this relationship based on its point estimate and confidence interval.\n\n\n9.2.2 Estimation by the emmeans() Package\nTo estimate the difference in \\(E(Y|X,Z^+)\\) and derive its confidence interval, we will use the emmeans() function and the contrast() function from the emmeans package.\nFirst, install the emmeans package (Section 1.4).\n\n  install.packages(\"emmeans\")\n\nThen, load this package.\n\n  library(emmeans)\n\n\nOur analysis is in two steps.\n\nIn the first step, we will use the emmeans() function to estimate \\(E(Y|X,Z^+)\\) for different values of \\(X\\), such as \\(X^*\\) and \\(X^{**}\\), holding other variables \\(Z\\) constant at \\(Z^+\\).\nIn the second step, we will supply the result of the emmeans() function to the contrast() function to conduct statistical inference for the difference in \\(E(Y|X,Z^+) = E(Y|X^{**},Z^+) - E(Y|X^{*},Z^+)\\).\n\nI will explain each step in turn in the following two sections.\n\n\n9.2.3 Estimate \\(E(Y|X,Z^+)\\): emmeans()\nFor the first step to estimate \\(E(Y|X,Z^+)\\), we use the emmeans() function. For our purpose, we specify the following three arguments in the emmeans() function.\n\nThe first argument (object) is the outcome of the lm() function, which is used to estimate the difference in \\(E(Y|X,Z^+)\\)\nThe second argument (spec) is the name of the independent variable of our interest, \\(X\\).\nThe third argument (at) is the values taken by the main independent variable of our interest, \\(X\\), and control variables, \\(Z\\). For \\(X\\), we will specify both \\(X = X^*\\) and \\(X = X^{**}\\). For all other control variables, \\(Z\\), we can specify \\(Z = Z^+\\), but we will see that the specification of the values for \\(Z\\) can be omitted for our purpose to compute the difference in \\(E(Y|X,Z^+)\\).\n\n\n\nAs we use the multiple linear regression model estimated in Section 9.1.3, \\(Y\\) is trudeau_therm_cps, \\(X\\) is percep_economy_cps_n, and \\(Z\\) includes ideology, union_d, and province.\nLet’s estimate the conditional expectation of trudeau_therm_cps between the respondents who perceived the state of economy had gotten better (percep_economy_cps_n = 3) and those who perceived it had gotten worse (percep_economy_cps_n = 1), holding the other control variables constant this way: ideology= 5,union_d=FALSE, andprovince=AB` (i.e., non-union member, Alberta resident with neutral ideology).\nHere,\n\n\\(X = X^{**}\\) corresponds to “percep_economy_cps_n = 3,”\n\\(X = X^*\\) corresponds to “percep_economy_cps_n = 1,” and\n\\(Z = Z^+\\) corresponds to “ideology = 5, union_d = FALSE, and province = AB”.\n\nFor simplicity, let’s estimate \\(E(Y|X^*,Z^+)\\) first. This is the conditional expectation of \\(Y\\) when the value of \\(X\\) is held at \\(X^*\\) and the values of \\(Z\\) at \\(Z^+\\).\n\n  emmeans( object = model, # The first argument is the output from the lm() function.\n           \n           specs = \"percep_economy_cps_n\",  # The second argument is the independent \n                                            # variable of our interest.\n           \n              # In the third argument, we specify the values at which we want to hold \n              # both the main independent variable of our interest and the other \n              # control variables. We may include the equations for all independent  \n              # variables within the list() function on the right-hand side of this \n              # argument.\n           at = list(percep_economy_cps_n = 1, \n                     ideology = 5, union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n\nConfidence level used: 0.95 \n\n\nIn the output above, you can see the point estimate of \\(E(Y|X^*,Z^+)\\) under emmean, its standard error under SE, the lower end of the 95% confidence interval for \\(E(Y|X^*,Z^+)\\) under lower.CL, and the upper end under upper.CL. I skip the “df” column as we don’t cover the degrees of freedom (“df”) in this class. According to this result, the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1, ideology = 5, union_d = FALSE, and province = AB is estimated as 17.8, and its 95% confidence interval is [13.8, 21.8].\nIn the second argument (specs), we specified percep_economy_cps_n as the main independent variable, X, for which we want to estimate \\(E(Y|X,Z^+)\\) at different values.\nIf we specify multiple values for percep_economy_cps_n in the third argument (at), then the emmeans() function will estimate multiple \\(E(Y|X,Z^+)\\) corresponding to each of the values specified for percep_economy_cps_n.\nBelow I specified three values — 1, 2 and 3 — for percep_economy_cps_n using c() to list all these values.\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # In the third argument, we specify three values --- 1, 2 and 3 --- for \n              # percep_economy_cps_n.\n           at = list(percep_economy_cps_n = c(1,2,3), \n                     ideology = 5, union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n                    2   33.6 2.05 2333     29.6     37.6\n                    3   49.4 2.33 2333     44.8     54.0\n\nConfidence level used: 0.95 \n\n\nThen, the emmeans() function estimated three conditional expectations of trudeau_therm_cps for each value specified for percep_economy_cps_n holding other variables at ideology = 5, union_d = FALSE, and province = AB. Specifically, the conditional expectation of trudeau_therm_cps is 17.8 when percep_economy_cps_n = 1, 33.6 when percep_economy_cps_n = 2, and 49.4 when percep_economy_cps_n = 3, holding other variables at the specified values.\nNote that the emmeans() function estimates \\(E(Y|X,Z^+)\\) for each of the specified values only for the variable specified in the specs argument (\\(X\\)). For example, the code below lists multiple values for ideology in the at argument3 while percep_economy_cps_n is still suggested in the specs argument. This code does not produce multiple \\(E(Y|X,Z)\\) for each of the specified values for ideology.\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # Now we specify the values from 0 to 10 for \"ideology,\"\n              # but the specs argument is still \"percep_economy_cps_n.\"\n           at = list(percep_economy_cps_n = 1, \n                     ideology = c(0:10), union_d = FALSE, province = \"AB\") )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   17.8 2.04 2333     13.8     21.8\n\nResults are averaged over the levels of: ideology \nConfidence level used: 0.95 \n\n\nThe above command estimated only one \\(E(Y|X,Z)\\). There is also the message that “Results are averaged over the levels of: ideology”. What this means is that the emmeans() function first estimated multiple \\(E(Y|X,Z)\\) for each of the specified values from 0 to 10 of ideology with other variables fixed at the specified values and then took the average of \\(E(Y|X)\\) across all the values of ideology from 0 to 10. If we want to estimate \\(E(Y|X,Z)\\) for each of these values of ideology separately, we should specify ideology in the specs function as in the code below. Note that ideology is the main independent variable of our interest (\\(X\\)), and percep_economy_cps_n is one of the control variables (\\(Z\\)) in this case.\n\n  emmeans( object = model, \n           specs = \"ideology\",  \n              # The specs argument is now changed to \"ideology.\"\n           \n           at = list(percep_economy_cps_n = 1, \n                     ideology = c(0:10), union_d = FALSE, province = \"AB\") )\n\n ideology emmean   SE   df lower.CL upper.CL\n        0  31.10 2.54 2333   26.113    36.09\n        1  28.44 2.40 2333   23.733    33.14\n        2  25.78 2.27 2333   21.316    30.23\n        3  23.11 2.17 2333   18.856    27.37\n        4  20.45 2.09 2333   16.346    24.55\n        5  17.79 2.04 2333   13.779    21.80\n        6  15.12 2.03 2333   11.153    19.10\n        7  12.46 2.04 2333    8.466    16.46\n        8   9.80 2.08 2333    5.718    13.88\n        9   7.14 2.15 2333    2.914    11.36\n       10   4.47 2.25 2333    0.058     8.89\n\nConfidence level used: 0.95 \n\n\nNow the emmeans() function returned the estimation of \\(E(Y|X,Z^+)\\) for all the specified values of ideology (\\(X\\)), respectively, from 31.10 when ideology = 0 to 4.47 when ideology = 10 holding the other variables constant at the specified values (\\(Z^+\\)).\nSo far, we have specified the values for all variables included in our linear regression model (\\(X\\) and \\(Z\\)). For our purpose, however, it suffices to specify the values just for the independent variable of our interest (\\(X\\)). This is because what we are interested in is the difference in \\(E(Y|X,Z)\\) across different values of \\(X\\) holding other control variables \\(Z\\) constant. For this purpose, which values we hold control variables at do not matter. If the values of control variables are not specified, the emmeans() function will use means of these variables. In the code below, I specified the values for percep_economy_cps_n only in the third argument (at).\n\n  emmeans( object = model, \n           specs = \"percep_economy_cps_n\",  \n           \n              # Now we specify the values for percep_economy_cps_n only.\n           at = list( percep_economy_cps_n = c(1,2,3) )  )\n\n percep_economy_cps_n emmean    SE   df lower.CL upper.CL\n                    1   29.6 1.020 2333     27.6     31.6\n                    2   45.5 0.755 2333     44.0     46.9\n                    3   61.3 1.160 2333     59.0     63.6\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated conditional expectations of trudeau_therm_cps for each value of percep_economy_cps_n in this output are different from those reported before. This is because the values of other control variables \\(Z\\) are held at different values. More specifically, without the values specified in the at argument, the values of the other variables \\(Z\\) are held at their means, if the variables are numeric. In the current example, as ideology is a numeric variable, its value is held at its mean. If \\(Z\\) are factor or logical variables, \\(E(Y|X,Z)\\) is first computed for each category of these variables in \\(Z\\), and the average of \\(E(Y|X,Z)\\) is computed across all these categories of \\(Z\\). Therefore, there is a message in the above output indicating “Results are averaged over the levels of: union_d, province.”\nBecause what values we hold control variables constant at do not matter when we take the difference in \\(E(Y|X)\\) by the contrast() function introduced in the next section, we will specify the values only for the independent variable of our interest \\(X\\) in the at argument of the emmeans() function in the rest of this chapter.\n\n\n\n9.2.4 Statistical Inference for Difference in \\(E(Y|X,Z^+)\\): contrast()\nIn the second step, we will supply the result of the emmeans() function to the contrast() function to estimate the difference in \\(E(Y|X)\\) between different values of the independent variable of interest. In other ward, we estimate \\(E(Y|X^{**},Z^+) - E(Y|X^{*},Z^+)\\) by this method.\nLet’s estimate the difference in the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1 (the respondent’s perception of economy is “Worse”) and when percep_economy_cps_n = 3 (the respondent’s perception of economy is “Better”), controlling for other variables.\nRecall that we can estimate \\(E(Y|X,Z^+)\\) for each of these two values of percep_economy_cps_n as below. Note that I use the pipe operator (|&gt;) in this code.\n\n  model |&gt;  \n        # \"model\" will be piped to the emmeans() function as its first argument.\n  \n      emmeans( specs = \"percep_economy_cps_n\",  \n               \n               # We now specify two values --- 1 and 3 --- only for percep_economy_cps_n \n               # in the at argument.\n               at = list( percep_economy_cps_n = c(1,3) ) )\n\n percep_economy_cps_n emmean   SE   df lower.CL upper.CL\n                    1   29.6 1.02 2333     27.6     31.6\n                    3   61.3 1.16 2333     59.0     63.6\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nWe supply this output to the contrast() function to take the difference. We set the method argument of the contrast() function to “pairwise”, so that the contrast() function will estimate a pairwise difference in \\(E(Y|X,Z^+)\\) between the values of \\(X\\) specified in the emmeans() function.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n        # The output from the emmeans() function is piped to the contrast() function.\n\n        # The method argument is set to \"pairwise\".\n      contrast( method = \"pairwise\" )\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n1 - percep_economy_cps_n3    -31.6 1.58 2333 -19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nIn the above output, the first column, named contrast, lists a pairwise comparison of the values of the independent variable \\(X\\) that we specified. In this column, we can see percep_economy_cps_n1 - percep_economy_cps_n3, which means that the contrast here is 1 - 3 in the value of percep_economy_cps_n. This indicates that what was estimated here was the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 1 (“Worse”) minus the conditional expectation of trudeau_therm_cps when percep_economy_cps_n = 3 (“Better”), controlling for other variables. This is the expected change in trudeau_therm_cps when the percep_economy_cps variable changes from “Better” to “Worse”. Because the change in percep_economy_cps considered here corresponds to a two-unit decline of the value of percep_economy_cps_n, and the coefficient estimate on percep_economy_cps_n is positive (15.8163), the expected difference in trudeau_therm_cps in the current scenario is negative, \\((-2) \\times 15.8 = -31.6\\). This is perhaps counter intuitive, because the estimated relationship between trudeu_therm_cps and percep_economy_cps_n is positive.\nThe problem here is that the pairwise difference computed was 1 - 3 in terms of the values of percep_economy_cps_n, or “Worse - Better” in terms of percep_economy_cps. However, what we want instead is a pairwise difference of 3 - 1 or “Better - Worse”. That is, we want to reverse the order of these values.\nWe can correct this in two ways. First, we may reverse the order of the values specified for percep_economy_cps_n in the at argument in the emmeans() function as in the following code.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(3,1) ) ) |&gt; \n               # Now the values are specified as c(3,1) instead of c(1,3).               \n  \n      contrast( method = \"pairwise\")\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333  19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nSecond, we may keep the original order of the values for percep_economy_cps_n in the emmeans() function, but change the method argument to \"revpairwise\" in the conrast() function. “revpairwise” stands for a reversed pairwise comparison. As its name suggests, if we use “revpairwise,” the contrast() function reverses the order of a pairwise comparison.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list(percep_economy_cps_n = c(1,3) ) ) |&gt; \n               # Now the original order of the values --- c(1,3) --- is kept.               \n  \n        # The method argument is changed to \"revpairwise\".  \n      contrast( method = \"revpairwise\")\n\n contrast                                      estimate   SE   df t.ratio\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333  19.967\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \n\n\nEither way, now we can get the difference we want — the change in the conditional expectation of trudeau_therm_cps when percep_economy_cps_n changes from 1 to 3 or percep_economy_cps changes from “Worse” to “Better”, which may be computed as \\(2 \\times 15.8 = 31.6\\)).\nIn the above outputs, what follows after contrast and estimate are a few statistics for statistical inference about the estimated difference in \\(E(Y|X,Z^+)\\), such as its standard error (SE) and p-value (p.value). We can also derive the confidence interval for the difference in \\(E(Y|X,Z^+)\\) by specifying the infer argument to TRUE in the contrast() function as in the code below.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n  \n        # Now we add \"infer = TRUE\" in the contrast() function.\n      contrast( method = \"revpairwise\", infer = TRUE )\n\n contrast                                      estimate   SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333     28.5\n upper.CL t.ratio p.value\n     34.7  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nIn this output, lower.CL indicates the lower end of the 95% confidence interval for the difference and upper.CL the upper end. According to this result, the 95% confidence interval for the difference in the conditional expectation of trudeau_therm_cps between those who perceived that the national economy had gotten better and those who perceived that it had gotten worse, controlling for the other variables included in the model, is [28.5, 34.7].\nWe can also change the confidence level by specifying the number between 0 and 1 in the level argument in the contrast() function. For example, if we specify level = 0.99 as in the code below, the contrast() function produces the 99% confidence interval for the difference in \\(E(Y|X,Z^+)\\).\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n  \n        # Now we add the level argument in the contrast() function.  \n      contrast( method = \"revpairwise\", infer = TRUE, level = 0.99 )\n\n contrast                                      estimate   SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1     31.6 1.58 2333     27.5\n upper.CL t.ratio p.value\n     35.7  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.99 \n\n\nIn addition, we can also change the number of digits to appear. For this purpose, as in the code below, we need to use the summary() function and the print() function, consecutively, and we specify the number of digits we want in the print() function.\n\n  model |&gt;   \n      emmeans( specs = \"percep_economy_cps_n\",  \n               at = list( percep_economy_cps_n = c(1,3) ) ) |&gt; \n      contrast( method = \"revpairwise\", infer = TRUE, level = 0.99 ) |&gt; \n  \n            # The output from the contrast() function is piped to the summary() function.\n      summary() |&gt; \n  \n            # Then, the output from the summary() function is piped further to the print() \n            # function, in which we can specify the number of digits to appear \n            # in the output on the R Console.\n      print( digits = 6 )\n\n contrast                                      estimate      SE   df lower.CL\n percep_economy_cps_n3 - percep_economy_cps_n1  31.6327 1.58427 2333  27.5485\n upper.CL t.ratio p.value\n  35.7168  19.967  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.99 \n\n\n\n\n9.2.5 Making Argument for Substantive Significance\nI suggested before that you should estimate the difference in \\(E(Y|X,Z^+)\\) corresponding to a meaningful amount of change in the independent variable of your interest, \\(X\\). You should carefully consider what would be a meaningful change in your main independent variable \\(X\\). Note that there are no hard and fast rules to determine what a meaningful amount of change would be. Instead, this is something you need to carefully consider and make a reasonable argument. To think about what a meaningful amount of change would be for your independent variable \\(X\\), it is advisable to explore the distribution of \\(X\\) carefully by using visualization and/or its summary statistics.\nAs an example, I draw a bar chart for percep_economy_cps below. As you can see, although about a half of the responses are concentrated on “Same,” the responses are reasonably spread across all three categories from “Worse” to “Better.” More specifically, of about 2,300 observations, approximately one third of the responses are “Worse” and a quarter are “Better”. This distribution of the responses may justify that the change from “Worse” to “Better” would be a meaningful change in percep_economy_cps in this sample, because there are reasonable fractions of observations in all these categories.\n\n\n\n\n\n\n\n\n\nIf most of the observations were concentrated on two consecutive categories, say “Worse” and “Same”, and only a tiny fraction of responses were in the last category, “Better”, as in the hypothetical bar chart below, then the change from “Worse” to “Better” might not have been justified as a meaningful change in percep_economy_cps in this hypothetical sample. In this case, a meaningful change may be from “Worse” to “Same” because this change encompasses most of the observations. The estimated change in the conditional expectations of trudeau_therm_cps corresponding to this change in percep_economy_cps is available immediately from the coefficient of percep_economy_cps_n as this is only a one-unit increase in percep_economy_cps_n.\n\n\n\n\n\n\n\n\n\nOnce you have determined the meaningful amount of change in \\(X\\), you can estimate the difference in \\(E(Y|X,Z^+)\\) by the emmeans() and contrast() functions, as discussed in Section 9.2.3 and Section 9.2.4. After that, you need to offer your argument about whether this estimated amount of change in \\(E(Y|X,Z^+)\\) is of substantively meaningful magnitude. The example above is relatively simple for this purpose because the estimated change in trudeau_therm_cps corresponding to the change in percep_economy from “Worse” to “Better” is \\(31.6\\), which is one-third — a large proportion — of the entire range of trudeau_therm_cps.\nWhen you evaluate the estimated difference in \\(E(Y|X,Z^+)\\) with respect to a meaningful change in \\(X\\), make sure you consider the entire range of its confidence interval. In the example above, the 99% confidence interval is [28.5, 34.7]. Even when we consider the lower end or the upper end of this interval, our conclusion will not change because either one is still about one-third of the entire range of trudeau_therm_cps. If the range of interval is so large that the conclusion may be different depending on whether we consider the point estimate, the lower end of the interval, or the upper end, then we should reflect this difference in our discussion. For example, if the confidence interval for the estimated change in trudeau_therm_cps corresponding to the change in percep_economy from “Worse” to “Better” were hypothetically [5.5, 57.7], then this expected change in trudeau_therm_cps would be as large as more than a half of the entire range (57.5) or as small as one twentieth of the entire range (5.5). Our discussion should reflect this inconclusiveness of the estimated magnitude in this hypothetical scenario.\nIn the above example, I compared the estimated difference in \\(E(Y|X)\\) with the entire range of the dependent variable, trudeau_therm_cps. Alternatively, you may compare the estimated difference in \\(E(Y|X)\\) with the IQR or the standard deviation of the dependent variable. If you use the IQR, then you compare the estimated difference in \\(E(Y|X)\\) with the amount of variation in \\(Y\\) in the middle half of your sample in terms of the value of \\(Y\\). If you use the standard deviation, then you compare it with a typical amount of deviation in the value of \\(Y\\) from the mean in your sample. You may also draw a histogram of your dependent variable and identify a meaningful range of values from the visual inspection of the distribution of \\(Y\\). It is of course fine if you can offer a reasonable discussion on the substantive magnitude of the difference in \\(E(Y|X)\\) without reference to a certain empirical range of the dependent variable. Again, there are no hard and fast rules to determine whether the estimated change in \\(E(Y|X)\\) is of substantive magnitude. Your creativity, logical and sensible reasoning, and convincing argumentation are called for.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  },
  {
    "objectID": "subsig.html#with-different-types-of-independent-variable-x",
    "href": "subsig.html#with-different-types-of-independent-variable-x",
    "title": "9  Substantive Significance",
    "section": "9.3 With Different Types of Independent Variable \\(X\\)",
    "text": "9.3 With Different Types of Independent Variable \\(X\\)\nThis section will discuss how we may consider a meaningful amount of change for different types of independent variable \\(X\\).\n\n9.3.1 Ordinal Categorical Variable\n\n9.3.1.1 Numeric Version\nThe main independent variable \\(X\\) in the example in the previous section (Section 9.2), percep_economy_cps_n, was a numeric version of an ordinal categorical variable. Therefore, if the independent variable of your interest is a numeric version of an ordinal categorical variable, then you may consider a meaningful change of this type of variable as we did in the previous section (Section 9.2).\n\n\n9.3.1.2 Dummified Version\nIf the independent variable of your interest \\(X\\) is dummified for all categories except for one (i.e., a factor version of an ordinal categorical variable is included in the right-hand side of the linear regression model in R), you may consider it in a similar way to the example given below in the section on a nominal categorical variable (Section 9.3.4).\n\n\n\n9.3.2 Quantitative Variable (numeric)\nNow consider the difference in the conditional expectation of trudeau_therm_cps for a meaningful change in ideology controlling for other variables in the model estimated above. That is, now we consider ideology as our main independent variable \\(X\\).\nNote that ideology is a quantitative variable.\n\n9.3.2.1 Entire Range\nOne idea is to estimate the difference in \\(E(Y|X)\\) between the minimum and maximum values of ideology as we did for percep_economy_cps_n. As the minimum value of ideology is 0 (most leftist/liberal position), and the maximum is 10 (most rightist/conservative position), let’s specify these values for ideology in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(10, 0) ) ) |&gt;\n          # We specified the maximum and minimum values of ideology.\n  \n  contrast( method = \"pairwise\", infer = TRUE )\n\n contrast               estimate   SE   df lower.CL upper.CL t.ratio p.value\n ideology10 - ideology0    -26.6 2.52 2333    -31.6    -21.7 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional mean of trudeau_therm_cps between the most conservative respondents (ideology = 10) and the most liberal respondents (ideology = 0), controlling for all other variables included in the model, is \\(-26.6\\) and its 95% confidence interval is [-31.6, -21.7].\nAs discussed before, we should carefully consider what a meaningful amount of change of ideology would be. For this purpose, let’s draw a bar chart of ideology below. Note that we draw a bar chart here because “ideology” takes only 11 values. If we examine a continuous variable or a discrete variable with many more values, it may be better to draw a histogram.\n\n\n\n\n\n\n\n\n\nAccording to this bar chart, the respondents are spread across the entire range of ideology from the most leftist position (ideology = 0) to the most rightist position (ideology = 10). This observation may be used to justify the comparison of the conditional expectation of trudeau_therm_cps between the maximum and minimum values of ideology.\n\n\n9.3.2.2 IQR\nHowever, the bar chart also indicates that there are only a very small number of respondents in the extreme ideological positions, such as 0, 1, 9 and 10. We may want to use an alternative amount of change in ideology, which do not include these extreme ideological positions. For example, we may want to use the IQR of ideology, which represents the extent of variation in the values of ideology in the middle half of the sample. IQR of ideology may be computed by the IQR() function.\n\n  IQR(my_data$ideology, na.rm = TRUE)\n\n[1] 3\n\n\nFor our purpose, however, we need the values of both lower and upper quartiles because we need to specify these values for ideology in the at argument of the emmeans() function. We can find the lower and upper quartiles of a variable by applying the summary() function to the variable.\n\n  summary(my_data$ideology)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   4.000   5.000   5.061   7.000  10.000 \n\n\nAccording to the above result, the lower quartile of ideology is 4 and the upper quartile is 7. Let’s specify these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7, 4) ) ) |&gt; \n                # We specified the upper and lower quartiles of ideology.  \n  \n  contrast( method = \"pairwise\", infer = TRUE )\n\n contrast              estimate    SE   df lower.CL upper.CL t.ratio p.value\n ideology7 - ideology4    -7.99 0.757 2333    -9.47     -6.5 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional expectation of trudeau_therm_cps between the respondents with the upper quartile in ideology and those with the lower quartile is \\(-7.99\\) and its 95% confidence interval is [ -9.47, -6.5].\n\n\n9.3.2.3 One Standard Deviation Above and Below the Mean\nAlternatively, we may want to use the standard deviation of ideology as a meaningful amount of change in this variable. We may use the sd() function to compute the standard deviation of a variable.\n\n  sd(my_data$ideology)\n\n[1] 2.21214\n\n\nAs the standard deviation represents a typical amount of deviation from the mean of a variable, we may consider the variation in ideology from one standard deviation below its mean to one standard deviation above its mean. The mean of ideology was reported above as \\(5.06\\) when we applied the summary() function to ideology. Given that the standard deviation of ideology reported above is \\(2.21\\), the range between one standard deviation below its mean (\\(5.06 - 2.21 = 2.85\\)) and one standard deviation above its mean (\\(5.06 + 2.21 = 7.27\\)) is \\(2.85\\) and \\(7.27\\). Let’s specify these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7.27, 2.85) ) ) |&gt; \n                # We specified one standard deviation above the mean \n                # and one standard deviation below the mean of ideology.  \n\n  contrast( method = \"pairwise\", infer = TRUE ) |&gt;       \n  summary() |&gt; \n  print( digits = 4 )\n\n contrast                    estimate    SE   df lower.CL upper.CL t.ratio\n ideology7.27 - ideology2.85   -11.77 1.116 2333   -13.96   -9.581 -10.549\n p.value\n  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional mean of trudeau_therm_cps between the respondents with one standard deviation above the mean in ideology and those with one standard deviation below the mean is \\(-11.77\\), and its 95% confidence interval is [-13.96, -9.58].\nNote that ideology is a discrete variable which takes only integer values. It may not make sense to consider the values such as \\(7.27\\) and \\(2.85\\) as ideology never takes these values. In this case, it may be more appropriate to use other types of range discussed in the sections above (Section 9.3.2.1, Section 9.3.2.2) and below (Section 9.3.2.4).\nIf the independent variable of interest is continuous, then the use of standard deviation makes more sense, as decimals naturally appear in such a variable.\nHere we considered a two standard deviation change of the independent variable \\(X\\), because we use the variation from one standard deviation below the mean to one standard deviation above the mean. Instead, we may also consider a one standard deviation change — e.g., the variation from the mean to one standard deviation above the mean. This amount of change is considered in my lecture when the substantive significance of economic voting in the U.S. presidential elections is discussed based on the national-level aggregate data.\n\n\n9.3.2.4 From Visual Inspection\nAnother alternative may be the range chosen from a visual inspection of the distribution of \\(X\\). In the bar chart drawn above, we can see that the values of ideology in the medium range from 3 to 7, except for the middle point of 5, have a relatively similar number of respondents, which is almost twice the number of the scores right next to this range, 2 and 8. In other words, this medium range of 3 to 7 seems to stand out from the rest as the most popular range of left-right ideology. This observation may be used to justify the use of the difference in conditional expectation of trudeau_therm_cps in this range of ideology. In the code below, I used these values in the at argument of the emmeans() function.\n\nmodel |&gt; \n  emmeans( specs = \"ideology\",  \n           at = list( ideology = c(7, 3) ) ) |&gt; \n                # I derived these values from a visual inspection of\n                # the bar chart of \"ideology\" drawn above.\n\n  contrast( method = \"pairwise\", infer = TRUE ) |&gt;       \n  summary() |&gt; \n  print( digits = 4 )\n\n contrast              estimate   SE   df lower.CL upper.CL t.ratio p.value\n ideology7 - ideology3   -10.65 1.01 2333   -12.63   -8.671 -10.549  &lt;.0001\n\nResults are averaged over the levels of: union_d, province \nConfidence level used: 0.95 \n\n\nThe estimated difference in the conditional expectation of trudeau_therm_cps in this visually identified middle range of ideology is \\(-10.65\\) and its 95% confidence interval is [-12.63, -8.67].\nAgain, there are no hard and fast rules to determine which one of the above ranges is most appropriate for ideology. You need to offer a reasonable and convincing justification on why you use a particular range. I would perhaps not use the mean plus/minus one standard deviation for ideology because ideology is discrete and never takes decimals. While the entire range of ideology is informative and legitimate in its own right, I would not rely solely on this range because the respondents with extreme values of ideology are very small in number. I would perhaps supplement the result with the entire range of ideology by the result with either the IQR of ideology or the range identified from a visual inspection.\n\n\n\n9.3.3 Dummy Variable (logical)\nIf the independent variable of interest \\(X\\) is a dummy variable, the change from \\(X = 0\\) to \\(X = 1\\) is an appropriate meaningful range of change because it doesn’t take any other values. Its estimate and confidence interval can be found immediately from the coefficient on the dummy independent variable \\(X\\) reported in the output from the summ() function.\nIn the output of the multiple linear regression model estimated in Section 9.1.3, the coefficient estimate of union_d is 0.60 and its 95% confidence interval is [-2.03, 3.21]. Therefore, the point estimate of the difference in the conditional expectations of trudeau_therm_cps between those who belong to the unions and those who don’t, holding other variables in the model constant, is 0.60 and its 95% confidence interval is [-2.03, 3.21].\nSince this confidence interval includes zero, this is inconclusive evidence about whether there is any relationship between trudeau_therm_cps and union_d controlling for other variables. While it is inconclusive whether there is any positive or negative relationship, we can still say from this estimation result that even if there is either a positive or negative relationship between them, it is likely to be small, because the lowest end of the 95% confidence interval is only \\(-2.03\\) and the highest end is only \\(3.21\\). Given that the range of trudeau_therm_cps is between 0 and 100, and the responses are spread over the entire range of this variable, these numbers (\\(-2.03\\) and \\(3.21\\)) seem to indicate a very small magnitude of the difference between uion members and non-members.\n\n\n9.3.4 Nominal Categorical Variable (factor)\nIf the independent variable of interest \\(X\\) is a nominal categorical variable, the variable should be dummified on the right-hand side of a linear regression model. Review Section 7.3 and Section 7.5 for detail. For a nominal categorical variable, a meaningful amount of change may be some substantively/theoretically meaningful comparison of the categories.\nConsider province included in the multiple linear regression estimated in Section 9.1.3. As we saw in Section 7.3 and Section 7.5, the coefficient on each dummified variable represents the difference between \\(E(Y|X,Z^+)\\) of the dummified category and \\(E(Y|X,Z^+)\\) of the reference category, controlling for other variables included in the model. Therefore, if a meaningful comparison of the categories is between a certain category and the reference category, we can estimate the difference in \\(E(Y|X,Z^+)\\) immediately from the coefficient on the dummy variable for this category.\nOn the other hand, if a meaningful comparison of the categories is between certain categories other than the reference category, we need to estimate the difference in \\(E(Y|X,Z^+)\\) between these categories using the emmeans() and the contrast() functions.\nSuppose we posit that a meaningful comparison is between Ontario and Saskatchewan. The choice like this, of course, needs to be justified. For example, we may argue that it is meaningful to compare a relatively urban province and a relatively rural province because urban areas tend to be more liberal while rural areas tend to be more conservative in developed democracies, and Ontario is more urban than Saskatchewan because the biggest urban areas in Canada can be found in Ontario, and a larger proportion of the population live in rural areas in Saskatchwan than in Ontario. Since both categories are not the reference category, we should specify both categories in the at argument in the emmeans() function as below.\n\n  model |&gt;   \n      emmeans( specs = \"province\",  \n               at = list( province = c(\"ON\",\"SK\") ) ) |&gt; \n              # Comparison is between \"ON\" and \"SK.\"\n  \n      contrast( method = \"pairwise\", infer = TRUE ) |&gt; \n      summary() |&gt; \n      print( digits = 4 )\n\n contrast estimate   SE   df lower.CL upper.CL t.ratio p.value\n ON - SK      11.9 2.45 2333    7.092     16.7   4.855  &lt;.0001\n\nResults are averaged over the levels of: union_d \nConfidence level used: 0.95 \n\n\nAccording to this result, the estimated difference in the conditional expectation of trudeau_therm_cps between Ontario and Saskatchewan is \\(11.90\\) and its 95% confidence interval is [7.09, 16.70].\nAlternatively, suppose we posit that a meaningful comparison is between Ontario and Alberta. Because Alberta is the reference category of province, the difference in the conditional expectation of trudeau_therm_cps between Ontario and Alberta is the same as the coefficient on the dummy variable for Ontario (provinceON). According to the linear regression table reported in Section 9.1.3, this difference or the coefficient of provinceON is \\(15.34\\), and its 95% confidence interval is [10.70, 19.98].",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Substantive Significance</span>"
    ]
  }
]